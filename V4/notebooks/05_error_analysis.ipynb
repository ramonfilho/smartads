{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2227fa51-0f7b-4454-97ee-d8f72f2e7f38",
   "metadata": {},
   "source": [
    "# Error analysis 1\n",
    "- Identification of high-value false negatives (conversions that the model does not detect). What in common do they have?\n",
    "- Identify clusters of leads with similar characteristics but different conversion behaviors, and what information can lead the algorithm to classify better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35aff8a-6cee-4778-be43-721ff343ab3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando conjuntos de dados originais...\n",
      "Dados carregados - treino: (74629, 225), validação: (15992, 225)\n",
      "Encontradas 225 colunas em comum entre os conjuntos\n",
      "Sanitizando nomes das colunas...\n",
      "Convertendo colunas inteiras para float...\n",
      "Taxa de conversão - treino: 0.0176, validação: 0.0176\n",
      "\n",
      "Treinando novo modelo RandomForest com parâmetros originais...\n",
      "Gerando previsões...\n",
      "Analisando erros...\n",
      "\n",
      "Métricas de desempenho:\n",
      "Precision: 0.6139\n",
      "Recall: 0.2199\n",
      "F1 Score: 0.3238\n",
      "Taxa de Falsos Positivos: 0.0025\n",
      "Falsos Negativos: 220 de 282 conversões reais\n",
      "Falsos Positivos: 39 de 15710 não-conversões reais\n",
      "\n",
      "Número de falsos negativos: 220\n",
      "Lista detalhada salva em: error_analysis/false_negatives.csv\n",
      "\n",
      "--- Análise de Falsos Negativos de Alto Valor ---\n",
      "\n",
      "Características numéricas distintivas em falsos negativos:\n",
      "  - Cuando hables inglés con fluidez, ¿qué cambiará en tu vida? ¿Qué oportunidades se abrirán para ti?_tfidf_conocer: 156.47% maior que a média geral\n",
      "  - Déjame un mensaje_tfidf_deseo: 123.59% maior que a média geral\n",
      "  - ¿Qué esperas aprender en la Inmersión Desbloquea Tu Inglés En 72 horas?_tfidf_mejor: 67.11% maior que a média geral\n",
      "  - ¿Qué esperas aprender en la Semana de Cero a Inglés Fluido?_tfidf_comunicarme: 57.08% maior que a média geral\n",
      "  - Déjame un mensaje_tfidf_mejorar: 38.44% maior que a média geral\n",
      "\n",
      "Características categóricas distintivas em falsos negativos:\n",
      "  - desired_salary_encoded = 4.0: 72.27% (vs 56.08% na população), 1.29x mais comum\n",
      "  - current_salary_encoded = 5.0: 20.45% (vs 7.89% na população), 2.59x mais comum\n",
      "  - current_salary_encoded = 4.0: 20.00% (vs 10.17% na população), 1.97x mais comum\n",
      "  - utm_day_of_week = 5.0: 20.79% (vs 14.19% na população), 1.47x mais comum\n",
      "  - gender_encoded = 1.0: 70.45% (vs 63.97% na população), 1.10x mais comum\n",
      "\n",
      "Análise de falsos negativos por segmentos:\n",
      "\n",
      "Segmentos com maior taxa de falsos negativos para country_freq:\n",
      "  - country_freq=0.0512601652706517: 100.00% das conversões não detectadas (11.0 de 11.0)\n",
      "  - country_freq=0.0448256779192031: 100.00% das conversões não detectadas (9.0 de 9.0)\n",
      "  - country_freq=0.2848714509487586: 87.18% das conversões não detectadas (34.0 de 39.0)\n",
      "\n",
      "Segmentos com maior taxa de falsos negativos para age_encoded:\n",
      "  - age_encoded=1.0: 87.50% das conversões não detectadas (7.0 de 8.0)\n",
      "  - age_encoded=4.0: 84.88% das conversões não detectadas (73.0 de 86.0)\n",
      "  - age_encoded=3.0: 82.09% das conversões não detectadas (55.0 de 67.0)\n",
      "\n",
      "Segmentos com maior taxa de falsos negativos para Cuando hables inglés con fluidez, ¿qué cambiará en tu vida? ¿Qué oportunidades se abrirán para ti?_motiv_improvement:\n",
      "  - Cuando hables inglés con fluidez, ¿qué cambiará en tu vida? ¿Qué oportunidades se abrirán para ti?_motiv_improvement=2.0: 100.00% das conversões não detectadas (3.0 de 3.0)\n",
      "  - Cuando hables inglés con fluidez, ¿qué cambiará en tu vida? ¿Qué oportunidades se abrirán para ti?_motiv_improvement=1.0: 78.43% das conversões não detectadas (40.0 de 51.0)\n",
      "  - Cuando hables inglés con fluidez, ¿qué cambiará en tu vida? ¿Qué oportunidades se abrirán para ti?_motiv_improvement=0.0: 77.63% das conversões não detectadas (177.0 de 228.0)\n",
      "\n",
      "--- Perfil Comparativo: Conversões Detectadas vs Não Detectadas ---\n",
      "Principais diferenças entre conversões detectadas e não detectadas:\n",
      "  - Déjame un mensaje_length: 64.5000 nas detectadas vs 59.1545 nas não detectadas\n",
      "  - age_encoded: 3.7377 nas detectadas vs 3.5227 nas não detectadas\n",
      "  - profession_freq: 0.0015 nas detectadas vs 0.0017 nas não detectadas\n",
      "  - UTM_CAMPAING_freq: 0.0279 nas detectadas vs 0.0317 nas não detectadas\n",
      "  - country_freq: 0.1397 nas detectadas vs 0.1488 nas não detectadas\n",
      "\n",
      "Número de falsos positivos: 39\n",
      "\n",
      "=== RESUMO DA ANÁLISE DE ERROS ===\n",
      "Total de registros analisados: 15992\n",
      "Conversões reais: 282.0 (1.76%)\n",
      "Conversões previstas: 101 (0.63%)\n",
      "Falsos negativos: 220 (78.01% das conversões reais)\n",
      "Falsos positivos: 39 (0.25% das não-conversões reais)\n",
      "Precisão: 0.6139, Recall: 0.2199, F1: 0.3238\n",
      "Todos os resultados foram salvos em: error_analysis/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Carregar dados do mesmo caminho usado originalmente\n",
    "print(\"Carregando conjuntos de dados originais...\")\n",
    "data_path = \"datasets/split/\"\n",
    "train_df = pd.read_csv(f\"{data_path}train.csv\")\n",
    "val_df = pd.read_csv(f\"{data_path}validation.csv\")\n",
    "\n",
    "print(f\"Dados carregados - treino: {train_df.shape}, validação: {val_df.shape}\")\n",
    "\n",
    "# 2. Identificar colunas comuns entre os conjuntos\n",
    "common_cols = set(train_df.columns).intersection(set(val_df.columns))\n",
    "print(f\"Encontradas {len(common_cols)} colunas em comum entre os conjuntos\")\n",
    "\n",
    "# 3. Usar apenas colunas em comum\n",
    "train_df = train_df[list(common_cols)]\n",
    "val_df = val_df[list(common_cols)]\n",
    "\n",
    "# 4. Sanitizar nomes das colunas (simplificado)\n",
    "print(\"Sanitizando nomes das colunas...\")\n",
    "# Aplicamos mesma transformação em ambos os conjuntos para garantir consistência\n",
    "target_col = 'target'\n",
    "feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "# 5. Converter colunas inteiras para float\n",
    "print(\"Convertendo colunas inteiras para float...\")\n",
    "for col in train_df.columns:\n",
    "    if pd.api.types.is_integer_dtype(train_df[col].dtype):\n",
    "        train_df[col] = train_df[col].astype(float)\n",
    "        val_df[col] = val_df[col].astype(float)\n",
    "\n",
    "# 6. Criar cópias para X e y\n",
    "X_train = train_df[feature_cols].copy()\n",
    "y_train = train_df[target_col].copy()\n",
    "X_val = val_df[feature_cols].copy()\n",
    "y_val = val_df[target_col].copy()\n",
    "\n",
    "print(f\"Taxa de conversão - treino: {y_train.mean():.4f}, validação: {y_val.mean():.4f}\")\n",
    "\n",
    "# 7. Treinar um modelo fresh com os mesmos parâmetros\n",
    "print(\"\\nTreinando novo modelo RandomForest com parâmetros originais...\")\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "best_threshold = 0.15  # valor do modelo original\n",
    "\n",
    "# 8. Gerar previsões\n",
    "print(\"Gerando previsões...\")\n",
    "y_pred_prob_val = rf_model.predict_proba(X_val)[:, 1]\n",
    "y_pred_val = (y_pred_prob_val >= best_threshold).astype(int)\n",
    "\n",
    "# 9. Criar diretório para salvar análises\n",
    "results_dir = \"error_analysis\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 10. Calcular e visualizar matriz de confusão\n",
    "print(\"Analisando erros...\")\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Não Converteu', 'Converteu'],\n",
    "            yticklabels=['Não Converteu', 'Converteu'])\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "# 11. Calcular métricas\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "print(f\"\\nMétricas de desempenho:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Taxa de Falsos Positivos: {fpr:.4f}\")\n",
    "print(f\"Falsos Negativos: {fn} de {fn+tp} conversões reais\")\n",
    "print(f\"Falsos Positivos: {fp} de {fp+tn} não-conversões reais\")\n",
    "\n",
    "# 12. Analisar distribuição de probabilidades\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_pred_prob_val[y_val == 0], bins=50, alpha=0.5, color='blue', label='Não Converteu')\n",
    "plt.hist(y_pred_prob_val[y_val == 1], bins=50, alpha=0.5, color='red', label='Converteu')\n",
    "plt.axvline(x=best_threshold, color='green', linestyle='--', label=f'Threshold: {best_threshold:.4f}')\n",
    "plt.title('Distribuição de Probabilidades Previstas')\n",
    "plt.xlabel('Probabilidade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend()\n",
    "plt.savefig(f\"{results_dir}/probability_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# 13. Análise de Falsos Negativos (conversões não detectadas)\n",
    "false_negatives = (y_val == 1) & (y_pred_val == 0)\n",
    "fn_indices = np.where(false_negatives)[0]\n",
    "fn_data = val_df.iloc[fn_indices].copy()\n",
    "fn_data['predicted_prob'] = y_pred_prob_val[fn_indices]\n",
    "\n",
    "# Ordenar por probabilidade (do maior para o menor - casos limítrofes)\n",
    "fn_data = fn_data.sort_values('predicted_prob', ascending=False)\n",
    "\n",
    "# Salvar para análise detalhada\n",
    "fn_data.to_csv(f\"{results_dir}/false_negatives.csv\", index=False)\n",
    "print(f\"\\nNúmero de falsos negativos: {len(fn_data)}\")\n",
    "print(f\"Lista detalhada salva em: {results_dir}/false_negatives.csv\")\n",
    "\n",
    "# 14. Identificar características comuns em falsos negativos de alto valor\n",
    "print(\"\\n--- Análise de Falsos Negativos de Alto Valor ---\")\n",
    "if len(fn_data) > 0:\n",
    "    # Tentar identificar colunas numéricas e categóricas\n",
    "    numeric_cols = []\n",
    "    categorical_cols = []\n",
    "    \n",
    "    for col in val_df.columns:\n",
    "        if col not in [target_col, 'predicted_prob'] and col in fn_data.columns:\n",
    "            try:\n",
    "                if pd.api.types.is_numeric_dtype(val_df[col]) and val_df[col].nunique() > 10:\n",
    "                    numeric_cols.append(col)\n",
    "                else:\n",
    "                    categorical_cols.append(col)\n",
    "            except:\n",
    "                categorical_cols.append(col)\n",
    "    \n",
    "    # Limitar o número de colunas para análise\n",
    "    numeric_cols = numeric_cols[:20]\n",
    "    categorical_cols = categorical_cols[:20]\n",
    "    \n",
    "    # Análise de características numéricas\n",
    "    if numeric_cols:\n",
    "        print(\"\\nCaracterísticas numéricas distintivas em falsos negativos:\")\n",
    "        numeric_analysis = []\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            try:\n",
    "                # Calcular estatísticas\n",
    "                fn_mean = fn_data[col].mean()\n",
    "                pop_mean = val_df[col].mean()\n",
    "                \n",
    "                # Calcular diferença percentual\n",
    "                diff_pct = ((fn_mean - pop_mean) / pop_mean * 100) if pop_mean != 0 else 0\n",
    "                \n",
    "                numeric_analysis.append({\n",
    "                    'Feature': col,\n",
    "                    'FN_Mean': fn_mean,\n",
    "                    'Population_Mean': pop_mean,\n",
    "                    'Diff_Pct': diff_pct\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pass  # Ignorar erros silenciosamente\n",
    "        \n",
    "        # Ordenar por diferença percentual\n",
    "        numeric_df = pd.DataFrame(numeric_analysis)\n",
    "        if not numeric_df.empty:\n",
    "            numeric_df = numeric_df.sort_values('Diff_Pct', ascending=False)\n",
    "            \n",
    "            # Mostrar top 5 características numéricas distintivas\n",
    "            for i, row in numeric_df.head(5).iterrows():\n",
    "                direction = \"maior\" if row['Diff_Pct'] > 0 else \"menor\"\n",
    "                print(f\"  - {row['Feature']}: {abs(row['Diff_Pct']):.2f}% {direction} que a média geral\")\n",
    "            \n",
    "            # Salvar análise completa\n",
    "            numeric_df.to_csv(f\"{results_dir}/fn_numeric_features.csv\", index=False)\n",
    "    \n",
    "    # Análise de características categóricas\n",
    "    if categorical_cols:\n",
    "        print(\"\\nCaracterísticas categóricas distintivas em falsos negativos:\")\n",
    "        categorical_analysis = []\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            try:\n",
    "                # Calcular frequências\n",
    "                pop_freq = val_df[col].value_counts(normalize=True).to_dict()\n",
    "                fn_freq = fn_data[col].value_counts(normalize=True).to_dict()\n",
    "                \n",
    "                # Identificar valores com maior diferença\n",
    "                for val, freq in fn_freq.items():\n",
    "                    if val in pop_freq:\n",
    "                        diff = freq - pop_freq[val]\n",
    "                        ratio = freq / pop_freq[val] if pop_freq[val] > 0 else float('inf')\n",
    "                        \n",
    "                        if abs(diff) > 0.05:  # Apenas diferenças significativas\n",
    "                            categorical_analysis.append({\n",
    "                                'Feature': col,\n",
    "                                'Value': val,\n",
    "                                'FN_Freq': freq,\n",
    "                                'Pop_Freq': pop_freq[val],\n",
    "                                'Difference': diff,\n",
    "                                'Ratio': ratio\n",
    "                            })\n",
    "            except Exception as e:\n",
    "                pass  # Ignorar erros silenciosamente\n",
    "        \n",
    "        # Ordenar por maior diferença\n",
    "        cat_df = pd.DataFrame(categorical_analysis)\n",
    "        if not cat_df.empty:\n",
    "            cat_df = cat_df.sort_values('Difference', ascending=False)\n",
    "            \n",
    "            # Mostrar top 5 características categóricas distintivas\n",
    "            for i, row in cat_df.head(5).iterrows():\n",
    "                print(f\"  - {row['Feature']} = {row['Value']}: {row['FN_Freq']:.2%} (vs {row['Pop_Freq']:.2%} na população), {row['Ratio']:.2f}x mais comum\")\n",
    "            \n",
    "            # Salvar análise completa\n",
    "            cat_df.to_csv(f\"{results_dir}/fn_categorical_features.csv\", index=False)\n",
    "    \n",
    "    # 15. Análise por segmentos (tipo de lançamento, país, etc.)\n",
    "    segment_cols = []\n",
    "    \n",
    "    # Identificar colunas de segmentação potencialmente interessantes\n",
    "    for pattern in ['launch', 'lançament', 'country', 'pais', 'age', 'idade']:\n",
    "        cols = [col for col in val_df.columns if pattern.lower() in col.lower()]\n",
    "        if cols:\n",
    "            segment_cols.extend(cols[:1])  # Adicionar apenas a primeira coluna encontrada para cada padrão\n",
    "    \n",
    "    # Limitar o número total de segmentos\n",
    "    segment_cols = segment_cols[:5]\n",
    "    \n",
    "    if segment_cols:\n",
    "        print(\"\\nAnálise de falsos negativos por segmentos:\")\n",
    "        \n",
    "        for col in segment_cols:\n",
    "            if col in val_df.columns:\n",
    "                try:\n",
    "                    # Calcular taxa de falsos negativos por segmento\n",
    "                    segment_stats = []\n",
    "                    \n",
    "                    # Limitar a 10 valores mais frequentes para evitar análise excessiva\n",
    "                    top_values = val_df[col].value_counts().nlargest(10).index\n",
    "                    \n",
    "                    for value in top_values:\n",
    "                        # Filtrar dados para este segmento\n",
    "                        segment_mask = val_df[col] == value\n",
    "                        segment_y_true = y_val[segment_mask]\n",
    "                        segment_y_pred = y_pred_val[segment_mask]\n",
    "                        \n",
    "                        # Se houver dados suficientes\n",
    "                        if sum(segment_mask) >= 20 and sum(segment_y_true) > 0:\n",
    "                            # Calcular taxa de falsos negativos\n",
    "                            segment_fn = ((segment_y_true == 1) & (segment_y_pred == 0)).sum()\n",
    "                            segment_fn_rate = segment_fn / sum(segment_y_true)\n",
    "                            \n",
    "                            segment_stats.append({\n",
    "                                'Segmento': value,\n",
    "                                'Tamanho': sum(segment_mask),\n",
    "                                'Conversões': sum(segment_y_true),\n",
    "                                'Falsos_Negativos': segment_fn,\n",
    "                                'Taxa_FN': segment_fn_rate\n",
    "                            })\n",
    "                    \n",
    "                    # Ordenar por taxa de falsos negativos\n",
    "                    segment_df = pd.DataFrame(segment_stats)\n",
    "                    if not segment_df.empty:\n",
    "                        segment_df = segment_df.sort_values('Taxa_FN', ascending=False)\n",
    "                        segment_df.to_csv(f\"{results_dir}/segment_analysis_{col}.csv\", index=False)\n",
    "                        \n",
    "                        print(f\"\\nSegmentos com maior taxa de falsos negativos para {col}:\")\n",
    "                        for i, row in segment_df.head(3).iterrows():\n",
    "                            print(f\"  - {col}={row['Segmento']}: {row['Taxa_FN']:.2%} das conversões não detectadas ({row['Falsos_Negativos']} de {row['Conversões']})\")\n",
    "                except Exception as e:\n",
    "                    pass  # Ignorar erros silenciosamente\n",
    "    \n",
    "    # 16. Comparação de perfil: conversões detectadas vs não detectadas\n",
    "    print(\"\\n--- Perfil Comparativo: Conversões Detectadas vs Não Detectadas ---\")\n",
    "    true_positives = (y_val == 1) & (y_pred_val == 1)\n",
    "    tp_indices = np.where(true_positives)[0]\n",
    "    tp_data = val_df.iloc[tp_indices].copy()\n",
    "    \n",
    "    # Selecionar features importantes para comparação\n",
    "    top_features = []\n",
    "    try:\n",
    "        feature_imp = pd.DataFrame({\n",
    "            'Feature': feature_cols,\n",
    "            'Importance': rf_model.feature_importances_\n",
    "        })\n",
    "        top_features = feature_imp.sort_values('Importance', ascending=False).head(10)['Feature'].tolist()\n",
    "    except:\n",
    "        # Se não conseguir obter importância de features, usar as numéricas\n",
    "        top_features = numeric_cols[:10]\n",
    "    \n",
    "    # Comparar médias entre TPs e FNs\n",
    "    comparison = []\n",
    "    for col in top_features:\n",
    "        if col in tp_data.columns and col in fn_data.columns:\n",
    "            try:\n",
    "                tp_mean = tp_data[col].mean()\n",
    "                fn_mean = fn_data[col].mean()\n",
    "                diff = tp_mean - fn_mean\n",
    "                \n",
    "                comparison.append({\n",
    "                    'Feature': col,\n",
    "                    'Detected_Mean': tp_mean,\n",
    "                    'Missed_Mean': fn_mean,\n",
    "                    'Difference': diff\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pass  # Ignorar erros silenciosamente\n",
    "    \n",
    "    # Mostrar diferenças mais significativas\n",
    "    comp_df = pd.DataFrame(comparison)\n",
    "    if not comp_df.empty:\n",
    "        comp_df = comp_df.sort_values('Difference', ascending=False)\n",
    "        comp_df.to_csv(f\"{results_dir}/detected_vs_missed_comparison.csv\", index=False)\n",
    "        \n",
    "        print(\"Principais diferenças entre conversões detectadas e não detectadas:\")\n",
    "        for i, row in comp_df.head(5).iterrows():\n",
    "            print(f\"  - {row['Feature']}: {row['Detected_Mean']:.4f} nas detectadas vs {row['Missed_Mean']:.4f} nas não detectadas\")\n",
    "else:\n",
    "    print(\"Não há falsos negativos suficientes para análise detalhada.\")\n",
    "\n",
    "# 17. Análise de Falsos Positivos\n",
    "false_positives = (y_val == 0) & (y_pred_val == 1)\n",
    "fp_indices = np.where(false_positives)[0]\n",
    "fp_data = val_df.iloc[fp_indices].copy()\n",
    "fp_data['predicted_prob'] = y_pred_prob_val[fp_indices]\n",
    "\n",
    "# Ordenar por probabilidade (do maior para o menor)\n",
    "fp_data = fp_data.sort_values('predicted_prob', ascending=False)\n",
    "\n",
    "# Salvar para análise detalhada\n",
    "fp_data.to_csv(f\"{results_dir}/false_positives.csv\", index=False)\n",
    "print(f\"\\nNúmero de falsos positivos: {len(fp_data)}\")\n",
    "\n",
    "# 18. Importância das features\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_imp = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n",
    "feature_imp = feature_imp.sort_values('Importance', ascending=False).head(30)\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp)\n",
    "plt.title('Top 30 Features (Importância do RandomForest)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/feature_importance.png\")\n",
    "plt.close()\n",
    "feature_imp.to_csv(f\"{results_dir}/feature_importance.csv\", index=False)\n",
    "\n",
    "# 19. Resumo final\n",
    "print(\"\\n=== RESUMO DA ANÁLISE DE ERROS ===\")\n",
    "print(f\"Total de registros analisados: {len(y_val)}\")\n",
    "print(f\"Conversões reais: {y_val.sum()} ({y_val.mean():.2%})\")\n",
    "print(f\"Conversões previstas: {y_pred_val.sum()} ({y_pred_val.mean():.2%})\")\n",
    "print(f\"Falsos negativos: {fn} ({fn/(fn+tp):.2%} das conversões reais)\")\n",
    "print(f\"Falsos positivos: {fp} ({fp/(fp+tn):.2%} das não-conversões reais)\")\n",
    "print(f\"Precisão: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "print(f\"Todos os resultados foram salvos em: {results_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9abe7-3778-412e-bf01-544e136197ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
