{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8547f55-b54f-4b85-bc56-99473291dc0a",
   "metadata": {},
   "source": [
    "# Configurar MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129d24a-d990-449a-a1d0-f5a70d227dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import mlflow\n",
    "import subprocess\n",
    "\n",
    "# Definir diretório de rastreamento\n",
    "mlflow_dir = \"/home/jupyter/smart_ads/notebooks/mlruns\"\n",
    "trash_dir = os.path.join(mlflow_dir, \".trash\")\n",
    "\n",
    "# Limpar e recriar os diretórios\n",
    "if os.path.exists(mlflow_dir):\n",
    "    print(f\"Removendo diretório MLflow existente: {mlflow_dir}\")\n",
    "    shutil.rmtree(mlflow_dir, ignore_errors=True)\n",
    "\n",
    "# Criar diretórios necessários\n",
    "os.makedirs(mlflow_dir, exist_ok=True)\n",
    "os.makedirs(trash_dir, exist_ok=True)  # Criar diretório .trash explicitamente\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(f\"file://{mlflow_dir}\")\n",
    "print(f\"MLflow configurado para usar: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Nome do experimento\n",
    "EXPERIMENT_NAME = \"smart-ads-baseline\"\n",
    "\n",
    "# Verificar se o experimento já existe e removê-lo\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "try:\n",
    "    existing_exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if existing_exp:\n",
    "        print(f\"Removendo experimento existente: {EXPERIMENT_NAME}\")\n",
    "        client.delete_experiment(existing_exp.experiment_id)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao verificar experimento existente: {e}\")\n",
    "\n",
    "# Criar um novo experimento\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "print(f\"Criado novo experimento: {EXPERIMENT_NAME} (ID: {experiment_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3affba1-16f8-43c5-a395-236679ad4df6",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "Train a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45e38c-5fb2-4a0d-8e31-fdb324db0032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (precision_recall_fscore_support, roc_auc_score, \n",
    "                             average_precision_score, confusion_matrix, \n",
    "                             precision_recall_curve, PrecisionRecallDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import re\n",
    "import hashlib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.lightgbm\n",
    "import mlflow.xgboost\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Configuração mínima\n",
    "EXPERIMENT_NAME = \"smart-ads-baseline\"\n",
    "GENERATE_LEARNING_CURVES = False  # Desativado para economizar tempo\n",
    "\n",
    "# 2. Configuração do experimento MLflow\n",
    "try:\n",
    "    existing_exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if existing_exp:\n",
    "        EXPERIMENT_ID = existing_exp.experiment_id\n",
    "        print(f\"Usando experimento existente: {EXPERIMENT_NAME} (ID: {EXPERIMENT_ID})\")\n",
    "    else:\n",
    "        EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"Criado novo experimento: {EXPERIMENT_NAME} (ID: {EXPERIMENT_ID})\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao configurar experimento: {e}\")\n",
    "    EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# 3. Função para gerar hash do dataset (rastreabilidade)\n",
    "def get_data_hash(df):\n",
    "    return hashlib.md5(pd.util.hash_pandas_object(df).values).hexdigest()\n",
    "\n",
    "# 4. Carregar dados pré-processados\n",
    "DATA_PATH = \"datasets/split/\"\n",
    "print(\"Carregando datasets...\")\n",
    "train_df = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "val_df = pd.read_csv(f\"{DATA_PATH}validation.csv\")\n",
    "train_hash = get_data_hash(train_df)\n",
    "val_hash = get_data_hash(val_df)\n",
    "\n",
    "# 5. Sanitizar nomes das colunas\n",
    "def sanitize_column_names(df):\n",
    "    sanitized_columns = {}\n",
    "    for col in df.columns:\n",
    "        new_col = re.sub(r'[^\\w\\s]', '_', col)\n",
    "        new_col = re.sub(r'\\s+', '_', new_col)\n",
    "        if new_col in sanitized_columns.values():\n",
    "            new_col = f\"{new_col}_{df.columns.get_loc(col)}\"\n",
    "        sanitized_columns[col] = new_col\n",
    "    df.rename(columns=sanitized_columns, inplace=True)\n",
    "    return sanitized_columns\n",
    "\n",
    "# 6. Aplicar sanitização e preparar features/target\n",
    "column_mapping = sanitize_column_names(train_df)\n",
    "sanitize_column_names(val_df)\n",
    "target_col = 'target' if 'target' in train_df.columns else column_mapping.get('target', 'target')\n",
    "feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "# 7. Converter colunas inteiras para float\n",
    "print(\"Convertendo colunas inteiras para float...\")\n",
    "integer_columns = []\n",
    "for col in train_df.columns:\n",
    "    if pd.api.types.is_integer_dtype(train_df[col].dtype):\n",
    "        train_df[col] = train_df[col].astype(float)\n",
    "        val_df[col] = val_df[col].astype(float)\n",
    "        integer_columns.append(col)\n",
    "\n",
    "# 8. Criar cópias para X e y\n",
    "X_train = train_df[feature_cols].copy()\n",
    "y_train = train_df[target_col].copy()\n",
    "X_val = val_df[feature_cols].copy()\n",
    "y_val = val_df[target_col].copy()\n",
    "\n",
    "# 9. Verificar se ainda existem colunas inteiras\n",
    "int_cols_remaining = [col for col in X_train.columns if pd.api.types.is_integer_dtype(X_train[col].dtype)]\n",
    "if int_cols_remaining:\n",
    "    for col in int_cols_remaining:\n",
    "        X_train[col] = X_train[col].astype(float)\n",
    "        X_val[col] = X_val[col].astype(float)\n",
    "\n",
    "print(f\"Dados carregados - treino: {X_train.shape}, validação: {X_val.shape}\")\n",
    "print(f\"Taxa de conversão - treino: {y_train.mean():.4f}, validação: {y_val.mean():.4f}\")\n",
    "\n",
    "# 10. Criar diretório para artefatos temporários\n",
    "os.makedirs(\"/tmp/mlflow_artifacts\", exist_ok=True)\n",
    "\n",
    "# 11. Definir modelos com pesos balanceados\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced'),\n",
    "    'lightgbm': lgb.LGBMClassifier(random_state=42, n_jobs=-1, scale_pos_weight=50),\n",
    "    'xgboost': xgb.XGBClassifier(random_state=42, n_jobs=-1, scale_pos_weight=50)\n",
    "}\n",
    "\n",
    "# 12. Funções para visualizações\n",
    "def plot_confusion_matrix(y_true, y_pred, title, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Não Converteu', 'Converteu'],\n",
    "                yticklabels=['Não Converteu', 'Converteu'])\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    return cm\n",
    "\n",
    "def plot_prob_histogram(y_true, y_pred_proba, threshold, title, filename):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(y_pred_proba[y_true == 0], bins=50, alpha=0.5, color='blue', label='Classe 0 (Não converteu)')\n",
    "    plt.hist(y_pred_proba[y_true == 1], bins=50, alpha=0.5, color='red', label='Classe 1 (Converteu)')\n",
    "    plt.axvline(x=threshold, color='green', linestyle='--', label=f'Threshold: {threshold:.2f}')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Probabilidade prevista')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred_proba, title, filename):\n",
    "    display = PrecisionRecallDisplay.from_predictions(y_true, y_pred_proba, name=\"PR curve\")\n",
    "    _, ax = plt.subplots(figsize=(10, 6))\n",
    "    display.plot(ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def plot_learning_curve(model, X, y, model_name, filename=None):\n",
    "    \"\"\"Versão leve da curva de aprendizado - usa apenas 3 pontos e 3 folds\"\"\"\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    train_sizes = np.linspace(0.3, 1.0, 3)\n",
    "    cv = 3\n",
    "    print(f\"  Gerando curva de aprendizado leve para {model_name}...\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=cv, train_sizes=train_sizes, scoring='f1',\n",
    "        n_jobs=-1, shuffle=True, random_state=42\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Treino\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Validação\")\n",
    "    plt.title(f\"Curva de Aprendizado - {model_name}\")\n",
    "    plt.xlabel(\"Tamanho do conjunto de treino\")\n",
    "    plt.ylabel(\"F1-Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    return filename\n",
    "\n",
    "# 13. Treinar modelos\n",
    "print(\"\\nTreinando modelos base com pesos balanceados...\")\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    \n",
    "    # 14. Iniciar execução MLflow com tags simplificadas\n",
    "    with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=f\"{name}_baseline\") as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        # 15. Registrar tags simplificadas\n",
    "        mlflow.set_tags({\n",
    "            \"model_type\": name,\n",
    "            \"experiment_type\": \"baseline\",\n",
    "            \"class_balance\": \"weighted\",\n",
    "            \"train_data_hash\": train_hash,\n",
    "            \"val_data_hash\": val_hash,\n",
    "            \"data_path\": DATA_PATH,\n",
    "            \"feature_count\": len(feature_cols),\n",
    "            \"dataset_size\": len(X_train),\n",
    "            \"positive_ratio\": float(y_train.mean()),\n",
    "            \"converted_int_cols\": ','.join(integer_columns)\n",
    "        })\n",
    "        \n",
    "        # 16. Registrar parâmetros do modelo\n",
    "        mlflow.log_params(model.get_params())\n",
    "        \n",
    "        # 17. Treinar modelo com medição de tempo\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        mlflow.log_metric(\"training_time_seconds\", train_time)\n",
    "        \n",
    "        # 18. Fazer predições\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # 19. Testar diferentes thresholds para encontrar o melhor F1\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        best_precision = 0\n",
    "        best_recall = 0\n",
    "        \n",
    "        thresholds_to_test = np.arange(0.01, 0.5, 0.01)\n",
    "        f1_scores = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        \n",
    "        for threshold in thresholds_to_test:\n",
    "            y_pred_t = (y_pred_proba >= threshold).astype(int)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_t, average='binary')\n",
    "            \n",
    "            f1_scores.append(f1)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "                best_precision = precision\n",
    "                best_recall = recall\n",
    "        \n",
    "        # 20. Fazer predições finais com o melhor threshold\n",
    "        y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "        auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "        pr_auc = average_precision_score(y_val, y_pred_proba)\n",
    "        \n",
    "        # 21. Contar predições positivas\n",
    "        positive_count = y_pred.sum()\n",
    "        positive_pct = positive_count / len(y_pred) * 100\n",
    "        \n",
    "        # 22. Registrar métricas\n",
    "        mlflow.log_metric(\"precision\", best_precision)\n",
    "        mlflow.log_metric(\"recall\", best_recall)\n",
    "        mlflow.log_metric(\"f1\", best_f1)\n",
    "        mlflow.log_metric(\"threshold\", best_threshold)\n",
    "        mlflow.log_metric(\"auc\", auc_score)\n",
    "        mlflow.log_metric(\"pr_auc\", pr_auc)\n",
    "        mlflow.log_metric(\"positive_predictions\", positive_count)\n",
    "        mlflow.log_metric(\"positive_pct\", positive_pct)\n",
    "        \n",
    "        # 23. Gráfico de Threshold vs F1/Precision/Recall\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(thresholds_to_test, f1_scores, label='F1')\n",
    "        plt.plot(thresholds_to_test, precisions, label='Precision')\n",
    "        plt.plot(thresholds_to_test, recalls, label='Recall')\n",
    "        plt.axvline(x=best_threshold, color='r', linestyle='--', label=f'Melhor threshold: {best_threshold:.2f}')\n",
    "        plt.title(f'Efeito do threshold nas métricas - {name}')\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('Valor')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        threshold_fig_path = f\"/tmp/mlflow_artifacts/threshold_plot_{name}.png\"\n",
    "        plt.savefig(threshold_fig_path)\n",
    "        mlflow.log_artifact(threshold_fig_path)\n",
    "        plt.close()\n",
    "        \n",
    "        # 24. Plotar matriz de confusão\n",
    "        cm_fig_path = f\"/tmp/mlflow_artifacts/confusion_matrix_{name}.png\"\n",
    "        plot_confusion_matrix(y_val, y_pred, f'Matriz de Confusão - {name} (threshold={best_threshold:.2f})', cm_fig_path)\n",
    "        mlflow.log_artifact(cm_fig_path)\n",
    "        \n",
    "        # 25. Plotar histograma de probabilidades\n",
    "        hist_fig_path = f\"/tmp/mlflow_artifacts/prob_histogram_{name}.png\"\n",
    "        plot_prob_histogram(y_val, y_pred_proba, best_threshold, f'Distribuição de Probabilidades - {name}', hist_fig_path)\n",
    "        mlflow.log_artifact(hist_fig_path)\n",
    "        \n",
    "        # 26. Plotar curva precision-recall\n",
    "        pr_curve_path = f\"/tmp/mlflow_artifacts/pr_curve_{name}.png\"\n",
    "        plot_precision_recall_curve(y_val, y_pred_proba, f'Curva Precision-Recall - {name}', pr_curve_path)\n",
    "        mlflow.log_artifact(pr_curve_path)\n",
    "        \n",
    "        # 27. Gerar curva de aprendizado apenas se necessário\n",
    "        if GENERATE_LEARNING_CURVES:\n",
    "            learning_curve_path = f\"/tmp/mlflow_artifacts/learning_curve_{name}.png\"\n",
    "            plot_learning_curve(model, X_train, y_train, model_name=name.capitalize(), filename=learning_curve_path)\n",
    "            mlflow.log_artifact(learning_curve_path)\n",
    "        \n",
    "        # 28. Registrar feature importance (quando disponível) - tudo em uma única pasta\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Criar DataFrame de importância\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_cols,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            # Salvar tabela de importância\n",
    "            importance_path = f\"/tmp/mlflow_artifacts/feature_importance_{name}.csv\"\n",
    "            importance_df.to_csv(importance_path, index=False)\n",
    "            mlflow.log_artifact(importance_path)\n",
    "            \n",
    "            # Plotar top 20 features\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            top_features = importance_df.head(20)\n",
    "            sns.barplot(x='importance', y='feature', data=top_features)\n",
    "            plt.title(f'Top 20 Features - {name}')\n",
    "            plt.tight_layout()\n",
    "            importance_fig_path = f\"/tmp/mlflow_artifacts/feature_importance_plot_{name}.png\"\n",
    "            plt.savefig(importance_fig_path)\n",
    "            mlflow.log_artifact(importance_fig_path)\n",
    "            plt.close()\n",
    "        \n",
    "        # 29. Preparar exemplo de entrada para assinatura e registrar modelo\n",
    "        input_example = X_train.iloc[:5].copy().astype(float)\n",
    "        \n",
    "        if name == 'random_forest':\n",
    "            mlflow.sklearn.log_model(model, name, input_example=input_example)\n",
    "        elif name == 'lightgbm':\n",
    "            mlflow.lightgbm.log_model(model, name, input_example=input_example)\n",
    "        elif name == 'xgboost':\n",
    "            mlflow.xgboost.log_model(model, name, input_example=input_example, model_format=\"json\")\n",
    "        \n",
    "        model_uri = f\"runs:/{run_id}/{name}\"\n",
    "        print(f\"  Modelo {name} salvo em: {run.info.artifact_uri}/{name}\")\n",
    "        print(f\"  URI do modelo para carregamento: {model_uri}\")\n",
    "        \n",
    "        # 30. Armazenar resultados no dicionário local\n",
    "        results[f\"{name}_precision\"] = float(best_precision)\n",
    "        results[f\"{name}_recall\"] = float(best_recall) \n",
    "        results[f\"{name}_f1\"] = float(best_f1)\n",
    "        results[f\"{name}_threshold\"] = float(best_threshold)\n",
    "        results[f\"{name}_auc\"] = float(auc_score)\n",
    "        results[f\"{name}_pr_auc\"] = float(pr_auc)\n",
    "        results[f\"{name}_model_uri\"] = model_uri\n",
    "        \n",
    "        print(f\"  {name} - F1: {best_f1:.4f}, PR-AUC: {pr_auc:.4f}, Threshold: {best_threshold:.4f}\")\n",
    "        print(f\"  {name} - Precision: {best_precision:.4f}, Recall: {best_recall:.4f}\")\n",
    "        print(f\"  {name} - Predições positivas: {positive_count} ({positive_pct:.2f}%)\")\n",
    "\n",
    "# 31. Mostrar resultados finais\n",
    "print(\"\\nResultados dos modelos com threshold otimizado:\")\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(f\"  F1: {results[f'{model_name}_f1']:.4f}\")\n",
    "    print(f\"  Precisão: {results[f'{model_name}_precision']:.4f}\")\n",
    "    print(f\"  Recall: {results[f'{model_name}_recall']:.4f}\")\n",
    "    print(f\"  Threshold: {results[f'{model_name}_threshold']:.4f}\")\n",
    "    print(f\"  AUC: {results[f'{model_name}_auc']:.4f}\")\n",
    "    print(f\"  PR-AUC: {results[f'{model_name}_pr_auc']:.4f}\")\n",
    "    print(f\"  Model URI: {results[f'{model_name}_model_uri']}\")\n",
    "\n",
    "print(\"\\nModelos treinados e registrados no MLflow com rastreabilidade.\")\n",
    "print(\"\\nPara carregar um modelo específico em código futuro, use:\")\n",
    "for model_name in models.keys():\n",
    "    model_type = \"sklearn\" if model_name == \"random_forest\" else model_name\n",
    "    print(f\"\"\"\n",
    "# Carregar modelo {model_name}:\n",
    "import mlflow.{model_type}\n",
    "model_{model_name} = mlflow.{model_type}.load_model(\"{results[f'{model_name}_model_uri']}\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef93b0-9491-4f97-a555-b6f303f44773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
