# Guia do Projeto - Pipeline de Lead Scoring DevClub

## Contexto do Projeto
Este projeto visa replicar um pipeline de treinamento para lead scoring, baseado em um modelo de Machine Learning desenvolvido e validado em ambiente de notebook (Google Colab). O modelo foi treinado com dados histÃ³ricos de leads e alunos da DevClub, para priorizaÃ§Ã£o de budget em campanhas de marketing.

## Estrutura de Arquivos

### Arquivos do Modelo na pasta arquivos_modelo
- Arquivos .pkl : Modelos treinados
- `model_metadata*.json`: Metadados dos modelos (hiperparÃ¢metros, mÃ©tricas de performance)
- `features_ordenadas*.json`: Lista ordenada das features esperadas pelos modelos
- `feature_registry*.json`: Registro detalhado das features
- `smart_ads_devclub_eda_v3.py`: Script Python extraÃ­do do notebook original

### Dados de Treinamento
- Pasta: `data/devclub/LF + ALUNOS/`
- 30 arquivos utilizados no treinamento
- `Lead Score LF24.xlsx`: Template de entrada em produÃ§Ã£o (aba: LF Pesquisa)

### Estrutura do CÃ³digo V2
```
V2/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/          # Componentes de prÃ©-processamento
â”‚   â”œâ”€â”€ features/      # Engenharia de features
â”‚   â”œâ”€â”€ model/         # AplicaÃ§Ã£o do modelo
â”‚   â””â”€â”€ pipeline.py    # Pipeline principal
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py  # Testes de integraÃ§Ã£o
â””â”€â”€ main.py            # Script de execuÃ§Ã£o
```

## ğŸ”´ METODOLOGIA DE DEBUGGING

### EstratÃ©gia: ComparaÃ§Ã£o via Prints
1. **Identificar** prints no script de treino (smart_ads_devclub_eda_v3.py)
2. **Replicar** prints idÃªnticos no pipeline produÃ§Ã£o
3. **Comparar** outputs treino vs produÃ§Ã£o
4. **Corrigir** divergÃªncias uma etapa por vez
5. **Validar** outputs idÃªnticos antes de prosseguir

**Fluxo:** Print â†’ Comparar â†’ Corrigir â†’ Validar â†’ PrÃ³xima Etapa

## Status Atual

### âœ… Implementado
- Pipeline modular completo em V2/src/
- Testes de validaÃ§Ã£o em tests/
- 4 modelos treinados com mÃ©tricas validadas

### ğŸš¨ Problemas Identificados
1. **Features UTM:** valores diferentes do esperado
2. **Ordem features:** `pd.get_dummies()` produz ordem alfabÃ©tica vs esperada
3. **Features artificiais:** handcoded sem correspondÃªncia no treino
4. **ValidaÃ§Ã£o falhando:** 0/4 modelos passam nos testes de compatibilidade

## PrincÃ­pios Fundamentais

### Regras CrÃ­ticas
- **LÃ³gica IDÃŠNTICA** ao ambiente de treinamento
- **SEM soluÃ§Ãµes handcoded** - apenas debug das diferenÃ§as
- **Uma correÃ§Ã£o por vez** - sempre com validaÃ§Ã£o
- **Notebook Colab** Ã© a fonte da verdade (nÃ£o editar .py local)

### AlteraÃ§Ãµes Permitidas
- Remover cÃ³digo do Colab (upload, visualizaÃ§Ãµes)
- Modularizar mantendo lÃ³gica idÃªntica
- Adicionar logging e tratamento de erros

### AlteraÃ§Ãµes que Requerem AprovaÃ§Ã£o
- Ordem de operaÃ§Ãµes ou listas
- Nomes de colunas ou mapeamentos
- Tratamento de valores nulos
- FÃ³rmulas ou cÃ¡lculos

## Objetivo Imediato
Debugar sistematicamente o pipeline via prints para identificar e corrigir as divergÃªncias entre treino e produÃ§Ã£o, garantindo que as features sejam geradas identicamente.