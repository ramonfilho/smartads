# Guia do Projeto - Pipeline ConfigurÃ¡vel de Lead Scoring

## Contexto do Projeto
Este projeto visa criar um sistema de pipelines configurÃ¡veis para lead scoring, baseado em modelos de Machine Learning validados. O objetivo Ã© evoluir de um sistema single-client (DevClub) para uma arquitetura multi-client reutilizÃ¡vel, mantendo toda a lÃ³gica de negÃ³cio jÃ¡ validada.

## Fase Atual: ProfissionalizaÃ§Ã£o (FASE 2)
**PrÃ©-requisito:** Cliente DevClub validado e pagando pela soluÃ§Ã£o

### Objetivos da FASE 2
1. **Extrair componentes reutilizÃ¡veis** do notebook/pipeline atual
2. **Criar arquitetura configurÃ¡vel** por cliente
3. **Separar pipelines de treino e produÃ§Ã£o** mantendo componentes compartilhados
4. **Implementar MLflow** para tracking de experimentos
5. **Preparar base** para escala futura (FASE 3: MLOps completo)

## Nova Estrutura de Arquivos Proposta
src/
â”œâ”€â”€ investigation/
â”‚   â”œâ”€â”€ data_profiling.py      # AnÃ¡lise exploratÃ³ria de dados
â”‚   â”œâ”€â”€ column_analysis.py     # AnÃ¡lise de colunas (tipos, valores, missing)
â”‚   â”œâ”€â”€ category_discovery.py  # Descoberta de categorias Ãºnicas
â”‚   â””â”€â”€ config_generator.py    # Gera configs/cliente.yaml baseado nas investigaÃ§Ãµes
â”œâ”€â”€ data_processing/
â”‚   â”œâ”€â”€ ingestion.py           # ConsolidaÃ§Ã£o de datasets
â”‚   â”œâ”€â”€ cleaning.py            # Limpeza e tratamento
â”‚   â”œâ”€â”€ matching.py            # Matching email/telefone
â”‚   â””â”€â”€ feature_engineering.py # CriaÃ§Ã£o de features
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_pipeline.py      # Pipeline completo de treino
â”‚   â””â”€â”€ model_training.py      # LÃ³gica de treino/avaliaÃ§Ã£o
â”œâ”€â”€ serving/
â”‚   â”œâ”€â”€ predict_pipeline.py    # Pipeline de prediÃ§Ã£o
â”‚   â””â”€â”€ model_serving.py       # Carregamento e prediÃ§Ã£o
â””â”€â”€ utils/
    â”œâ”€â”€ config_loader.py       # Carregamento de configuraÃ§Ãµes
    â””â”€â”€ mlflow_utils.py        # Tracking e logging
configs/
â”œâ”€â”€ devclub.yaml               # ConfiguraÃ§Ã£o especÃ­fica DevClub
â””â”€â”€ template.yaml              # Template para novos clientes
data/
â”œâ”€â”€ devclub/                   # Dados especÃ­ficos DevClub
â””â”€â”€ [cliente2]/                # Dados do prÃ³ximo cliente

## ğŸ”´ METODOLOGIA DE REFATORAÃ‡ÃƒO

### EstratÃ©gia: MigraÃ§Ã£o Incremental - ZERO QUEBRA DE FUNCIONALIDADE

**PRINCÃPIO FUNDAMENTAL:** A funcionalidade atual (DevClub) deve continuar 100% operacional durante toda a refatoraÃ§Ã£o.

**FLUXO DE TRABALHO:**
1. **Validar entendimento** da estrutura atual
2. **Extrair UM componente** por vez
3. **Testar compatibilidade** com pipeline atual
4. **Confirmar resultados idÃªnticos** antes de prosseguir
5. **AvanÃ§ar para prÃ³ximo componente**

### ğŸ”§ PRINCÃPIOS FUNDAMENTAIS DE IMPLEMENTAÃ‡ÃƒO

#### 1. **CONFIGURAÃ‡ÃƒO PRIMEIRO**
**TODO cÃ³digo deve ser configurÃ¡vel desde o inÃ­cio.**

- âŒ **NUNCA** hardcodar valores especÃ­ficos do DevClub no cÃ³digo
- âœ… **SEMPRE** receber parÃ¢metros via `configs/cliente.yaml`
- âœ… FunÃ§Ãµes recebem argumentos explÃ­citos, nÃ£o assumem defaults especÃ­ficos
- âœ… CÃ³digo deve funcionar para **qualquer cliente** apenas trocando a config

**Exemplo:**
```python
# âŒ ERRADO - Hardcoded
def filter_sheets(df):
    termos_manter = ["Pesquisa", "Vendas", "tmb"]  # EspecÃ­fico DevClub!

# âœ… CORRETO - ConfigurÃ¡vel
def filter_sheets(df, termos_manter: List[str]):
    # termos_manter vem de configs/devclub.yaml
```

#### 2. **GRANULARIDADE EXTREMA**
**TODA funcionalidade deve ser dividida em sub-etapas mÃ­nimas verificÃ¡veis.**

- NÃ£o sÃ³ `ingestion.py`, mas **TUDO**: `cleaning`, `matching`, `feature_engineering`, `encoding`
- **Uma funÃ§Ã£o pequena por vez**
- Cada funÃ§Ã£o deve ser:
  - âœ… TestÃ¡vel isoladamente
  - âœ… ValidÃ¡vel contra o notebook (outputs idÃªnticos)
  - âœ… AprovÃ¡vel antes de prosseguir para a prÃ³xima

**Exemplo de granularidade:**
```
âŒ ERRADO: Criar ingestion.py completo (400 linhas) de uma vez

âœ… CORRETO:
  1.1 read_excel_files() â†’ validar â†’ aprovar
  1.2 remove_duplicates_per_sheet() â†’ validar â†’ aprovar
  1.3 filter_sheets() â†’ validar â†’ aprovar
  1.4 consolidate_sheets() â†’ validar â†’ aprovar
  1.5 filter_by_date() â†’ validar â†’ aprovar
```

### Regras CrÃ­ticas
- **FUNCIONALIDADE PRIMEIRO** - Pipeline DevClub deve continuar funcionando
- **UM COMPONENTE POR VEZ** - Extrair/refatorar apenas um mÃ³dulo por sessÃ£o
- **SUB-ETAPAS GRANULARES** - Dividir cada mÃ³dulo em funÃ§Ãµes mÃ­nimas verificÃ¡veis
- **TESTES DE REGRESSÃƒO** - Comparar outputs antes/depois de cada mudanÃ§a
- **CONFIGURAÃ‡ÃƒO DESDE O INÃCIO** - Nada hardcoded, tudo vem de configs
- **VALIDAÃ‡ÃƒO CONTÃNUA** - Aprovar cada etapa antes de prosseguir

### Componentes a Extrair (Ordem Correta)

**Nota:** Sub-etapas granulares sÃ£o descobertas e documentadas Ã  medida que avanÃ§amos sessÃ£o por sessÃ£o.

#### **ATUAL: 1. data_processing/ingestion.py** - ConsolidaÃ§Ã£o de datasets
Sub-etapas granulares identificadas:
- 1.1 `read_excel_files()` - Leitura de mÃºltiplos arquivos Excel
- 1.2 `remove_duplicates_per_sheet()` - RemoÃ§Ã£o de duplicatas por aba
- 1.3 `filter_sheets()` - Filtragem de abas por critÃ©rios configurÃ¡veis
- 1.4 `consolidate_sheets()` - ConcatenaÃ§Ã£o em DataFrame Ãºnico
- 1.5 `filter_by_date()` - Filtragem temporal opcional

#### PrÃ³ximos mÃ³dulos (sub-etapas a descobrir):
2. **data_processing/cleaning.py** - Limpeza e tratamento bÃ¡sico
3. **data_processing/matching.py** - Matching e criaÃ§Ã£o de targets
4. **data_processing/feature_engineering.py** - CriaÃ§Ã£o de features
5. **training/model_training.py** - Treino e avaliaÃ§Ã£o
6. **serving/model_serving.py** - PrediÃ§Ã£o
7. **investigation/** - MÃ³dulos de investigaÃ§Ã£o (geram configs)
8. **ConfiguraÃ§Ã£o cliente-especÃ­fica** - Baseada nas investigaÃ§Ãµes

### Protocolo de ValidaÃ§Ã£o (CRÃTICO)

**Fluxo obrigatÃ³rio para cada sub-etapa:**

1. **Criar funÃ§Ã£o** configurÃ¡vel (sem valores hardcoded)
2. **Adicionar parÃ¢metros necessÃ¡rios** ao `configs/devclub.yaml`
3. **Teste unitÃ¡rio** - Verificar que a funÃ§Ã£o executa sem erros isoladamente
4. **IntegraÃ§Ã£o ao pipeline** - Adicionar a funÃ§Ã£o ao pipeline de treino (`train_pipeline.py`)
5. **Teste integrado** - Executar pipeline completo e gerar output
6. **PARAR E AGUARDAR** - Compartilhar output com usuÃ¡rio
7. **UsuÃ¡rio valida** - Comparar output com notebook original (Ãºnica fonte da verdade)
8. **AprovaÃ§Ã£o explÃ­cita** - SÃ³ avanÃ§ar apÃ³s confirmaÃ§Ã£o do usuÃ¡rio

**Detalhamento da IntegraÃ§Ã£o ao Pipeline:**
- Criar/atualizar script que reproduz o notebook cÃ©lula por cÃ©lula
- Cada nova funÃ§Ã£o aprovada Ã© adicionada ao script de integraÃ§Ã£o
- Script deve usar `configs/devclub.yaml` para todos os parÃ¢metros
- Output do script deve ser comparÃ¡vel ao output do notebook

**REGRA CRÃTICA:**
- âŒ **NUNCA** avanÃ§ar para a prÃ³xima funÃ§Ã£o sem aprovaÃ§Ã£o do usuÃ¡rio
- âŒ **NUNCA** assumir que o output estÃ¡ correto
- âœ… **SEMPRE** testar isolado (unitÃ¡rio) E integrado (pipeline completo)
- âœ… **SEMPRE** esperar confirmaÃ§Ã£o: "estÃ¡ correto, pode prosseguir"

### ValidaÃ§Ãµes ObrigatÃ³rias (Feitas pelo UsuÃ¡rio)
- **Shapes de dataframes** idÃªnticos em cada etapa
- **Valores** idÃªnticos ou equivalentes
- **Estrutura de dados** mantida
- **LÃ³gica de negÃ³cio** preservada

## DiferenÃ§as entre Pipelines

### Pipeline de Treino
- **Input:** MÃºltiplos arquivos histÃ³ricos
- **Processamento:** ConsolidaÃ§Ã£o + Matching + Feature Engineering + Treino
- **Output:** Modelo salvo + MÃ©tricas + Artefatos MLflow

### Pipeline de ProduÃ§Ã£o  
- **Input:** Arquivo Ãºnico de leads
- **Processamento:** Feature Engineering + PrediÃ§Ã£o
- **Output:** Scores de leads

### Componentes Compartilhados
- Limpeza de dados
- Feature engineering
- ValidaÃ§Ãµes de entrada
- Tratamento de categorias nÃ£o vistas

## ğŸ” MÃ³dulos de InvestigaÃ§Ã£o â†’ ConfiguraÃ§Ã£o

### Conceito Fundamental
**As configuraÃ§Ãµes de um cliente sÃ£o DESCOBERTAS, nÃ£o inventadas.**

O fluxo para onboarding de um novo cliente Ã©:
```
dados_cliente â†’ investigation/ â†’ configs/cliente.yaml â†’ pipeline usa essa config
```

### Responsabilidade dos MÃ³dulos de InvestigaÃ§Ã£o
Extrair do notebook DevClub as **anÃ¡lises exploratÃ³rias** que foram necessÃ¡rias para descobrir:
- Quais colunas usar/descartar
- Quais tipos de limpeza aplicar (encoding, missing values, outliers)
- Quais categorias Ãºnicas existem em cada coluna categÃ³rica
- Quais features criar
- Quais thresholds e parÃ¢metros usar
- DistribuiÃ§Ãµes e estatÃ­sticas relevantes

### MÃ³dulos a Criar
1. **data_profiling.py** - Overview geral dos dados (shape, tipos, missing %)
2. **column_analysis.py** - AnÃ¡lise detalhada coluna por coluna
3. **category_discovery.py** - Mapeamento de todas as categorias Ãºnicas
4. **config_generator.py** - Converte outputs das investigaÃ§Ãµes em `configs/cliente.yaml`

### Objetivo
Quando um novo cliente chegar, rodar:
```bash
python src/investigation/run_investigation.py --client novo_cliente
```
E obter automaticamente (ou semi-automaticamente) o arquivo `configs/novo_cliente.yaml` pronto para uso nos pipelines.