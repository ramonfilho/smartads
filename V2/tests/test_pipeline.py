"""
Teste de integra√ß√£o do pipeline completo.
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.pipeline import LeadScoringPipeline
import pandas as pd
import json


def test_model_configuration(model_name: str, com_utm: bool, versao: str, expected_features: int, features_file: str, test_file: str):
    """
    Testa uma configura√ß√£o espec√≠fica do pipeline com valida√ß√£o detalhada de features.

    Args:
        model_name: Nome do modelo para identifica√ß√£o
        com_utm: Se deve manter features UTM
        versao: "v1" ou "v2"
        expected_features: N√∫mero esperado de features
        features_file: Caminho para arquivo JSON com features esperadas
        test_file: Caminho para arquivo de teste
    """
    print(f"\n{'='*60}")
    print(f"üî¨ TESTANDO: {model_name}")
    print(f"   Par√¢metros: com_utm={com_utm}, versao={versao}")
    print(f"   Features esperadas: {expected_features}")
    print(f"{'='*60}")

    # Carregar features esperadas
    try:
        with open(features_file, 'r', encoding='utf-8') as f:
            expected_features_data = json.load(f)
            expected_feature_names = expected_features_data['feature_names']
    except Exception as e:
        print(f"‚ùå ERRO ao carregar features esperadas: {str(e)}")
        return False, None

    # Criar pipeline com configura√ß√£o fixa (V1 com UTM)
    pipeline = LeadScoringPipeline()

    try:
        # Executar pipeline
        result = pipeline.run(test_file)

        # Obter features produzidas
        actual_feature_names = list(result.columns)
        actual_features = len(actual_feature_names)

        print(f"\nüìä RESULTADO:")
        print(f"   Features produzidas: {actual_features}")
        print(f"   Features esperadas: {expected_features}")

        # 1. Verificar n√∫mero de features
        features_count_ok = actual_features == expected_features
        if features_count_ok:
            print(f"   ‚úÖ Quantidade de features: CORRETO")
        else:
            print(f"   ‚ùå Quantidade de features: INCORRETO (diff: {actual_features - expected_features:+d})")

        # 2. Verificar nomes das features (ordem e conte√∫do)
        features_names_ok = actual_feature_names == expected_feature_names
        if features_names_ok:
            print(f"   ‚úÖ Nomes e ordem das features: CORRETO")
        else:
            print(f"   ‚ùå Nomes e ordem das features: INCORRETO")

            # Mostrar diferen√ßas detalhadas
            missing_features = set(expected_feature_names) - set(actual_feature_names)
            extra_features = set(actual_feature_names) - set(expected_feature_names)

            # DEBUG: Confirmar que os conjuntos s√£o id√™nticos
            conjuntos_identicos = missing_features == set() and extra_features == set()
            print(f"   üîç CONJUNTOS DE FEATURES ID√äNTICOS: {'‚úÖ SIM' if conjuntos_identicos else '‚ùå N√ÉO'}")

            if missing_features:
                print(f"   üîç Features FALTANDO ({len(missing_features)}):")
                for feat in sorted(missing_features)[:10]:  # Mostrar primeiras 10
                    print(f"      - {feat}")
                if len(missing_features) > 10:
                    print(f"      ... e mais {len(missing_features)-10} features")

            if extra_features:
                print(f"   üîç Features EXTRAS ({len(extra_features)}):")
                for feat in sorted(extra_features)[:10]:  # Mostrar primeiras 10
                    print(f"      + {feat}")
                if len(extra_features) > 10:
                    print(f"      ... e mais {len(extra_features)-10} features")

            # Mostrar compara√ß√£o ordenada se mesmo conjunto mas ordem diferente
            if not missing_features and not extra_features:
                print(f"   üîç MESMAS FEATURES, ORDEM DIFERENTE:")
                print(f"   Verificando todas as {len(actual_feature_names)} features:")

                # Encontrar primeira diverg√™ncia
                primeira_divergencia = None
                for i in range(len(actual_feature_names)):
                    esperada = expected_feature_names[i] if i < len(expected_feature_names) else "N/A"
                    atual = actual_feature_names[i] if i < len(actual_feature_names) else "N/A"
                    if atual != esperada:
                        primeira_divergencia = i
                        break

                if primeira_divergencia is None:
                    print(f"      ‚úÖ TODAS AS FEATURES EST√ÉO EM ORDEM CORRETA!")
                else:
                    print(f"      ‚ùå Primeira diverg√™ncia na posi√ß√£o {primeira_divergencia+1}")
                    print(f"      Compara√ß√£o ao redor da diverg√™ncia:")
                    start = max(0, primeira_divergencia - 2)
                    end = min(len(actual_feature_names), primeira_divergencia + 8)

                    for i in range(start, end):
                        esperada = expected_feature_names[i] if i < len(expected_feature_names) else "N/A"
                        atual = actual_feature_names[i] if i < len(actual_feature_names) else "N/A"
                        match = "‚úì" if atual == esperada else "‚úó"
                        destaque = " <<<" if i == primeira_divergencia else ""
                        print(f"      {i+1:2d}. {match} {atual[:50]:<52} | {esperada[:50]}{destaque}")

        # 3. Verificar tipos de dados das features
        print(f"\nüîç TIPOS DE DADOS:")
        type_issues = []
        for i, feature in enumerate(actual_feature_names[:10]):  # Verificar primeiras 10
            dtype = str(result[feature].dtype)
            null_count = result[feature].isnull().sum()
            print(f"   {feature}: {dtype} (nulls: {null_count})")

            # Verificar se h√° problemas √≥bvios
            if dtype == 'object' and feature not in ['nome_comprimento', 'dia_semana']:
                # Features categ√≥ricas codificadas deveriam ser num√©ricas
                if any(keyword in feature for keyword in ['_N_o', '_Sim', '_Feminino', '_Masculino']):
                    type_issues.append(f"{feature} deveria ser num√©rico, mas √© {dtype}")

        if len(actual_feature_names) > 10:
            print(f"   ... e mais {len(actual_feature_names)-10} features")

        if type_issues:
            print(f"   ‚ö†Ô∏è  Poss√≠veis problemas de tipo:")
            for issue in type_issues[:3]:
                print(f"      - {issue}")

        # Status final
        status = features_count_ok and features_names_ok
        if status:
            print(f"\n   üéâ SUCESSO COMPLETO: Features exatamente como esperadas!")
        else:
            print(f"\n   ‚ùå FALHA: Verifique as diferen√ßas acima")

        return status, result

    except Exception as e:
        print(f"‚ùå ERRO durante execu√ß√£o: {str(e)}")
        return False, None


def test_pipeline():
    """Testa o pipeline completo com as 4 configura√ß√µes de modelos."""

    print("=== TESTE DO PIPELINE COMPLETO ===\n")

    # Arquivo de teste conforme especificado no PROJECT_GUIDE.md
    test_file = '../Lead score LF 24.xlsx'

    # Verificar se arquivo existe
    if not os.path.exists(test_file):
        print(f"‚ùå Arquivo n√£o encontrado: {test_file}")
        print("Certifique-se de que o arquivo de teste est√° no local correto.")
        return None

    # Listar arquivos de modelos dispon√≠veis
    import glob
    model_files = glob.glob("../arquivos_modelo/features_ordenadas_*.json")

    if not model_files:
        print("‚ùå Nenhum arquivo de modelo encontrado em ../arquivos_modelo/")
        return None

    print(f"üìÅ Arquivos de modelo encontrados: {len(model_files)}")
    for i, file in enumerate(model_files, 1):
        filename = file.split('/')[-1]
        print(f"  {i}. {filename}")

    # Usar o primeiro arquivo encontrado
    features_file = model_files[0]
    print(f"\nüéØ Usando arquivo: {features_file.split('/')[-1]}")

    # Carregar features esperadas
    try:
        with open(features_file, 'r', encoding='utf-8') as f:
            expected_features_data = json.load(f)
            expected_feature_names = expected_features_data['feature_names']
            expected_features = len(expected_feature_names)
    except Exception as e:
        print(f"‚ùå ERRO ao carregar features esperadas: {str(e)}")
        return None

    # Configura√ß√£o √∫nica - V1 com UTM
    test_configs = [
        {
            "model_name": "V1 DEVCLUB com UTM",
            "expected_features": expected_features,
            "features_file": features_file
        }
    ]

    # Executar todos os testes
    results = []
    result_dfs = []

    for config in test_configs:
        success, result_df = test_model_configuration(
            config["model_name"], True, "v1",
            config["expected_features"], config["features_file"], test_file
        )
        results.append((config["model_name"], success))
        if result_df is not None:
            result_dfs.append((config["model_name"], result_df))

    # Resumo final dos testes
    print(f"\n{'='*60}")
    print("üìã RESUMO DOS TESTES")
    print(f"{'='*60}")

    for model_name, success in results:
        status_icon = "‚úÖ" if success else "‚ùå"
        print(f"{status_icon} {model_name}")

    total_success = sum(1 for _, success in results if success)
    total_tests = len(results)

    print(f"\nüéØ RESULTADO GERAL: {total_success}/{total_tests} testes aprovados")

    if total_success == total_tests:
        print("üéâ TODOS OS TESTES PASSARAM! Pipeline configurado corretamente.")
    else:
        print("‚ö†Ô∏è  ALGUNS TESTES FALHARAM. Verifique a configura√ß√£o do pipeline.")

    # Retornar o primeiro resultado para compatibilidade
    return result_dfs[0][1] if result_dfs else None


if __name__ == "__main__":
    df_result = test_pipeline()
    if df_result is not None:
        print(f"\nüìä Pipeline testado com sucesso!")
        print(f"DataFrame final: {len(df_result)} registros, {len(df_result.columns)} colunas")
    else:
        print("\n‚ùå Teste falhou - verifique o caminho do arquivo")
        sys.exit(1)