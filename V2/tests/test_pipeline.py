"""
Teste de integra√ß√£o do pipeline completo.
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.pipeline import LeadScoringPipeline
import pandas as pd


def test_pipeline():
    """Testa o pipeline completo com dados reais."""

    print("=== TESTE DO PIPELINE COMPLETO ===\n")

    # Inicializar pipeline
    pipeline = LeadScoringPipeline()

    # Arquivo de teste conforme especificado no PROJECT_GUIDE.md
    # Usar o arquivo correto: Lead score LF 24.xlsx (com espa√ßos)
    test_file = '../../data/devclub/LF + ALUNOS/Lead score LF 24.xlsx'

    # Verificar se arquivo existe
    if not os.path.exists(test_file):
        print(f"‚ùå Arquivo n√£o encontrado: {test_file}")
        print("Certifique-se de que o arquivo de teste est√° no local correto.")
        return None

    # Carregar dados originais da aba correta para compara√ß√£o
    original_df = pd.read_excel(test_file, sheet_name='LF Pesquisa')
    print(f"Dados originais (aba 'LF Pesquisa'): {len(original_df)} linhas, {len(original_df.columns)} colunas")

    # Executar pipeline - ele deve usar a aba 'LF Pesquisa' por padr√£o
    result = pipeline.run(test_file)

    # Verificar resultados b√°sicos
    print(f"\nüìä Resultados do Pipeline:")
    print(f"   - Linhas originais: {len(original_df)}")
    print(f"   - Linhas processadas: {len(result)}")
    print(f"   - Duplicatas removidas: {len(original_df) - len(result)}")
    print(f"   - Colunas originais: {len(original_df.columns)}")
    print(f"   - Colunas finais: {len(result.columns)}")
    print(f"   - Varia√ß√£o de colunas: {len(result.columns) - len(original_df.columns):+d}")

    # Identificar colunas que foram removidas e adicionadas (c√°lculo real)
    original_cols = set(original_df.columns)
    final_cols = set(result.columns)

    removed_cols = original_cols - final_cols
    added_cols = final_cols - original_cols

    print(f"\nüîç An√°lise Real das Colunas:")
    print(f"   - Colunas removidas: {len(removed_cols)}")
    if removed_cols:
        print(f"     ‚Ä¢ {', '.join(sorted(removed_cols))}")

    print(f"   - Colunas adicionadas: {len(added_cols)}")
    if added_cols:
        print(f"     ‚Ä¢ {', '.join(sorted(added_cols))}")

    print(f"   - Resultado l√≠quido: {len(added_cols) - len(removed_cols):+d} colunas")

    # Verificar que duplicatas foram processadas
    assert len(result) <= len(original_df), "Pipeline n√£o deveria adicionar linhas"
    print(f"   - N√∫mero de linhas consistente (n√£o foram adicionadas linhas)")

    # Verificar que encoding expandiu as features categ√≥ricas
    assert len(result.columns) > len(original_df.columns), "One-hot encoding deveria adicionar colunas"
    print(f"   - Colunas expandidas pelo encoding conforme esperado (+{len(result.columns) - len(original_df.columns)})")

    # Verificar que a coluna de faixa salarial foi preservada (√© uma feature, n√£o resultado)
    if 'Atualmente, qual a sua faixa salarial?' in original_df.columns:
        assert 'Atualmente, qual a sua faixa salarial?' in result.columns, \
            "‚ùå Coluna de faixa salarial foi removida incorretamente!"
        print(f"   - Coluna de faixa salarial preservada (√© uma feature)")

    print(f"\n‚úÖ Pipeline executado com sucesso!")
    return result


if __name__ == "__main__":
    df_result = test_pipeline()
    if df_result is not None:
        print(f"\nüìä Pipeline testado com sucesso!")
        print(f"DataFrame final: {len(df_result)} registros, {len(df_result.columns)} colunas")
    else:
        print("\n‚ùå Teste falhou - verifique o caminho do arquivo")
        sys.exit(1)