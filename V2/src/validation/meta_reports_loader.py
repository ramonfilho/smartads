"""
M√≥dulo para carregar dados dos relat√≥rios Excel exportados do Meta Ads.

L√™ os arquivos de campanhas, conjuntos de an√∫ncios e an√∫ncios exportados
manualmente do Meta Ads Manager.
"""

import os
import sys
import logging
import re
import unicodedata
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import pandas as pd
from glob import glob

logger = logging.getLogger(__name__)


def normalize_unicode(text: str) -> str:
    """
    Normaliza texto Unicode para NFC (composed form).

    Isso resolve problemas onde "√∫" pode estar como:
    - NFC: "√∫" (1 caractere)
    - NFD: "u" + "¬¥" (2 caracteres: base + combining accent)
    """
    return unicodedata.normalize('NFC', text)


def normalize_whitespace(text: str) -> str:
    """
    Normaliza espa√ßos em branco em nomes para matching consistente.

    - Colapsa m√∫ltiplos espa√ßos em um √∫nico espa√ßo
    - Remove espa√ßos no in√≠cio e fim

    Args:
        text: Texto a normalizar

    Returns:
        Texto normalizado
    """
    if pd.isna(text):
        return text
    # Colapsar m√∫ltiplos espa√ßos em um √∫nico
    normalized = re.sub(r'\s+', ' ', str(text))
    # Remover espa√ßos no in√≠cio e fim
    return normalized.strip()


class MetaReportsLoader:
    """
    Carrega dados dos relat√≥rios Excel do Meta Ads.

    Estrutura esperada dos arquivos:
    - Ads---[Conta]-Campanhas-[per√≠odo].xlsx
    - Ads---[Conta]-Conjuntos-de-an√∫ncios-[per√≠odo].xlsx
    - Ads---[Conta]-An√∫ncios-[per√≠odo].xlsx
    """

    def __init__(self, reports_dir: str):
        """
        Inicializa o loader.

        Args:
            reports_dir: Diret√≥rio contendo os relat√≥rios Excel
        """
        self.reports_dir = Path(reports_dir)
        if not self.reports_dir.exists():
            raise FileNotFoundError(f"Diret√≥rio de relat√≥rios n√£o encontrado: {reports_dir}")

    def load_all_reports(
        self,
        start_date: str,
        end_date: str
    ) -> Dict[str, pd.DataFrame]:
        """
        Carrega todos os relat√≥rios (campanhas, adsets, ads) de todas as contas.

        Args:
            start_date: Data in√≠cio (YYYY-MM-DD)
            end_date: Data fim (YYYY-MM-DD)

        Returns:
            Dict com DataFrames:
            - 'campaigns': DataFrame consolidado de campanhas
            - 'adsets': DataFrame consolidado de adsets
            - 'ads': DataFrame consolidado de ads
        """
        logger.info(f"üìÇ Carregando relat√≥rios Meta de {self.reports_dir}...")

        # Buscar arquivos por padr√£o (recursivamente em subpastas)
        # Usar listagem manual para evitar problemas com Unicode em glob
        all_files = list(self.reports_dir.rglob('*.xlsx'))

        # Normalizar nomes de arquivos para resolver problemas de encoding Unicode
        campaign_files = [f for f in all_files
                         if 'Campanhas' in normalize_unicode(f.name) or 'campanhas' in normalize_unicode(f.name)]

        adset_files = [f for f in all_files
                      if 'Conjuntos' in normalize_unicode(f.name)
                      and ('an√∫ncios' in normalize_unicode(f.name) or 'anuncios' in normalize_unicode(f.name))]

        # Para ads: deve ter "An√∫ncios" MAS N√ÉO "Conjuntos"
        ad_files = [f for f in all_files
                   if ('An√∫ncios' in normalize_unicode(f.name) or 'Anuncios' in normalize_unicode(f.name))
                   and 'Conjuntos' not in normalize_unicode(f.name)]

        logger.info(f"   Campanhas: {len(campaign_files)} arquivo(s)")
        logger.info(f"   Adsets: {len(adset_files)} arquivo(s)")
        logger.info(f"   An√∫ncios: {len(ad_files)} arquivo(s)")

        # Carregar e consolidar
        campaigns_df = self._load_and_consolidate(campaign_files, 'campaign')
        adsets_df = self._load_and_consolidate(adset_files, 'adset')
        ads_df = self._load_and_consolidate(ad_files, 'ad')

        # CR√çTICO: Carregar edge cases (adsets e ads que n√£o aparecem nos relat√≥rios normais)
        adsets_df = self._load_edge_cases(adsets_df, 'adset')
        ads_df = self._load_edge_cases(ads_df, 'ad')

        # IMPORTANTE: N√ÉO filtrar campanhas e adsets por per√≠odo (manter todas as linhas)!
        # Motivo: Convers√µes podem ter sido atribu√≠das a campanhas/adsets que foram pausados/deletados
        # antes do per√≠odo atual. Precisamos manter todos hist√≥ricos para:
        # 1. Construir comparison_group_map completo (usado em fair_campaign_comparison.py)
        # 2. Fazer matching de convers√µes com adsets hist√≥ricos
        logger.info(f"   ‚ÑπÔ∏è  Campanhas e Adsets: mantendo hist√≥rico completo para matching")

        # CR√çTICO: Filtrar APENAS o spend por per√≠odo (zerando spend fora do per√≠odo)
        # Isso garante que convers√µes hist√≥ricas sejam atribu√≠das, mas gasto seja apenas do per√≠odo
        campaigns_df = self._filter_spend_by_period(campaigns_df, start_date, end_date, 'Campanhas')
        adsets_df = self._filter_spend_by_period(adsets_df, start_date, end_date, 'Adsets')

        # NOTA: Deduplica√ß√£o de adsets √© feita em compare_all_adsets_performance() e compare_adset_performance()
        # para evitar duplica√ß√£o de convers√µes no matching (linhas 402-409 e 641-648 em fair_campaign_comparison.py)

        ads_df = self._filter_by_period(ads_df, start_date, end_date, 'Ads')

        return {
            'campaigns': campaigns_df,
            'adsets': adsets_df,
            'ads': ads_df
        }

    def _load_and_consolidate(
        self,
        file_paths: List[Path],
        report_type: str
    ) -> pd.DataFrame:
        """
        Carrega e consolida m√∫ltiplos arquivos Excel.

        Args:
            file_paths: Lista de caminhos dos arquivos
            report_type: 'campaign', 'adset' ou 'ad'

        Returns:
            DataFrame consolidado
        """
        if not file_paths:
            logger.warning(f"   ‚ö†Ô∏è  Nenhum arquivo encontrado para {report_type}")
            return pd.DataFrame()

        all_dfs = []

        for file_path in file_paths:
            try:
                # Detectar conta pelo nome do arquivo
                account_name = self._extract_account_name(file_path.name)

                # Ler Excel
                df = pd.read_excel(file_path)

                # Adicionar identifica√ß√£o da conta
                df['_source_file'] = file_path.name
                df['_account_name'] = account_name

                # Normalizar nomes de colunas
                df = self._normalize_column_names(df, report_type)

                all_dfs.append(df)

                logger.info(f"      ‚úÖ {file_path.name}: {len(df)} linhas")

            except Exception as e:
                logger.error(f"      ‚ùå Erro ao ler {file_path.name}: {e}")

        if not all_dfs:
            return pd.DataFrame()

        # Consolidar todos os DataFrames
        consolidated = pd.concat(all_dfs, ignore_index=True)

        logger.info(f"   ‚úÖ Total consolidado: {len(consolidated)} linhas de {report_type}")

        return consolidated

    def _extract_account_name(self, filename: str) -> str:
        """
        Extrai nome da conta do nome do arquivo.

        Args:
            filename: Nome do arquivo (ex: "Ads---Rodolfo-Mori-Campanhas-...")

        Returns:
            Nome da conta (ex: "Rodolfo Mori")
        """
        # Padr√£o: Ads---[Nome-da-Conta]-[Tipo]-[Per√≠odo]
        parts = filename.split('---')
        if len(parts) >= 2:
            # Pegar segunda parte e remover tipo do relat√≥rio
            account_part = parts[1].split('-Campanhas-')[0]
            account_part = account_part.split('-Conjuntos-')[0]
            account_part = account_part.split('-An√∫ncios-')[0]
            return account_part.replace('-', ' ')
        return 'Unknown'

    def _normalize_column_names(self, df: pd.DataFrame, report_type: str) -> pd.DataFrame:
        """
        Normaliza nomes de colunas para padr√£o consistente.

        Args:
            df: DataFrame original
            report_type: 'campaign', 'adset' ou 'ad'

        Returns:
            DataFrame com colunas normalizadas
        """
        # Mapeamento de nomes do Excel ‚Üí nomes padronizados
        column_mapping = {
            # Comum a todos
            'Nome da campanha': 'campaign_name',
            'Valor usado (BRL)': 'spend',
            'Resultados': 'results',
            'Indicador de resultados': 'optimization_goal',
            'Identifica√ß√£o da campanha': 'campaign_id',

            # Budget - campanhas e adsets
            'Or√ßamento da campanha': 'budget',  # CBO (Campaign Budget Optimization)
            'Or√ßamento do conjunto de an√∫ncios': 'budget',  # ABO (Ad Set Budget Optimization)
            'Tipo de or√ßamento do conjunto de an√∫ncios': 'budget_type',
            'Tipo de or√ßamento da campanha': 'budget_type',

            # Adsets
            'Nome do conjunto de an√∫ncios': 'adset_name',
            'Identifica√ß√£o do conjunto de an√∫ncios': 'adset_id',

            # An√∫ncios
            'Nome do an√∫ncio': 'ad_name',
            'Identifica√ß√£o do an√∫ncio': 'ad_id',

            # Eventos personalizados (colunas diretas nos novos relat√≥rios)
            'Leads': 'leads_standard',
            'LeadQualified': 'lead_qualified',
            'LeadQualifiedHighQuality': 'lead_qualified_hq',
            'Faixa A': 'faixa_a',

            # Indicador de resultados (objetivo de otimiza√ß√£o) - IMPORTANTE para classifica√ß√£o ML
            'Indicador de resultados': 'optimization_goal_indicator',
        }

        df = df.rename(columns=column_mapping)

        # CR√çTICO: Normalizar whitespace em nomes (adset_name, ad_name, campaign_name)
        # Isso garante matching consistente mesmo com varia√ß√µes de espa√ßamento
        for name_col in ['campaign_name', 'adset_name', 'ad_name']:
            if name_col in df.columns:
                df[name_col] = df[name_col].apply(normalize_whitespace)

        # Converter spend para num√©rico
        if 'spend' in df.columns:
            df['spend'] = pd.to_numeric(df['spend'].astype(str).str.replace(',', ''), errors='coerce')

        # Converter results para num√©rico
        if 'results' in df.columns:
            df['results'] = pd.to_numeric(df['results'], errors='coerce')

        # Converter budget para num√©rico
        if 'budget' in df.columns:
            df['budget'] = pd.to_numeric(df['budget'], errors='coerce')

        # Converter IDs para string (para evitar nota√ß√£o cient√≠fica)
        for id_col in ['campaign_id', 'adset_id', 'ad_id']:
            if id_col in df.columns:
                df[id_col] = df[id_col].astype(str).str.replace('.0', '', regex=False)

                # CR√çTICO: Normalizar IDs para os primeiros 15 d√≠gitos
                # Isso resolve o problema de edge_cases terem sufixo "390" enquanto relat√≥rios normais t√™m "000"
                # Exemplo: 120234898385570390 ‚Üí 120234898385570
                # Isso garante que a mesma campanha n√£o seja duplicada
                df[id_col] = df[id_col].apply(lambda x: str(x)[:15] if pd.notna(x) and str(x) != 'nan' else x)

        # Converter colunas de eventos para num√©rico
        for event_col in ['leads_standard', 'lead_qualified', 'lead_qualified_hq', 'faixa_a']:
            if event_col in df.columns:
                df[event_col] = pd.to_numeric(df[event_col], errors='coerce').fillna(0)

        # Extrair AD code do nome do an√∫ncio (ex: "DEV-AD0033-vid" ‚Üí "AD0033")
        if report_type == 'ad' and 'ad_name' in df.columns:
            df['ad_code'] = df['ad_name'].str.extract(r'(AD0\d+)', expand=False)

        # Simplificar optimization_goal_indicator (extrair apenas o tipo de evento)
        # Ex: "actions:offsite_conversion.fb_pixel_lead" ‚Üí "Lead"
        # Ex: "conversions:offsite_conversion.fb_pixel_custom.LeadQualifiedHighQuality" ‚Üí "LeadQualifiedHighQuality"
        if 'optimization_goal_indicator' in df.columns:
            def simplify_optimization_goal(val):
                if pd.isna(val):
                    return 'Lead'
                val_str = str(val).lower()

                # Verificar eventos customizados CAPI (ordem importa - mais espec√≠fico primeiro)
                if 'leadqualifiedhighquality' in val_str or 'lead_qualified_high_quality' in val_str:
                    return 'LeadQualifiedHighQuality'
                elif 'leadqualified' in val_str or 'lead_qualified' in val_str:
                    return 'LeadQualified'
                elif 'faixa a' in val_str or 'faixa_a' in val_str:
                    return 'Faixa A'
                elif 'lead' in val_str:
                    return 'Lead'

                return str(val)

            df['optimization_goal'] = df['optimization_goal_indicator'].apply(simplify_optimization_goal)

        return df

    def _filter_by_period(
        self,
        df: pd.DataFrame,
        start_date: str,
        end_date: str,
        report_type: str
    ) -> pd.DataFrame:
        """
        Filtra DataFrame por per√≠odo usando as colunas de data do relat√≥rio.

        Args:
            df: DataFrame a filtrar
            start_date: Data in√≠cio (YYYY-MM-DD)
            end_date: Data fim (YYYY-MM-DD)
            report_type: Nome do tipo de relat√≥rio (para log)

        Returns:
            DataFrame filtrado
        """
        if df.empty:
            return df

        # Verificar se as colunas de per√≠odo existem
        if 'In√≠cio dos relat√≥rios' not in df.columns or 'T√©rmino dos relat√≥rios' not in df.columns:
            logger.warning(f"   ‚ö†Ô∏è  Colunas de per√≠odo n√£o encontradas em {report_type}, n√£o foi poss√≠vel filtrar")
            return df

        before_count = len(df)

        # Filtrar: manter apenas registros onde o per√≠odo do relat√≥rio SE SOBREP√ïE ao per√≠odo solicitado
        # Sobreposi√ß√£o ocorre quando:
        # - In√≠cio do relat√≥rio <= end_date (relat√≥rio come√ßa antes ou durante o per√≠odo)
        # - T√©rmino do relat√≥rio >= start_date (relat√≥rio termina depois ou durante o per√≠odo)
        df_filtered = df[
            (df['In√≠cio dos relat√≥rios'] <= end_date) &
            (df['T√©rmino dos relat√≥rios'] >= start_date)
        ].copy()

        after_count = len(df_filtered)

        if before_count != after_count:
            logger.info(f"   üóìÔ∏è  {report_type} filtrados por per√≠odo: {after_count}/{before_count} ({after_count/before_count*100:.1f}%)")
            logger.info(f"      Per√≠odo solicitado: {start_date} a {end_date}")
        else:
            logger.info(f"   ‚úÖ {report_type}: {after_count} registros (100% no per√≠odo)")

        return df_filtered

    def _filter_spend_by_period(
        self,
        df: pd.DataFrame,
        start_date: str,
        end_date: str,
        report_type: str
    ) -> pd.DataFrame:
        """
        Zera o spend de registros FORA do per√≠odo, mas mant√©m todas as linhas.

        Isso permite que convers√µes hist√≥ricas sejam atribu√≠das a campanhas/adsets antigos,
        mas garante que o gasto considerado seja apenas do per√≠odo de an√°lise.

        Args:
            df: DataFrame a processar
            start_date: Data in√≠cio (YYYY-MM-DD)
            end_date: Data fim (YYYY-MM-DD)
            report_type: Nome do tipo de relat√≥rio (para log)

        Returns:
            DataFrame com spend zerado fora do per√≠odo
        """
        if df.empty or 'spend' not in df.columns:
            return df

        # Verificar se as colunas de per√≠odo existem
        if 'In√≠cio dos relat√≥rios' not in df.columns or 'T√©rmino dos relat√≥rios' not in df.columns:
            logger.warning(f"   ‚ö†Ô∏è  Colunas de per√≠odo n√£o encontradas em {report_type}, n√£o foi poss√≠vel filtrar spend")
            return df

        # Criar c√≥pia para n√£o modificar original
        df = df.copy()

        # Identificar linhas FORA do per√≠odo
        # Linha est√° fora se N√ÉO h√° sobreposi√ß√£o:
        # - T√©rmino do relat√≥rio < start_date (relat√≥rio terminou antes do per√≠odo)
        # - In√≠cio do relat√≥rio > end_date (relat√≥rio come√ßou depois do per√≠odo)
        outside_period = (
            (df['T√©rmino dos relat√≥rios'] < start_date) |
            (df['In√≠cio dos relat√≥rios'] > end_date)
        )

        # Contar spend que ser√° zerado
        spend_outside = df.loc[outside_period, 'spend'].sum() if outside_period.any() else 0
        spend_total = df['spend'].sum()

        # Zerar spend fora do per√≠odo
        df.loc[outside_period, 'spend'] = 0

        if spend_outside > 0:
            logger.info(f"   üí∞ {report_type}: Spend filtrado por per√≠odo")
            logger.info(f"      Total: R$ {spend_total:,.2f}")
            logger.info(f"      Fora do per√≠odo (zerado): R$ {spend_outside:,.2f}")
            logger.info(f"      No per√≠odo: R$ {spend_total - spend_outside:,.2f}")

        return df

    def _load_edge_cases(
        self,
        df: pd.DataFrame,
        report_type: str
    ) -> pd.DataFrame:
        """
        Carrega edge cases (adsets/ads) que n√£o aparecem nos relat√≥rios normais devido a bugs da Meta.

        Edge cases s√£o registros que:
        - Aparecem na interface da Meta com gasto e m√©tricas
        - MAS n√£o s√£o inclu√≠dos nas exporta√ß√µes de relat√≥rios
        - Precisam ser exportados individualmente e colocados na pasta edge_cases/

        Args:
            df: DataFrame j√° carregado (adsets ou ads)
            report_type: 'adset' ou 'ad'

        Returns:
            DataFrame com edge cases adicionados
        """
        edge_case_dir = self.reports_dir / 'edge_cases'

        if not edge_case_dir.exists():
            # Pasta edge_cases n√£o existe, retornar dados normais
            return df

        # IMPORTANTE: Usar apenas arquivos CSV (mais confi√°veis e r√°pidos)
        all_edge_files = list(edge_case_dir.glob('*.csv'))

        # Filtrar arquivos baseado no tipo
        if report_type == 'adset':
            # Arquivos de Conjuntos de an√∫ncios
            edge_case_files = [f for f in all_edge_files
                              if 'Conjuntos' in f.name or 'conjunto' in f.name.lower()]
        elif report_type == 'ad':
            # Arquivos de An√∫ncios (mas N√ÉO Conjuntos)
            edge_case_files = [f for f in all_edge_files
                              if ('An√∫ncios' in f.name or 'anuncio' in f.name.lower())
                              and 'Conjuntos' not in f.name]
        else:
            edge_case_files = []

        if not edge_case_files:
            # Nenhum edge case encontrado para este tipo
            return df

        logger.info(f"   üîß Carregando {report_type} edge cases de {edge_case_dir.name}/...")

        edge_case_dfs = []

        for file_path in edge_case_files:
            try:
                # Ler arquivo CSV
                df_edge = pd.read_csv(file_path)

                # Verificar colunas esperadas baseado no tipo
                if report_type == 'adset':
                    expected_col = 'Nome do conjunto de an√∫ncios'
                else:  # ad
                    expected_col = 'Nome do an√∫ncio'

                # Pular se estiver vazio ou sem colunas esperadas
                if df_edge.empty or expected_col not in df_edge.columns:
                    continue

                # Adicionar metadados
                df_edge['_source_file'] = file_path.name
                df_edge['_account_name'] = self._extract_account_name(file_path.name)
                df_edge['_is_edge_case'] = True  # Marcar como edge case

                # Normalizar nomes de colunas usando o mesmo processo
                df_edge = self._normalize_column_names(df_edge, report_type)

                edge_case_dfs.append(df_edge)

                logger.info(f"      ‚úÖ Edge case: {file_path.name} ({len(df_edge)} {report_type}(s))")

                # Log dos registros carregados
                for idx, row in df_edge.iterrows():
                    if report_type == 'adset':
                        name = row.get('adset_name', 'Unknown')
                        id_val = row.get('adset_id', 'Unknown')
                    else:  # ad
                        name = row.get('ad_name', 'Unknown')
                        id_val = row.get('ad_id', 'Unknown')

                    campaign_id = row.get('campaign_id', 'Unknown')
                    spend = row.get('spend', 0)
                    logger.info(f"         ‚Ä¢ {name} (ID: {str(id_val)[:15]}..., Campaign: {str(campaign_id)[:15]}..., R$ {spend:.2f})")

            except Exception as e:
                logger.warning(f"      ‚ö†Ô∏è Erro ao ler {file_path.name}: {e}")

        if not edge_case_dfs:
            # Nenhum edge case v√°lido carregado
            return df

        # Consolidar edge cases
        edge_cases_consolidated = pd.concat(edge_case_dfs, ignore_index=True)

        # Combinar com dados normais
        # IMPORTANTE: Edge cases t√™m prioridade (adicionar no final para sobrescrever duplicatas)
        if df.empty:
            combined_df = edge_cases_consolidated
        else:
            # Remover duplicatas baseado no ID (edge case tem prioridade)
            id_col = 'adset_id' if report_type == 'adset' else 'ad_id'

            if id_col in edge_cases_consolidated.columns:
                edge_case_ids = edge_cases_consolidated[id_col].astype(str).unique()
                df_filtered = df[~df[id_col].astype(str).isin(edge_case_ids)]
                combined_df = pd.concat([df_filtered, edge_cases_consolidated], ignore_index=True)
            else:
                combined_df = pd.concat([df, edge_cases_consolidated], ignore_index=True)

        logger.info(f"   ‚úÖ Total {report_type}s com edge cases: {len(combined_df)} (+{len(edge_cases_consolidated)} edge case(s))")

        return combined_df

    def build_costs_hierarchy(
        self,
        start_date: str,
        end_date: str
    ) -> Dict:
        """
        Constr√≥i estrutura costs_hierarchy a partir dos relat√≥rios Excel.

        Args:
            start_date: Data in√≠cio (YYYY-MM-DD)
            end_date: Data fim (YYYY-MM-DD)

        Returns:
            Dict no formato costs_hierarchy esperado pelo metrics_calculator:
            {
                'campaigns': {
                    campaign_id: {
                        'name': campaign_name,
                        'account_id': account_id,
                        'spend': total_spend,
                        'daily_budget': budget,
                        'num_creatives': num_ads,
                        'optimization_goals': set([...])
                    }
                }
            }
        """
        # Carregar relat√≥rios j√° filtrados por per√≠odo
        reports = self.load_all_reports(start_date, end_date)
        campaigns_df = reports['campaigns']
        adsets_df = reports['adsets']
        ads_df = reports['ads']

        # NOTA: O filtro por per√≠odo j√° foi aplicado em load_all_reports()
        # N√£o √© necess√°rio filtrar novamente aqui

        costs_hierarchy = {'campaigns': {}}

        # NOVO: Criar mapeamento campaign_name ‚Üí campaign_id dos relat√≥rios de Campanhas
        # (quando dispon√≠vel - arquivos novos com coluna "Identifica√ß√£o da campanha")
        campaign_name_to_id = {}
        skipped_campaigns = []

        if not campaigns_df.empty and 'campaign_id' in campaigns_df.columns:
            for _, row in campaigns_df.iterrows():
                camp_name = row.get('campaign_name')
                camp_id = row.get('campaign_id')

                # Debug: verificar valores
                if pd.isna(camp_id):
                    skipped_campaigns.append((camp_name, 'ID is NaN'))
                    continue
                if pd.isna(camp_name):
                    skipped_campaigns.append((str(camp_id), 'Name is NaN'))
                    continue

                # Converter ID
                camp_id_str = str(int(camp_id)) if isinstance(camp_id, float) else str(camp_id)
                campaign_name_to_id[camp_name] = camp_id_str

            if campaign_name_to_id:
                logger.info(f"   ‚úÖ {len(campaign_name_to_id)} IDs de campanha carregados dos relat√≥rios de Campanhas")

            if skipped_campaigns:
                logger.warning(f"   ‚ö†Ô∏è  {len(skipped_campaigns)} campanhas ignoradas no mapeamento:")
                for name, reason in skipped_campaigns[:5]:
                    logger.warning(f"      ‚Ä¢ {name[:60]}: {reason}")

        # Validar adsets
        if adsets_df.empty or 'campaign_id' not in adsets_df.columns:
            logger.error("   ‚ùå Adsets vazios ou sem campaign_id")
            return costs_hierarchy

        # Agrupar por campaign_id extra√≠do dos adsets
        for campaign_id in adsets_df['campaign_id'].dropna().unique():
            if pd.isna(campaign_id) or campaign_id == 'nan':
                continue

            # Buscar adsets desta campanha
            campaign_adsets = adsets_df[adsets_df['campaign_id'] == campaign_id]
            if campaign_adsets.empty:
                continue

            # Nome da campanha vem do primeiro adset
            campaign_name = campaign_adsets.iloc[0]['campaign_name']

            # NOTA: N√ÉO sobrescrever campaign_id do adset com mapeamento por nome
            # porque pode haver campanhas com mesmo nome mas IDs diferentes.
            # O campaign_id do adset j√° √© correto (vem da coluna "Identifica√ß√£o da campanha")

            # CORRE√á√ÉO: Usar spend dos ADSETS (que tem campaign_id correto)
            # em vez de campaigns_df (que s√≥ tem nome e causa duplica√ß√£o)
            total_spend = campaign_adsets['spend'].sum() if not campaign_adsets.empty else 0.0

            # Buscar ads desta campanha
            campaign_ads = ads_df[ads_df['campaign_id'] == campaign_id] if not ads_df.empty else pd.DataFrame()

            # Agregar budget dos adsets (ABO - Ad Set Budget Optimization)
            budget = campaign_adsets['budget'].sum() if not campaign_adsets.empty else 0.0

            # Se budget dos adsets √© 0, pode ser CBO (Campaign Budget Optimization)
            # Buscar budget do n√≠vel da campanha
            if budget == 0:
                # Buscar do campaigns_df por nome (√∫nico lugar onde budget de campanha CBO pode estar)
                campaign_rows = campaigns_df[campaigns_df['campaign_name'] == campaign_name]
                if not campaign_rows.empty and 'budget' in campaign_rows.columns:
                    campaign_budget = campaign_rows['budget'].iloc[0] if len(campaign_rows) > 0 else 0
                    if campaign_budget > 0:
                        budget = campaign_budget

            # N√∫mero de criativos (ads √∫nicos)
            num_creatives = len(campaign_ads) if not campaign_ads.empty else 0

            # Account name do primeiro adset
            account_name = campaign_adsets.iloc[0].get('_account_name', 'Unknown')

            # NOVO: Extrair eventos diretamente das colunas dos adsets
            # Os novos relat√≥rios t√™m colunas separadas para cada tipo de evento
            total_leads_standard = 0
            lead_qualified = 0
            lead_qualified_hq = 0
            faixa_a = 0

            # Somar eventos de todos os adsets da campanha
            if 'leads_standard' in campaign_adsets.columns:
                total_leads_standard = campaign_adsets['leads_standard'].sum()
            if 'lead_qualified' in campaign_adsets.columns:
                lead_qualified = campaign_adsets['lead_qualified'].sum()
            if 'lead_qualified_hq' in campaign_adsets.columns:
                lead_qualified_hq = campaign_adsets['lead_qualified_hq'].sum()
            if 'faixa_a' in campaign_adsets.columns:
                faixa_a = campaign_adsets['faixa_a'].sum()

            # Total de leads = apenas leads padr√£o (n√£o somar eventos customizados, pois s√£o subsets)
            # Eventos customizados (LQ, LQHQ, Faixa A) s√£o subconjuntos dos leads, n√£o leads adicionais
            total_leads = total_leads_standard

            # Coletar optimization_goals √∫nicos dos adsets desta campanha
            # Agora usa a coluna "Indicador de resultados" (j√° simplificada para "optimization_goal")
            optimization_goals = set()
            if 'optimization_goal' in campaign_adsets.columns:
                for goal in campaign_adsets['optimization_goal'].dropna().unique():
                    if goal and goal != 'nan':
                        optimization_goals.add(str(goal))

            # Se n√£o tiver optimization_goal, usar Lead como fallback
            if not optimization_goals:
                optimization_goals.add('Lead')

            # Construir estrutura de adsets para essa campanha
            adsets_dict = {}
            for _, adset_row in campaign_adsets.iterrows():
                adset_id = adset_row.get('adset_id', 'unknown')
                adset_name = adset_row.get('adset_name', 'Unknown')

                # Usar optimization_goal do adset (j√° simplificado na normaliza√ß√£o)
                adset_opt_goal = adset_row.get('optimization_goal', 'Lead')
                if pd.isna(adset_opt_goal) or adset_opt_goal == 'nan':
                    adset_opt_goal = 'Lead'

                adsets_dict[str(adset_id)] = {
                    'name': adset_name,
                    'optimization_goal': adset_opt_goal,
                    'spend': float(adset_row.get('spend', 0)),
                    'budget': float(adset_row.get('budget', 0))
                }

            # Construir entrada
            costs_hierarchy['campaigns'][campaign_id] = {
                'name': campaign_name,
                'account_id': account_name,
                'spend': float(total_spend) if not pd.isna(total_spend) else 0.0,
                'daily_budget': float(budget) if not pd.isna(budget) else 0.0,
                'num_creatives': num_creatives,
                'optimization_goals': optimization_goals,
                'leads': int(total_leads) if not pd.isna(total_leads) else 0,
                'LeadQualified': int(lead_qualified) if not pd.isna(lead_qualified) else 0,
                'LeadQualifiedHighQuality': int(lead_qualified_hq) if not pd.isna(lead_qualified_hq) else 0,
                'Faixa A': int(faixa_a) if not pd.isna(faixa_a) else 0,
                'adsets': adsets_dict  # NOVO: Adicionar adsets individuais
            }

        logger.info(f"   ‚úÖ Costs hierarchy constru√≠da: {len(costs_hierarchy['campaigns'])} campanhas")

        # DEBUG: Verificar se leads foram extra√≠dos
        total_leads_extracted = sum(camp.get('leads', 0) for camp in costs_hierarchy['campaigns'].values())
        logger.info(f"   üìä Total de leads extra√≠dos: {total_leads_extracted}")

        # DEBUG: Verificar gasto total
        total_spend_extracted = sum(camp.get('spend', 0) for camp in costs_hierarchy['campaigns'].values())
        logger.info(f"   üí∞ Gasto total extra√≠do: R$ {total_spend_extracted:,.2f}")

        # DEBUG: Comparar com total nos relat√≥rios
        total_campaigns_in_df = len(campaign_name_to_id) if campaign_name_to_id else 0
        total_adsets_unique_campaigns = len(adsets_df['campaign_id'].dropna().unique()) if not adsets_df.empty else 0
        if total_campaigns_in_df != len(costs_hierarchy['campaigns']):
            logger.warning(f"   ‚ö†Ô∏è  Discrep√¢ncia: {total_campaigns_in_df} IDs nos Campanhas.xlsx, mas apenas {len(costs_hierarchy['campaigns'])} processadas")
            logger.warning(f"   ‚ö†Ô∏è  {total_adsets_unique_campaigns} IDs √∫nicos de campanha encontrados nos Adsets")

        # DEBUG DETALHADO: Estat√≠sticas por conta
        logger.info("")
        logger.info("=" * 100)
        logger.info("üìä DEBUG: ESTAT√çSTICAS POR CONTA")
        logger.info("=" * 100)

        # Agrupar campanhas por account
        from collections import defaultdict
        stats_by_account = defaultdict(lambda: {'campaigns': 0, 'adsets': 0, 'ads': 0, 'spend': 0.0})

        # Contar campanhas por conta
        for camp_id, camp_data in costs_hierarchy['campaigns'].items():
            account = camp_data.get('account_id', 'Unknown')
            stats_by_account[account]['campaigns'] += 1
            stats_by_account[account]['spend'] += camp_data.get('spend', 0.0)

        # Contar adsets por conta (usar account_name dos relat√≥rios)
        if not adsets_df.empty and 'account_name' in adsets_df.columns:
            adsets_by_account = adsets_df.groupby('account_name').size().to_dict()
            for account, count in adsets_by_account.items():
                stats_by_account[account]['adsets'] = count

        # Contar ads por conta (usar account_name dos relat√≥rios)
        if not ads_df.empty and 'account_name' in ads_df.columns:
            ads_by_account = ads_df.groupby('account_name').size().to_dict()
            for account, count in ads_by_account.items():
                stats_by_account[account]['ads'] = count

        # Exibir estat√≠sticas
        for account in sorted(stats_by_account.keys()):
            stats = stats_by_account[account]
            logger.info("")
            logger.info(f"üè¢ Conta: {account}")
            logger.info(f"   üìä Campanhas: {stats['campaigns']}")
            logger.info(f"   üìä Adsets: {stats['adsets']}")
            logger.info(f"   üìä Ads: {stats['ads']}")
            logger.info(f"   üí∞ Gasto Total: R$ {stats['spend']:,.2f}")

        logger.info("")
        logger.info("=" * 100)
        logger.info("")

        return costs_hierarchy


    def load_adsets_for_comparison(
        self,
        ml_campaign_ids: List[str],
        control_campaign_ids: List[str]
    ) -> pd.DataFrame:
        """
        Carrega adsets de campanhas ML e Controle para compara√ß√£o.

        Args:
            ml_campaign_ids: IDs das campanhas ML
            control_campaign_ids: IDs das campanhas controle

        Returns:
            DataFrame com adsets filtrados e marcados (ml_type)
        """
        reports = self.load_all_reports(start_date='2025-11-18', end_date='2025-12-01')
        adsets_df = reports['adsets']

        if adsets_df.empty:
            return pd.DataFrame()

        # Filtrar apenas campanhas relevantes
        all_campaign_ids = ml_campaign_ids + control_campaign_ids
        adsets_filtered = adsets_df[adsets_df['campaign_id'].isin(all_campaign_ids)].copy()

        # Marcar tipo (ML ou Controle)
        adsets_filtered['ml_type'] = adsets_filtered['campaign_id'].apply(
            lambda x: 'COM_ML' if x in ml_campaign_ids else 'SEM_ML'
        )

        return adsets_filtered

    def load_ads_for_comparison(
        self,
        ml_campaign_ids: List[str],
        control_campaign_ids: List[str]
    ) -> pd.DataFrame:
        """
        Carrega ads de campanhas ML e Controle para compara√ß√£o.

        Args:
            ml_campaign_ids: IDs das campanhas ML
            control_campaign_ids: IDs das campanhas controle

        Returns:
            DataFrame com ads filtrados e marcados (ml_type)
        """
        reports = self.load_all_reports(start_date='2025-11-18', end_date='2025-12-01')
        ads_df = reports['ads']

        if ads_df.empty:
            return pd.DataFrame()

        # Extrair AD code do nome do an√∫ncio
        ads_df['ad_code'] = ads_df['ad_name'].str.extract(r'(AD0\d+)', expand=False)

        # Filtrar apenas campanhas relevantes
        all_campaign_ids = ml_campaign_ids + control_campaign_ids
        ads_filtered = ads_df[ads_df['campaign_id'].isin(all_campaign_ids)].copy()

        # Marcar tipo (ML ou Controle)
        ads_filtered['ml_type'] = ads_filtered['campaign_id'].apply(
            lambda x: 'COM_ML' if x in ml_campaign_ids else 'SEM_ML'
        )

        return ads_filtered
