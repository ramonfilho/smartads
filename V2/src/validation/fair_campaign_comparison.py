"""
M√≥dulo para compara√ß√£o fair control em n√≠vel de ADSETS e ADS.

Compara campanhas ML vs Controle no n√≠vel de conjuntos de an√∫ncios e an√∫ncios individuais.
Foco em m√©tricas de neg√≥cio: ROAS, CPA, Margem de Contribui√ß√£o, Taxa de Convers√£o.

Princ√≠pio: "Ma√ß√£s com Ma√ß√£s"
- Compara MESMOS adsets (mesmo targeting/p√∫blico)
- Compara MESMOS ads (mesmo criativo)
- Filtro de gasto m√≠nimo: R$ 200 por adset/ad
"""

import os
import sys
import logging
from typing import List, Dict, Set, Optional, Tuple
from datetime import datetime
from pathlib import Path
import pandas as pd

# Adicionar path para imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# Meta Ads API
from facebook_business.api import FacebookAdsApi
from facebook_business.adobjects.adaccount import AdAccount
from facebook_business.adobjects.campaign import Campaign
from facebook_business.adobjects.adset import AdSet
from facebook_business.adobjects.ad import Ad

# Token fixo do projeto
from api.meta_config import META_CONFIG

logger = logging.getLogger(__name__)


# ============================================================================
# HELPER: CRIAR MAPEAMENTO REFINADO DE CAMPANHAS
# ============================================================================

def create_refined_campaign_map(
    campaigns_df: pd.DataFrame,
    ml_campaign_ids: List[str],
    control_campaign_ids: List[str]
) -> Dict[str, str]:
    """
    Cria mapeamento refinado: campaign_id ‚Üí comparison_group.

    Distingue entre:
    - 'Eventos ML': Campanhas ML que usam eventos CAPI customizados (LeadQualified/LQHQ)
    - 'Otimiza√ß√£o ML': Campanhas ML que N√ÉO usam eventos customizados
    - 'Controle': Campanhas sem ML

    Args:
        campaigns_df: DataFrame com campanhas (deve ter optimization_goal)
        ml_campaign_ids: Lista de IDs de campanhas ML
        control_campaign_ids: Lista de IDs de campanhas Controle

    Returns:
        Dict mapping campaign_id ‚Üí comparison_group ('Eventos ML', 'Otimiza√ß√£o ML', ou 'Controle')
    """
    refined_map = {}

    # DEBUG: Mostrar colunas dispon√≠veis
    logger.info(f"   üîç DEBUG create_refined_campaign_map:")
    logger.info(f"      Colunas dispon√≠veis: {list(campaigns_df.columns)[:10]}")
    logger.info(f"      Total de linhas: {len(campaigns_df)}")

    # Criar lookup de campaign_id ‚Üí optimization_goal
    if 'optimization_goal' in campaigns_df.columns and 'campaign_id' in campaigns_df.columns:
        # Limpar campaign_id (primeiros 15 d√≠gitos)
        campaigns_df['campaign_id_clean'] = campaigns_df['campaign_id'].astype(str).str[:15]

        opt_goal_map = {}
        for idx, row in campaigns_df.iterrows():
            cid = str(row['campaign_id_clean'])
            opt_goal = str(row.get('optimization_goal', ''))
            opt_goal_map[cid] = opt_goal
    else:
        opt_goal_map = {}

    # IMPORTANTE: Campanhas especiais que n√£o disparam evento Lead padr√£o
    # mas usam LeadQualified (configuradas no validation_config.yaml)
    SPECIAL_EVENTOS_ML_CAMPAIGNS = [
        '120234062599950',  # "DEVLF | CAP | FRIO | FASE 04 | ADV | ML | S/ ABERTO" - N√£o dispara Lead, s√≥ LeadQualified
    ]

    # Classificar campanhas ML
    for cid in ml_campaign_ids:
        cid_clean = str(cid)[:15]
        opt_goal = opt_goal_map.get(cid_clean, '')

        # Override para campanhas especiais listadas explicitamente
        if cid_clean in SPECIAL_EVENTOS_ML_CAMPAIGNS:
            refined_map[cid_clean] = 'Eventos ML'
            logger.info(f"   ‚úÖ Campanha especial for√ßada como Eventos ML: {cid_clean}")
            continue

        # Verificar se usa eventos customizados CAPI
        uses_custom_events = any(custom in opt_goal for custom in ['LeadQualified', 'LeadQualifiedHighQuality'])

        # DEBUG: Log das campanhas problem√°ticas
        if '120234062599950' in cid_clean or '120234748179990' in cid_clean:
            logger.info(f"   üîç DEBUG - Classificando campanha ML:")
            logger.info(f"      ID (15): {cid_clean}")
            logger.info(f"      ID (completo): {cid}")
            logger.info(f"      optimization_goal encontrado: '{opt_goal}'")
            logger.info(f"      uses_custom_events: {uses_custom_events}")
            logger.info(f"      Grupo: {'Eventos ML' if uses_custom_events else 'Otimiza√ß√£o ML'}")

        if uses_custom_events:
            refined_map[cid_clean] = 'Eventos ML'  # USAR 15 D√çGITOS como chave
        else:
            refined_map[cid_clean] = 'Otimiza√ß√£o ML'  # USAR 15 D√çGITOS como chave

    # Classificar campanhas Controle
    logger.info(f"   üîç DEBUG - Classificando {len(control_campaign_ids)} campanhas Controle:")
    for cid in control_campaign_ids:
        cid_clean = str(cid)[:15]
        refined_map[cid_clean] = 'Controle'  # USAR 15 D√çGITOS como chave
        logger.info(f"      ‚Ä¢ {cid_clean} ‚Üí Controle")

    logger.info(f"   üìä Mapeamento refinado criado:")
    eventos_ml = sum(1 for v in refined_map.values() if v == 'Eventos ML')
    otimiz_ml = sum(1 for v in refined_map.values() if v == 'Otimiza√ß√£o ML')
    controle = sum(1 for v in refined_map.values() if v == 'Controle')
    logger.info(f"      Eventos ML: {eventos_ml}, Otimiza√ß√£o ML: {otimiz_ml}, Controle: {controle}")

    return refined_map


# ============================================================================
# HELPER: NORMALIZAR WHITESPACE EM ADSET NAMES
# ============================================================================

def normalize_whitespace(text: str) -> str:
    """
    Normaliza espa√ßos em branco em nomes de adsets para matching consistente.

    - Colapsa m√∫ltiplos espa√ßos em um √∫nico espa√ßo
    - Remove espa√ßos no in√≠cio e fim

    Args:
        text: Texto a normalizar

    Returns:
        Texto normalizado
    """
    import re
    if pd.isna(text):
        return text
    # Colapsar m√∫ltiplos espa√ßos em um √∫nico
    normalized = re.sub(r'\s+', ' ', str(text))
    # Remover espa√ßos no in√≠cio e fim
    return normalized.strip()


# ============================================================================
# CONFIGURA√á√ÉO: ADSETS E ADS MATCHED
# ============================================================================

# Defini√ß√£o dos matched adsets (aparecem em ML E Controle)
# IMPORTANTE: Espa√ßamento ser√° normalizado automaticamente (m√∫ltiplos espa√ßos ‚Üí 1 espa√ßo)
MATCHED_ADSETS = [
    'ABERTO | AD0022',
    'ABERTO | AD0027',
    'ADV | Linguagem de programa√ß√£o',
    'ADV | Lookalike 1% Cadastrados - DEV 2.0 + Interesse Ci√™ncia da Computa√ß√£o',
    'ADV | Lookalike 2% Cadastrados - DEV 2.0 + Interesses',
]

# Normalizar MATCHED_ADSETS ao carregar o m√≥dulo
MATCHED_ADSETS = [normalize_whitespace(adset) for adset in MATCHED_ADSETS]

# Defini√ß√£o dos matched ads (aparecem em ML E Controle)
MATCHED_ADS = [
    'AD0013', 'AD0014', 'AD0017', 'AD0018', 'AD0022', 'AD0027', 'AD0033'
]

# Gasto m√≠nimo para incluir adset/ad na compara√ß√£o (R$)
MIN_SPEND = 200.0


# ============================================================================
# FUN√á√ïES DE IDENTIFICA√á√ÉO DE MATCHED PAIRS
# ============================================================================

def identify_matched_adset_pairs(
    adsets_df: pd.DataFrame,
    ml_campaign_ids: List[str],
    control_campaign_ids: List[str],
    min_spend: float = MIN_SPEND
) -> Tuple[List[str], pd.DataFrame]:
    """
    Identifica adsets que aparecem tanto em campanhas ML quanto controle.

    Args:
        adsets_df: DataFrame com adsets e suas m√©tricas
        ml_campaign_ids: IDs das campanhas ML
        control_campaign_ids: IDs das campanhas controle
        min_spend: Gasto m√≠nimo para incluir adset (default: R$ 200)

    Returns:
        Tuple (matched_adsets, adsets_metrics_df)
        - matched_adsets: Lista de nomes de adsets matched
        - adsets_metrics_df: DataFrame com m√©tricas por adset
    """
    logger.info("üîç Identificando matched pairs de adsets...")

    # CR√çTICO: Normalizar whitespace em adset_name para matching consistente
    adsets_df = adsets_df.copy()
    adsets_df['adset_name'] = adsets_df['adset_name'].apply(normalize_whitespace)

    # Adsets em campanhas ML - AGREGAR primeiro, DEPOIS filtrar
    ml_adsets_all = adsets_df[adsets_df['campaign_id'].isin(ml_campaign_ids)]
    if not ml_adsets_all.empty:
        # Agregar spend por adset_name
        ml_adsets_agg = ml_adsets_all.groupby('adset_name')['spend'].sum().reset_index()
        # Filtrar por gasto m√≠nimo agregado
        ml_adsets_filtered = ml_adsets_agg[ml_adsets_agg['spend'] >= min_spend]
        ml_adsets = set(ml_adsets_filtered['adset_name'].dropna().unique().tolist())
    else:
        ml_adsets = set()

    # Adsets em campanhas controle - AGREGAR primeiro, DEPOIS filtrar
    ctrl_adsets_all = adsets_df[adsets_df['campaign_id'].isin(control_campaign_ids)]
    if not ctrl_adsets_all.empty:
        # Agregar spend por adset_name
        ctrl_adsets_agg = ctrl_adsets_all.groupby('adset_name')['spend'].sum().reset_index()
        # Filtrar por gasto m√≠nimo agregado
        ctrl_adsets_filtered = ctrl_adsets_agg[ctrl_adsets_agg['spend'] >= min_spend]
        control_adsets = set(ctrl_adsets_filtered['adset_name'].dropna().unique().tolist())
    else:
        control_adsets = set()

    # Matched pairs (interse√ß√£o)
    matched = list(ml_adsets.intersection(control_adsets))

    # DEBUG: Mostrar adsets matched
    logger.info(f"   üîç DEBUG - Adsets matched (interse√ß√£o): {len(matched)}")
    for adset in sorted(matched):
        logger.info(f"      ‚Ä¢ {repr(adset)}")

    # Filtrar apenas adsets na lista MATCHED_ADSETS
    matched_final = [adset for adset in matched if adset in MATCHED_ADSETS]

    # DEBUG: Mostrar adsets que n√£o est√£o na lista MATCHED_ADSETS
    not_in_list = [adset for adset in matched if adset not in MATCHED_ADSETS]
    if not_in_list:
        logger.info(f"   ‚ö†Ô∏è DEBUG - Adsets matched mas N√ÉO na lista MATCHED_ADSETS:")
        for adset in sorted(not_in_list):
            logger.info(f"      ‚Ä¢ {repr(adset)}")

    # DEBUG: Mostrar adsets esperados mas n√£o matched
    not_matched = [adset for adset in MATCHED_ADSETS if adset not in matched]
    if not_matched:
        logger.info(f"   ‚ö†Ô∏è DEBUG - Adsets na lista MATCHED_ADSETS mas N√ÉO matched:")
        for adset in sorted(not_matched):
            in_ml = '‚úì' if adset in ml_adsets else '‚úó'
            in_ctrl = '‚úì' if adset in control_adsets else '‚úó'
            logger.info(f"      ‚Ä¢ {repr(adset)} (ML:{in_ml}, Ctrl:{in_ctrl})")

    logger.info(f"   ‚úÖ {len(matched_final)} adsets matched (de {len(MATCHED_ADSETS)} esperados)")
    logger.info(f"      ML adsets: {len(ml_adsets)}, Controle adsets: {len(control_adsets)}")

    # Criar DataFrame com m√©tricas por adset
    adsets_metrics = adsets_df[adsets_df['adset_name'].isin(matched_final)].copy()

    # Renomear 'leads_standard' para 'leads' (vem do MetaReportsLoader)
    if 'leads_standard' in adsets_metrics.columns:
        adsets_metrics['leads'] = adsets_metrics['leads_standard']

    return matched_final, adsets_metrics


def identify_matched_ad_pairs(
    ads_df: pd.DataFrame,
    ml_campaign_ids: List[str],
    control_campaign_ids: List[str],
    min_spend: float = MIN_SPEND
) -> Tuple[List[str], pd.DataFrame]:
    """
    Identifica an√∫ncios que aparecem tanto em campanhas ML quanto controle.

    Args:
        ads_df: DataFrame com ads e suas m√©tricas
        ml_campaign_ids: IDs das campanhas ML
        control_campaign_ids: IDs das campanhas controle
        min_spend: Gasto m√≠nimo para incluir ad (default: R$ 200)

    Returns:
        Tuple (matched_ads, ads_metrics_df)
        - matched_ads: Lista de AD codes matched
        - ads_metrics_df: DataFrame com m√©tricas por ad
    """
    logger.info("üîç Identificando matched pairs de an√∫ncios...")

    # An√∫ncios em campanhas ML - AGREGAR primeiro, DEPOIS filtrar
    ml_ads_all = ads_df[ads_df['campaign_id'].isin(ml_campaign_ids)]
    if not ml_ads_all.empty:
        # Agregar spend por ad_code
        ml_ads_agg = ml_ads_all.groupby('ad_code')['spend'].sum().reset_index()
        # Filtrar por gasto m√≠nimo agregado
        ml_ads_filtered = ml_ads_agg[ml_ads_agg['spend'] >= min_spend]
        ml_ads = set(ml_ads_filtered['ad_code'].dropna().unique().tolist())
    else:
        ml_ads = set()

    # An√∫ncios em campanhas controle - AGREGAR primeiro, DEPOIS filtrar
    ctrl_ads_all = ads_df[ads_df['campaign_id'].isin(control_campaign_ids)]
    if not ctrl_ads_all.empty:
        # Agregar spend por ad_code
        ctrl_ads_agg = ctrl_ads_all.groupby('ad_code')['spend'].sum().reset_index()
        # Filtrar por gasto m√≠nimo agregado
        ctrl_ads_filtered = ctrl_ads_agg[ctrl_ads_agg['spend'] >= min_spend]
        control_ads = set(ctrl_ads_filtered['ad_code'].dropna().unique().tolist())
    else:
        control_ads = set()

    # Matched pairs (interse√ß√£o)
    matched = list(ml_ads.intersection(control_ads))

    # Filtrar apenas ads na lista MATCHED_ADS
    matched_final = [ad for ad in matched if ad in MATCHED_ADS]

    logger.info(f"   ‚úÖ {len(matched_final)} an√∫ncios matched (de {len(MATCHED_ADS)} esperados)")
    logger.info(f"      ML ads: {len(ml_ads)}, Controle ads: {len(control_ads)}")

    # Criar DataFrame com m√©tricas por ad
    ads_metrics = ads_df[ads_df['ad_code'].isin(matched_final)].copy()

    return matched_final, ads_metrics


# ============================================================================
# FUN√á√ïES DE COMPARA√á√ÉO DE PERFORMANCE
# ============================================================================

def compare_all_adsets_performance(
    adsets_df: pd.DataFrame,
    matched_df: pd.DataFrame,
    comparison_group_map: Dict[str, str],
    product_value: float = 2000.0,
    min_spend: float = 0.0
) -> pd.DataFrame:
    """
    Compara performance de TODOS os adsets (Eventos ML vs Controle), sem filtrar por matched pairs.

    Args:
        adsets_df: DataFrame com TODOS os adsets do Excel (sem filtro de matched pairs)
        matched_df: DataFrame com convers√µes matched (leads‚Üívendas)
        comparison_group_map: Mapeamento campaign_id ‚Üí comparison_group
        product_value: Valor do produto em R$
        min_spend: Gasto m√≠nimo para incluir adset (default: R$ 0)

    Returns:
        DataFrame agregado com m√©tricas por grupo (Eventos ML vs Controle)
    """
    logger.info("üìä Comparando performance de TODOS os adsets (Eventos ML vs Controle)...")

    # CR√çTICO: Contar LEADS (todos) e CONVERS√ïES por CAMPAIGN + ADSET + COMPARISON_GROUP do matched_df
    # Isso garante consist√™ncia com a Tabela 1 (Compara√ß√£o por Campanhas)
    # IMPORTANTE: Incluir comparison_group no agrupamento para manter a mesma classifica√ß√£o
    if 'medium' in matched_df.columns and 'campaign' in matched_df.columns and 'comparison_group' in matched_df.columns:
        # PASSO 1: Contar TODOS os leads por campanha + adset + comparison_group
        leads_by_campaign_adset = matched_df.groupby(
            ['campaign', 'medium', 'comparison_group']
        ).size().reset_index(name='leads_count')

        leads_by_campaign_adset.columns = ['campaign_name', 'adset_name', 'comparison_group', 'leads_count']

        # PASSO 2: Contar convers√µes e receita (apenas convertidos)
        if 'converted' in matched_df.columns:
            converted_leads = matched_df[matched_df['converted'] == True].copy()

            conversions_by_campaign_adset = converted_leads.groupby(
                ['campaign', 'medium', 'comparison_group']
            ).agg({
                'email': 'nunique',  # Convers√µes √∫nicas
                'sale_value': 'sum'   # Receita real total
            }).reset_index()

            conversions_by_campaign_adset.columns = ['campaign_name', 'adset_name', 'comparison_group', 'conversions', 'revenue']

            # Merge leads + convers√µes
            metrics_by_campaign_adset = leads_by_campaign_adset.merge(
                conversions_by_campaign_adset,
                on=['campaign_name', 'adset_name', 'comparison_group'],
                how='left'
            )
            metrics_by_campaign_adset['conversions'] = metrics_by_campaign_adset['conversions'].fillna(0)
            metrics_by_campaign_adset['revenue'] = metrics_by_campaign_adset['revenue'].fillna(0)
        else:
            # Se n√£o tem convers√µes, usar apenas leads
            metrics_by_campaign_adset = leads_by_campaign_adset.copy()
            metrics_by_campaign_adset['conversions'] = 0
            metrics_by_campaign_adset['revenue'] = 0

        # Extrair Campaign ID do final do nome
        def extract_campaign_id(campaign_name):
            if pd.isna(campaign_name):
                return None
            parts = str(campaign_name).split('|')
            if len(parts) >= 2:
                campaign_id = parts[-1].strip()
                if campaign_id.isdigit() and len(campaign_id) >= 15:
                    return campaign_id[:15]
            return None

        metrics_by_campaign_adset['campaign_id_from_utm'] = metrics_by_campaign_adset['campaign_name'].apply(extract_campaign_id)

        # Verificar se h√° IDs extra√≠dos
        total_leads = metrics_by_campaign_adset['leads_count'].sum()
        total_convs = metrics_by_campaign_adset['conversions'].sum()
        total_revenue = metrics_by_campaign_adset['revenue'].sum()
        combinations_with_id = metrics_by_campaign_adset['campaign_id_from_utm'].notna().sum()
        logger.info(f"   ‚úÖ Leads, convers√µes e receita calculadas por campanha + adset + comparison_group")
        logger.info(f"   Total de combina√ß√µes: {len(metrics_by_campaign_adset)}")
        logger.info(f"   Campaign IDs extra√≠dos dos UTMs: {combinations_with_id}/{len(metrics_by_campaign_adset)}")
        logger.info(f"   Leads totais: {total_leads}")
        logger.info(f"   Convers√µes totais: {total_convs:.0f}")
        logger.info(f"   Receita total real: R$ {total_revenue:,.2f}")

        # DEBUG: Verificar se h√° (campaign, adset) que aparecem em m√∫ltiplos comparison_groups
        duplicates = metrics_by_campaign_adset.groupby(['campaign_name', 'adset_name']).size()
        multi_group = duplicates[duplicates > 1]
        if len(multi_group) > 0:
            logger.warning(f"   ‚ö†Ô∏è  {len(multi_group)} pares (campaign, adset) aparecem em M√öLTIPLOS comparison_groups:")
            for (camp, adset), count in multi_group.head(5).items():
                logger.warning(f"      ‚Ä¢ {adset[:40]} (campaign {camp[-20:]}): {count} grupos")
                # Mostrar quais grupos
                groups = metrics_by_campaign_adset[
                    (metrics_by_campaign_adset['campaign_name'] == camp) &
                    (metrics_by_campaign_adset['adset_name'] == adset)
                ]['comparison_group'].tolist()
                leads_per_group = metrics_by_campaign_adset[
                    (metrics_by_campaign_adset['campaign_name'] == camp) &
                    (metrics_by_campaign_adset['adset_name'] == adset)
                ]['leads_count'].tolist()
                for g, l in zip(groups, leads_per_group):
                    logger.warning(f"         - {g}: {l} leads")
    else:
        metrics_by_campaign_adset = pd.DataFrame(columns=['campaign_name', 'adset_name', 'leads_count', 'conversions', 'revenue'])

    # Preparar campaign_id para merge (primeiros 15 d√≠gitos)
    adsets_df['campaign_id_clean'] = adsets_df['campaign_id'].astype(str).str[:15]
    metrics_by_campaign_adset['campaign_id_clean'] = metrics_by_campaign_adset['campaign_id_from_utm'].astype(str).str[:15]

    # CR√çTICO: Normalizar adset_name em AMBOS DataFrames antes do merge
    # Isso resolve problemas de espa√ßamento ("ABERTO |  AD0065" vs "ABERTO | AD0065")
    if 'adset_name' in adsets_df.columns:
        adsets_df['adset_name'] = adsets_df['adset_name'].apply(normalize_whitespace)
    metrics_by_campaign_adset['adset_name'] = metrics_by_campaign_adset['adset_name'].apply(normalize_whitespace)

    # CR√çTICO: Deduplicar adsets_df ANTES do merge para evitar duplica√ß√£o de leads!
    # O adsets_df pode ter m√∫ltiplas linhas para o mesmo adset (diferentes per√≠odos)
    # IMPORTANTE: Deduplicar por (campaign_id_clean, adset_name) que s√£o as chaves do merge!
    logger.info(f"   üîß Deduplicando adsets_df antes do merge...")
    adsets_df_before = len(adsets_df)
    adsets_df = adsets_df.groupby(['campaign_id_clean', 'adset_name'], as_index=False).agg({
        'campaign_id': 'first',  # Pegar primeiro campaign_id completo
        'adset_id': 'first',     # Pegar primeiro adset_id completo
        'campaign_name': 'first' if 'campaign_name' in adsets_df.columns else lambda x: None,
        'spend': 'sum',  # SOMAR spend de todos os per√≠odos
        'leads_standard': 'sum' if 'leads_standard' in adsets_df.columns else lambda x: 0,
        'lead_qualified': 'sum' if 'lead_qualified' in adsets_df.columns else lambda x: 0,
        'lead_qualified_hq': 'sum' if 'lead_qualified_hq' in adsets_df.columns else lambda x: 0,
        'faixa_a': 'sum' if 'faixa_a' in adsets_df.columns else lambda x: 0,
    })
    logger.info(f"      {adsets_df_before} rows ‚Üí {len(adsets_df)} rows (removidas {adsets_df_before - len(adsets_df)} duplicatas)")

    # Merge leads, convers√µes e receita (do matched_df) com dados de spend do Excel
    adsets_full = adsets_df.merge(
        metrics_by_campaign_adset,
        on=['campaign_id_clean', 'adset_name'],
        how='left',
        suffixes=('', '_matched')
    )

    # Preencher valores ausentes (adsets sem leads no matched_df)
    adsets_full['leads_count'] = adsets_full['leads_count'].fillna(0)
    adsets_full['conversions'] = adsets_full['conversions'].fillna(0)
    adsets_full['revenue'] = adsets_full['revenue'].fillna(0)  # Receita real do matched_df

    # CR√çTICO: Usar APENAS comparison_group do matched_df - N√ÉO preencher com mapeamento!
    # Isso garante que a classifica√ß√£o seja EXATAMENTE a mesma que na Tabela 1
    if 'comparison_group' not in adsets_full.columns:
        # Se n√£o tem comparison_group, criar vazio (ser√° filtrado depois)
        adsets_full['comparison_group'] = None
        logger.warning(f"   ‚ö†Ô∏è  comparison_group n√£o veio do matched_df - adsets sem leads")

    # DEBUG: Verificar quantos NaN temos
    nan_count = adsets_full['comparison_group'].isna().sum()
    if nan_count > 0:
        logger.info(f"   ‚ÑπÔ∏è  {nan_count} adsets sem comparison_group (sem leads no matched_df)")

    # IMPORTANTE: N√ÉO preencher NaN com mapeamento!
    # Leads com comparison_group=NaN n√£o est√£o no matched_df, ent√£o n√£o devem ser contados
    logger.info(f"   ‚úÖ comparison_group preservado EXATAMENTE como no matched_df (sem preenchimento)")

    # DEBUG: Verificar total de leads ANTES da agrega√ß√£o
    total_leads_before_agg = adsets_full['leads_count'].sum()
    rows_before_agg = len(adsets_full)
    logger.info(f"   üîç DEBUG - ANTES agrega√ß√£o:")
    logger.info(f"      Total rows: {rows_before_agg}")
    logger.info(f"      Total leads: {total_leads_before_agg:.0f}")

    # CR√çTICO: Agregar duplicatas por (campaign_id, adset_id) SOMANDO o spend
    # Pode haver duplicatas no adsets_df devido a m√∫ltiplos relat√≥rios ou per√≠odos
    # IMPORTANTE: Somar spend garante que tenhamos o gasto total mesmo ap√≥s filtro de per√≠odo
    before_dedup = len(adsets_full)
    convs_before_dedup = adsets_full['conversions'].sum()
    spend_before_dedup = adsets_full['spend'].sum()

    # DEBUG: Verificar leads ANTES da agrega√ß√£o por grupo
    logger.info(f"   üîç DEBUG - Leads ANTES da agrega√ß√£o por grupo (do matched_df):")
    adsets_full_temp = adsets_full.copy()
    adsets_full_temp['comparison_group_temp'] = adsets_full_temp['campaign_id_clean'].map(comparison_group_map)
    for group in ['Eventos ML', 'Controle']:
        group_rows = adsets_full_temp[adsets_full_temp['comparison_group_temp'] == group]
        if 'leads_count' in group_rows.columns:
            total_leads = group_rows['leads_count'].sum()
            logger.info(f"      {group}: {len(group_rows)} linhas, {total_leads:.0f} leads (matched_df)")
        else:
            logger.info(f"      {group}: {len(group_rows)} linhas, coluna leads_count n√£o encontrada")

    # CR√çTICO: Agregar por (campaign_id, adset_id, comparison_group) para preservar breakdown
    # Isso evita misturar leads de diferentes grupos no mesmo adset
    agg_dict = {
        'campaign_id_clean': 'first',
        'adset_name': 'first',
        'spend': 'sum',  # SOMAR spend de todos os per√≠odos
        'leads_count': 'max',  # Leads do matched_df n√£o duplicam (j√° agregados por campaign+adset+group)
        'conversions': 'max',  # Convers√µes n√£o duplicam (vem do matched_df)
        'revenue': 'max',  # Revenue n√£o duplica (vem do matched_df)
    }

    # Adicionar colunas opcionais se existirem
    if 'campaign_name' in adsets_full.columns:
        agg_dict['campaign_name'] = 'first'
    if 'lead_qualified' in adsets_full.columns:
        agg_dict['lead_qualified'] = 'sum'
    if 'lead_qualified_hq' in adsets_full.columns:
        agg_dict['lead_qualified_hq'] = 'sum'
    if 'faixa_a' in adsets_full.columns:
        agg_dict['faixa_a'] = 'sum'

    # IMPORTANTE: Incluir comparison_group no groupby para preservar breakdown por grupo
    group_cols = ['campaign_id', 'adset_id']
    if 'comparison_group' in adsets_full.columns:
        group_cols.append('comparison_group')

    adsets_full = adsets_full.groupby(group_cols, as_index=False).agg(agg_dict)

    after_dedup = len(adsets_full)
    convs_after_dedup = adsets_full['conversions'].sum()
    spend_after_dedup = adsets_full['spend'].sum()

    # DEBUG: Verificar total de leads DEPOIS da agrega√ß√£o
    total_leads_after_agg = adsets_full['leads_count'].sum()
    logger.info(f"   üîç DEBUG - DEPOIS agrega√ß√£o:")
    logger.info(f"      Total rows: {after_dedup}")
    logger.info(f"      Total leads: {total_leads_after_agg:.0f}")
    if total_leads_before_agg != total_leads_after_agg:
        logger.warning(f"      ‚ö†Ô∏è Leads mudaram na agrega√ß√£o: {total_leads_before_agg:.0f} ‚Üí {total_leads_after_agg:.0f} ({total_leads_after_agg - total_leads_before_agg:+.0f})")

    # DEBUG: Verificar leads DEPOIS da agrega√ß√£o por grupo
    logger.info(f"   üîç DEBUG - Leads DEPOIS da agrega√ß√£o por grupo (do matched_df):")
    adsets_full_temp2 = adsets_full.copy()
    adsets_full_temp2['comparison_group_temp'] = adsets_full_temp2['campaign_id_clean'].map(comparison_group_map)
    for group in ['Eventos ML', 'Controle']:
        group_rows = adsets_full_temp2[adsets_full_temp2['comparison_group_temp'] == group]
        if 'leads_count' in group_rows.columns:
            total_leads = group_rows['leads_count'].sum()
            logger.info(f"      {group}: {len(group_rows)} linhas, {total_leads:.0f} leads (matched_df)")
        else:
            logger.info(f"      {group}: {len(group_rows)} linhas, coluna leads_count n√£o encontrada")

    if before_dedup != after_dedup:
        logger.info(f"   üîß Agregadas {before_dedup - after_dedup} linhas duplicadas (mesmo campaign_id + adset_id)")
        logger.info(f"      Spend: R$ {spend_before_dedup:,.2f} ‚Üí R$ {spend_after_dedup:,.2f}")
        if convs_before_dedup != convs_after_dedup:
            logger.warning(f"      ‚ö†Ô∏è Convers√µes afetadas: {convs_before_dedup:.0f} ‚Üí {convs_after_dedup:.0f} (-{convs_before_dedup - convs_after_dedup:.0f})")

    # Renomear 'leads_count' para 'leads' (vem do matched_df)
    if 'leads_count' in adsets_full.columns:
        adsets_full['leads'] = adsets_full['leads_count']
    elif 'leads' not in adsets_full.columns:
        logger.warning("   ‚ö†Ô∏è Coluna 'leads' n√£o encontrada, usando 0")
        adsets_full['leads'] = 0

    # CR√çTICO: Remover adsets "fantasma" (0 leads E 0 gasto) DEPOIS do merge e renomea√ß√£o
    # Esses adsets causam duplica√ß√£o de convers√µes quando t√™m o mesmo nome que adsets ativos
    # Exemplo: "ABERTO |  AD0027" (espa√ßo duplo, 0 leads) duplica convers√µes de "ABERTO | AD0027" (ativo)
    before_filter = len(adsets_full)

    # DEBUG: Verificar leads ANTES do filtro de fantasma por grupo
    logger.info(f"   üîç DEBUG - Leads ANTES do filtro de adsets fantasma (do matched_df):")
    adsets_full_temp3 = adsets_full.copy()
    adsets_full_temp3['comparison_group_temp'] = adsets_full_temp3['campaign_id_clean'].map(comparison_group_map)
    for group in ['Eventos ML', 'Controle']:
        group_rows = adsets_full_temp3[adsets_full_temp3['comparison_group_temp'] == group]
        total_leads = group_rows['leads'].sum()
        logger.info(f"      {group}: {len(group_rows)} linhas, {total_leads:.0f} leads (matched_df)")

    adsets_full = adsets_full[~((adsets_full['leads'] == 0) & (adsets_full['spend'] == 0))]
    after_filter = len(adsets_full)

    # DEBUG: Verificar leads DEPOIS do filtro de fantasma por grupo
    logger.info(f"   üîç DEBUG - Leads DEPOIS do filtro de adsets fantasma (do matched_df):")
    adsets_full_temp4 = adsets_full.copy()
    adsets_full_temp4['comparison_group_temp'] = adsets_full_temp4['campaign_id_clean'].map(comparison_group_map)
    for group in ['Eventos ML', 'Controle']:
        group_rows = adsets_full_temp4[adsets_full_temp4['comparison_group_temp'] == group]
        total_leads = group_rows['leads'].sum()
        logger.info(f"      {group}: {len(group_rows)} linhas, {total_leads:.0f} leads (matched_df)")

    if before_filter != after_filter:
        logger.info(f"   üßπ Removidos {before_filter - after_filter} adsets fantasma (0 leads E 0 gasto)")

    # AJUSTE ESPECIAL: Adsets da campanha edge case que n√£o dispara evento Lead
    # Aplicar mesma l√≥gica de "forjar" leads que foi feita no n√≠vel de campanha
    campaign_special_id_prefix = '120234062599950'

    # Verificar se h√° coluna LeadQualified
    if 'lead_qualified' in adsets_full.columns or 'LeadQualified' in adsets_full.columns:
        lq_col = 'lead_qualified' if 'lead_qualified' in adsets_full.columns else 'LeadQualified'

        # Calcular propor√ß√£o m√©dia LQ/Leads dos adsets normais (excluindo campanha especial)
        adsets_normal = adsets_full[
            ~adsets_full['campaign_id_clean'].astype(str).str.startswith(campaign_special_id_prefix)
        ]

        total_leads_normal = adsets_normal['leads'].sum()
        total_lq_normal = adsets_normal[lq_col].sum()

        if total_leads_normal > 0 and total_lq_normal > 0:
            avg_ratio = total_lq_normal / total_leads_normal

            # Ajustar adsets da campanha especial
            for idx in adsets_full.index:
                camp_id = str(adsets_full.at[idx, 'campaign_id_clean'])
                if camp_id.startswith(campaign_special_id_prefix):
                    lq = adsets_full.at[idx, lq_col]
                    current_leads = adsets_full.at[idx, 'leads']

                    # Se tem LQ mas n√£o tem leads, calcular leads artificiais
                    if pd.notna(lq) and lq > 0 and (pd.isna(current_leads) or current_leads == 0):
                        leads_artificial = int(lq / avg_ratio)
                        adsets_full.at[idx, 'leads'] = leads_artificial
                        logger.info(f"   üîß Adset especial ajustado: {adsets_full.at[idx, 'adset_name'][:50]}")
                        logger.info(f"      LeadQualified: {lq:.0f} ‚Üí Leads artificial: {leads_artificial} (propor√ß√£o {avg_ratio:.2%})")

    # DEBUG: Mostrar distribui√ß√£o de leads por comparison_group ANTES do filtro
    logger.info(f"   üîç DEBUG - Leads por comparison_group ANTES do filtro:")
    for group in adsets_full['comparison_group'].unique():
        if pd.notna(group):
            group_leads = adsets_full[adsets_full['comparison_group'] == group]['leads'].sum()
            group_count = len(adsets_full[adsets_full['comparison_group'] == group])
            logger.info(f"      {group}: {group_count} adsets, {group_leads:.0f} leads")

    # Filtrar apenas Eventos ML e Controle (remover Otimiza√ß√£o ML e outros)
    # IMPORTANTE: Mostrar TODOS os adsets, independente de gasto, leads ou convers√µes
    # Isso garante que os totais batam com a tabela de Campanhas
    adsets_filtered = adsets_full[adsets_full['comparison_group'].isin(['Eventos ML', 'Controle'])].copy()

    logger.info(f"   üìä Todos os adsets das campanhas Eventos ML + Controle: {len(adsets_filtered)}")

    # DEBUG: Mostrar distribui√ß√£o de leads por comparison_group DEPOIS do filtro
    logger.info(f"   üîç DEBUG - Leads por comparison_group DEPOIS do filtro:")
    for group in ['Eventos ML', 'Controle']:
        group_leads = adsets_filtered[adsets_filtered['comparison_group'] == group]['leads'].sum()
        group_count = len(adsets_filtered[adsets_filtered['comparison_group'] == group])
        logger.info(f"      {group}: {group_count} adsets, {group_leads:.0f} leads")

    # DEBUG: Verificar spend e leads por grupo
    logger.info(f"   üí∞ DEBUG - Spend e Leads por grupo (leads do matched_df):")
    for group in ['Eventos ML', 'Controle']:
        group_adsets = adsets_filtered[adsets_filtered['comparison_group'] == group]
        total_spend = group_adsets['spend'].sum()
        total_leads = group_adsets['leads'].sum()
        adsets_with_spend = group_adsets[group_adsets['spend'] > 0]
        logger.info(f"      {group}: {len(adsets_with_spend)}/{len(group_adsets)} adsets com spend > 0")
        logger.info(f"         Spend: R$ {total_spend:,.2f}, Leads: {total_leads:.0f} (matched_df)")

    # Calcular m√©tricas de neg√≥cio
    # NOTA: 'revenue' j√° vem do matched_df com valores reais de venda, n√£o usar product_value fixo
    # adsets_filtered['revenue'] j√° foi preenchida no merge acima
    adsets_filtered['cpl'] = adsets_filtered['spend'] / adsets_filtered['leads'].replace(0, 1)  # Evitar divis√£o por zero
    adsets_filtered['roas'] = adsets_filtered['revenue'] / adsets_filtered['spend'].replace(0, 1)  # Evitar divis√£o por zero
    adsets_filtered['margin'] = adsets_filtered['revenue'] - adsets_filtered['spend']
    adsets_filtered['conversion_rate'] = adsets_filtered['conversions'] / adsets_filtered['leads'].replace(0, 1)  # Evitar divis√£o por zero

    # DEBUG: Verificar se h√° duplica√ß√£o de convers√µes por comparison_group
    logger.info(f"\n   üîç DEBUG - Verificando convers√µes √∫nicas por grupo:")
    for group in ['Eventos ML', 'Controle']:
        group_adsets = adsets_filtered[adsets_filtered['comparison_group'] == group]
        total_convs = group_adsets['conversions'].sum()

        # Verificar se h√° adsets com convers√µes duplicadas
        adsets_with_convs = group_adsets[group_adsets['conversions'] > 0]
        logger.info(f"      {group}: {len(adsets_with_convs)} adsets com convers√µes, total: {total_convs:.0f}")

        # Mostrar top 5 adsets por convers√µes
        if len(adsets_with_convs) > 0:
            top5 = adsets_with_convs.nlargest(5, 'conversions')[['adset_name', 'campaign_id_clean', 'adset_id', 'conversions']]
            for idx, row in top5.iterrows():
                adset_id_short = str(row['adset_id'])[:18] if pd.notna(row.get('adset_id')) else 'NO_ID'
                logger.info(f"         ‚Ä¢ {row['adset_name'][:40]} (campaign {row['campaign_id_clean']}, adset {adset_id_short}): {row['conversions']:.0f}")

    # DEBUG ESPEC√çFICO: Investigar "ABERTO | AD0027" duplicado
    logger.info(f"\n   üîç DEBUG - Investigando 'ABERTO | AD0027' duplicado:")
    ad0027_adsets = adsets_filtered[adsets_filtered['adset_name'] == 'ABERTO | AD0027']
    if len(ad0027_adsets) > 0:
        logger.info(f"      Total de linhas com 'ABERTO | AD0027': {len(ad0027_adsets)}")
        for idx, row in ad0027_adsets.iterrows():
            logger.info(f"         ‚Ä¢ campaign_id: {row.get('campaign_id_clean', 'N/A')}")
            logger.info(f"           adset_id: {row.get('adset_id', 'N/A')}")
            logger.info(f"           comparison_group: {row.get('comparison_group', 'N/A')}")
            logger.info(f"           conversions: {row.get('conversions', 0):.0f}")
            logger.info(f"           leads: {row.get('leads', 0):.0f}")
            logger.info(f"           spend: R$ {row.get('spend', 0):.2f}")
            logger.info(f"           ---")

            # DEBUG: Mostrar emails das convers√µes desse adset
            if row.get('conversions', 0) > 0:
                try:
                    adset_id = row.get('adset_id')
                    campaign_id = str(row.get('campaign_id_clean', ''))

                    logger.info(f"           üîç Procurando convers√µes para campaign {campaign_id}, adset {adset_id}")

                    # Filtrar convers√µes desse adset espec√≠fico
                    converted_leads = matched_df[matched_df['converted'] == True].copy()
                    logger.info(f"              Total de convers√µes: {len(converted_leads)}")

                    # Extrair ID da campanha do formato "NOME|ID"
                    # O campo campaign est√° no formato: "DEVLF | CAP | FRIO | ... |120220370119870390"
                    if 'campaign' in converted_leads.columns:
                        # Extrair ID da campanha (ap√≥s o √∫ltimo pipe, primeiros 15 d√≠gitos)
                        converted_leads['campaign_id_extracted'] = converted_leads['campaign'].astype(str).str.split('|').str[-1].str[:15]

                        # Filtrar por campanha
                        converted_leads = converted_leads[converted_leads['campaign_id_extracted'] == campaign_id]
                        logger.info(f"              Convers√µes dessa campanha: {len(converted_leads)}")

                    # Normalizar medium para compara√ß√£o
                    if len(converted_leads) > 0 and 'medium' in converted_leads.columns:
                        converted_leads['medium_norm'] = converted_leads['medium'].apply(normalize_whitespace)
                        converted_leads_adset = converted_leads[converted_leads['medium_norm'] == 'ABERTO | AD0027']

                        logger.info(f"              Convers√µes do adset 'ABERTO | AD0027': {len(converted_leads_adset)}")

                        if len(converted_leads_adset) > 0:
                            logger.info(f"           üìß Emails das convers√µes ({len(converted_leads_adset)}):")
                            for idx, conv_row in converted_leads_adset.head(5).iterrows():
                                email = conv_row.get('email', 'N/A')
                                medium_orig = conv_row.get('medium', 'N/A')
                                logger.info(f"              - {email} (medium original: '{medium_orig}')")
                except Exception as e:
                    logger.error(f"           ‚ùå Erro ao buscar emails: {e}")

    # Agregar por comparison_group
    aggregated = adsets_filtered.groupby('comparison_group').agg({
        'leads': 'sum',
        'conversions': 'sum',
        'spend': 'sum',
        'revenue': 'sum',
        'margin': 'sum'
    }).reset_index()

    # Recalcular m√©tricas agregadas
    aggregated['conversion_rate'] = aggregated['conversions'] / aggregated['leads']
    aggregated['cpl'] = aggregated['spend'] / aggregated['leads']
    aggregated['roas'] = aggregated['revenue'] / aggregated['spend']

    logger.info(f"   ‚úÖ Compara√ß√£o completa de adsets calculada")
    logger.info(f"      Eventos ML: {aggregated[aggregated['comparison_group']=='Eventos ML']['conversions'].sum():.0f} convers√µes")
    logger.info(f"      Controle: {aggregated[aggregated['comparison_group']=='Controle']['conversions'].sum():.0f} convers√µes")

    return aggregated


def compare_adset_performance(
    adsets_metrics_df: pd.DataFrame,
    matched_df: pd.DataFrame,
    ml_type_map: Dict[str, str],
    product_value: float = 2000.0,
    comparison_group_map: Optional[Dict[str, str]] = None
) -> Dict[str, pd.DataFrame]:
    """
    Compara performance de adsets entre ML e Controle.

    Args:
        adsets_metrics_df: DataFrame com m√©tricas de adsets (da Meta API)
        matched_df: DataFrame com convers√µes matched (leads‚Üívendas)
        ml_type_map: Mapeamento campaign_id ‚Üí ml_type (DEPRECATED - usar comparison_group_map)
        product_value: Valor do produto em R$
        comparison_group_map: Mapeamento campaign_id ‚Üí comparison_group ('Eventos ML', 'Otimiza√ß√£o ML', 'Controle')

    Returns:
        Dict com DataFrames:
        - 'aggregated': Agrega√ß√£o ML vs Controle
        - 'detailed': Detalhamento adset-a-adset (CADA CAMPANHA SEPARADA)
    """
    logger.info("üìä Comparando performance de adsets...")

    # CR√çTICO: Normalizar adset_name no DataFrame de m√©tricas do Excel
    # Isso resolve problemas de espa√ßamento ("ABERTO |  AD0065" vs "ABERTO | AD0065")
    if 'adset_name' in adsets_metrics_df.columns:
        adsets_metrics_df['adset_name'] = adsets_metrics_df['adset_name'].apply(normalize_whitespace)

    # Adicionar ml_type aos adsets (para compatibilidade)
    adsets_metrics_df['ml_type'] = adsets_metrics_df['campaign_id'].map(ml_type_map)

    # Se temos comparison_group_map, usar ele diretamente (novo comportamento)
    if comparison_group_map:
        adsets_metrics_df['comparison_group_from_campaign'] = adsets_metrics_df['campaign_id'].map(comparison_group_map)

    # NOVO: Calcular convers√µes E RECEITA REAL por CAMPAIGN + ADSET usando 'campaign' e 'medium' do matched_df
    # A coluna 'medium' cont√©m o NOME DO ADSET que gerou o lead
    # A coluna 'campaign' cont√©m o NOME DA CAMPANHA
    # IMPORTANTE: Precisamos das DUAS para matching preciso!
    if 'converted' in matched_df.columns and 'medium' in matched_df.columns and 'campaign' in matched_df.columns:
        # Convers√µes e receita real por campanha + adset (usando campaign + medium)
        # CR√çTICO: Contar emails √∫nicos, n√£o agrega√ß√£o de linhas (evita duplicatas)
        converted_leads = matched_df[matched_df['converted'] == True].copy()

        conversions_by_campaign_adset = converted_leads.groupby(
            ['campaign', 'medium']  # campaign + medium = identifica√ß√£o √∫nica
        ).agg({
            'email': 'nunique',  # Convers√µes √∫nicas
            'sale_value': 'sum'   # Receita real total
        }).reset_index()

        conversions_by_campaign_adset.columns = ['campaign_name', 'adset_name', 'conversions', 'revenue']

        # CR√çTICO: Normalizar whitespace em adset_name (UTMs podem ter espa√ßamento inconsistente)
        conversions_by_campaign_adset['adset_name'] = conversions_by_campaign_adset['adset_name'].apply(normalize_whitespace)

        # IMPORTANTE: Extrair Campaign ID do final do nome para fazer matching preciso
        # Exemplo: "CAMPAIGN | 2025-04-15|120220370119870390" ‚Üí ID = "120220370119870390"
        def extract_campaign_id(campaign_name):
            """Extrai o Campaign ID do final do nome da campanha"""
            if pd.isna(campaign_name):
                return None
            parts = str(campaign_name).split('|')
            if len(parts) > 1:
                last_part = parts[-1].strip()
                # Se √∫ltimo elemento √© num√©rico e tem 18+ d√≠gitos, √© um Campaign ID
                if last_part.isdigit() and len(last_part) >= 18:
                    return last_part
            return None

        conversions_by_campaign_adset['campaign_id_from_utm'] = conversions_by_campaign_adset['campaign_name'].apply(extract_campaign_id)

        # DEBUG: Verificar quantos IDs foram extra√≠dos
        ids_extracted = conversions_by_campaign_adset['campaign_id_from_utm'].notna().sum()
        logger.info(f"   ‚úÖ Convers√µes calculadas por campanha + adset (via 'campaign' + 'medium')")
        logger.info(f"   Total de combina√ß√µes campanha+adset com convers√µes: {len(conversions_by_campaign_adset)}")
        logger.info(f"   Campaign IDs extra√≠dos dos UTMs: {ids_extracted}/{len(conversions_by_campaign_adset)}")

        if ids_extracted < len(conversions_by_campaign_adset):
            logger.warning(f"   ‚ö†Ô∏è {len(conversions_by_campaign_adset) - ids_extracted} convers√µes SEM Campaign ID no UTM")
            # Mostrar exemplos
            sem_id = conversions_by_campaign_adset[conversions_by_campaign_adset['campaign_id_from_utm'].isna()]
            for idx, row in sem_id.head(3).iterrows():
                logger.warning(f"      ‚Ä¢ Campaign: {row['campaign_name'][:70]}")
                logger.warning(f"        Adset: {row['adset_name'][:50]}")
    else:
        conversions_by_campaign_adset = pd.DataFrame(columns=['campaign_name', 'adset_name', 'conversions', 'revenue'])
        if 'medium' not in matched_df.columns:
            logger.warning("   ‚ö†Ô∏è Coluna 'medium' n√£o encontrada em matched_df - convers√µes n√£o podem ser atribu√≠das aos adsets!")

    # Merge convers√µes por campanha + adset
    # IMPORTANTE: Usar Campaign ID + Adset Name para matching preciso
    # (evita ambiguidade quando h√° m√∫ltiplas campanhas com mesmo nome)

    # Preparar campaign_id para merge (primeiros 15 d√≠gitos - parte comum)
    # UTMs t√™m 18 d√≠gitos, Excel tem 21 (18 + "000"), primeiros 15 s√£o a parte comum
    adsets_metrics_df['campaign_id_clean'] = adsets_metrics_df['campaign_id'].astype(str).str[:15]
    conversions_by_campaign_adset['campaign_id_clean'] = conversions_by_campaign_adset['campaign_id_from_utm'].astype(str).str[:15]

    # DEBUG: Verificar matching antes do merge
    logger.info(f"\n   üîç DEBUG - Preparando merge:")
    logger.info(f"      IDs √∫nicos no Excel: {adsets_metrics_df['campaign_id_clean'].nunique()}")
    logger.info(f"      IDs √∫nicos nas convers√µes: {conversions_by_campaign_adset['campaign_id_clean'].nunique()}")

    # Verificar se h√° algum match poss√≠vel
    ids_excel = set(adsets_metrics_df['campaign_id_clean'].unique())
    ids_conversions = set(conversions_by_campaign_adset['campaign_id_clean'].dropna().unique())
    matching_ids = ids_excel & ids_conversions
    logger.info(f"      IDs que fazem match: {len(matching_ids)}")

    if len(matching_ids) == 0:
        logger.warning(f"      ‚ö†Ô∏è NENHUM ID FAZ MATCH! Vamos comparar:")
        logger.warning(f"         Excel (primeiros 3): {list(ids_excel)[:3]}")
        logger.warning(f"         Convers√µes (primeiros 3): {list(ids_conversions)[:3]}")

    # DEBUG: Identificar convers√µes que N√ÉO fazem match com Excel
    # Fazer merge inverso: quais convers√µes n√£o encontram adset no Excel?
    conversions_not_in_excel = conversions_by_campaign_adset.merge(
        adsets_metrics_df[['campaign_id_clean', 'adset_name']].drop_duplicates(),
        on=['campaign_id_clean', 'adset_name'],
        how='left',
        indicator=True
    )
    unmatched_conversions = conversions_not_in_excel[conversions_not_in_excel['_merge'] == 'left_only']

    if len(unmatched_conversions) > 0:
        total_unmatched_convs = unmatched_conversions['conversions'].sum()
        logger.warning(f"\n   ‚ö†Ô∏è CONVERS√ïES N√ÉO ENCONTRADAS NO EXCEL META:")
        logger.warning(f"      Total de adsets n√£o encontrados: {len(unmatched_conversions)}")
        logger.warning(f"      Total de convers√µes perdidas: {total_unmatched_convs:.0f}")
        logger.warning(f"\n      Detalhes dos adsets n√£o encontrados:")

        # Para cada adset n√£o encontrado, buscar os emails correspondentes em matched_df
        for idx, row in unmatched_conversions.iterrows():
            logger.warning(f"      ‚Ä¢ Campaign: {row['campaign_name'][:60]}")
            logger.warning(f"        Adset: {row['adset_name'][:50]}")
            logger.warning(f"        Campaign ID (15): {row['campaign_id_clean']}")
            logger.warning(f"        Convers√µes: {row['conversions']:.0f}")

            # Buscar emails espec√≠ficos deste adset em matched_df
            if 'campaign' in matched_df.columns and 'medium' in matched_df.columns:
                matching_rows = matched_df[
                    (matched_df['campaign'] == row['campaign_name']) &
                    (matched_df['medium'] == row['adset_name']) &
                    (matched_df['converted'] == True)
                ]
                if len(matching_rows) > 0:
                    emails = matching_rows['email'].unique()
                    logger.warning(f"        Emails: {', '.join(emails[:3])}{' ...' if len(emails) > 3 else ''}")
                    # Verificar comparison_group destes leads
                    if 'comparison_group' in matching_rows.columns:
                        groups = matching_rows['comparison_group'].unique()
                        logger.warning(f"        Grupos: {', '.join(groups)}")
        logger.warning("")

    # MELHORADO: Merge com matching mais flex√≠vel de nomes
    # 1. Tentar merge exato primeiro
    adsets_full = adsets_metrics_df.merge(
        conversions_by_campaign_adset,
        on=['campaign_id_clean', 'adset_name'],
        how='left',
        suffixes=('', '_conv')
    )

    # CR√çTICO: Remover duplicatas por (campaign_id, adset_id)
    # Pode haver duplicatas no adsets_metrics_df devido a m√∫ltiplos relat√≥rios ou per√≠odos
    before_dedup = len(adsets_full)
    adsets_full = adsets_full.drop_duplicates(subset=['campaign_id', 'adset_id'], keep='first')
    after_dedup = len(adsets_full)

    if before_dedup != after_dedup:
        logger.info(f"   üîß Removidas {before_dedup - after_dedup} linhas duplicadas (mesmo campaign_id + adset_id)")

    # 2. Para convers√µes que n√£o tiveram match exato, tentar matching flex√≠vel
    # (√∫til quando nomes no UTM s√£o truncados)
    if len(unmatched_conversions) > 0:
        logger.info(f"   üîß Tentando matching flex√≠vel para {len(unmatched_conversions)} convers√µes n√£o encontradas...")
        matches_found = 0

        # Para cada convers√£o que n√£o encontrou adset no Excel
        for conv_idx, conv_row in unmatched_conversions.iterrows():
            utm_name = str(conv_row['adset_name']).strip()
            utm_campaign_id = str(conv_row['campaign_id_clean'])

            # Normalizar nome do UTM (remover espa√ßos extras, lowercase)
            utm_name_normalized = ' '.join(utm_name.split()).lower()

            # DEBUG: Log do adset que estamos tentando encontrar
            logger.info(f"      üîç Buscando adset: '{utm_name}' (campanha {utm_campaign_id})")

            # Procurar adsets da mesma campanha no Excel
            same_campaign_excel = adsets_metrics_df[
                adsets_metrics_df['campaign_id_clean'] == utm_campaign_id
            ]

            logger.info(f"         Encontrados {len(same_campaign_excel)} adsets da mesma campanha no Excel")

            # Tentar matching por substring/similaridade
            for excel_idx, excel_row in same_campaign_excel.iterrows():
                excel_name = str(excel_row['adset_name']).strip()
                excel_name_normalized = ' '.join(excel_name.split()).lower()

                # DEBUG: Comparar nomes
                logger.info(f"         Comparando com: '{excel_name}'")
                logger.info(f"            UTM norm: '{utm_name_normalized}'")
                logger.info(f"            Excel norm: '{excel_name_normalized}'")
                logger.info(f"            Exato match: {utm_name_normalized == excel_name_normalized}")

                # Estrat√©gia 1: Match exato (redundante mas √∫til para debug)
                if utm_name_normalized == excel_name_normalized:
                    # Encontrar a linha correspondente em adsets_full
                    match_mask = (
                        (adsets_full['campaign_id_clean'] == utm_campaign_id) &
                        (adsets_full['adset_name'] == excel_name)
                    )
                    if match_mask.any():
                        adsets_full.loc[match_mask, 'conversions'] = conv_row['conversions']
                        matches_found += 1
                        logger.info(f"      ‚úÖ Match EXATO encontrado: '{utm_name[:50]}' ‚Üí '{excel_name[:50]}'")
                        break

                # Estrat√©gia 2: Substring/similaridade (70% dos caracteres)
                min_len = min(len(utm_name_normalized), len(excel_name_normalized))

                if min_len >= 20:  # S√≥ tentar se os nomes forem razoavelmente longos
                    # Verificar se os primeiros 70% dos caracteres s√£o iguais
                    check_len = int(min_len * 0.7)
                    if utm_name_normalized[:check_len] == excel_name_normalized[:check_len]:
                        # Encontrar a linha correspondente em adsets_full
                        match_mask = (
                            (adsets_full['campaign_id_clean'] == utm_campaign_id) &
                            (adsets_full['adset_name'] == excel_name)
                        )
                        if match_mask.any():
                            adsets_full.loc[match_mask, 'conversions'] = conv_row['conversions']
                            matches_found += 1
                            logger.info(f"      ‚úÖ Match flex√≠vel ({check_len} chars): '{utm_name[:50]}' ‚Üí '{excel_name[:50]}'")
                            break

        if matches_found > 0:
            logger.info(f"   ‚úÖ Recuperadas {matches_found} convers√µes via matching flex√≠vel!")
        else:
            logger.info(f"   ‚ö†Ô∏è Nenhum match flex√≠vel encontrado")

    # CR√çTICO: Deduplic novamente ap√≥s matching flex√≠vel (pode ter criado duplicatas)
    before_dedup2 = len(adsets_full)
    adsets_full = adsets_full.drop_duplicates(subset=['campaign_id', 'adset_id'], keep='first')
    after_dedup2 = len(adsets_full)

    if before_dedup2 != after_dedup2:
        logger.info(f"   üîß Removidas {before_dedup2 - after_dedup2} linhas duplicadas ap√≥s matching flex√≠vel")

    adsets_full['conversions'] = adsets_full['conversions'].fillna(0)
    adsets_full['revenue'] = adsets_full['revenue'].fillna(0)  # Receita real do matched_df

    # Remover colunas tempor√°rias
    adsets_full = adsets_full.drop(columns=['campaign_id_clean', 'campaign_id_from_utm', 'campaign_name_conv'], errors='ignore')

    # Calcular m√©tricas de neg√≥cio
    # IMPORTANTE: N√ÉO sobrescrever 'leads' - o valor j√° vem correto do Excel!
    # Apenas garantir que leads esteja preenchido (fallback para casos sem dados)
    if 'leads' not in adsets_full.columns or adsets_full['leads'].isna().all():
        logger.warning("   ‚ö†Ô∏è Coluna 'leads' n√£o encontrada ou vazia, usando count como fallback")
        adsets_full['leads'] = adsets_full.groupby(['campaign_id', 'adset_name'])['adset_id'].transform('count')
    else:
        # Preencher NaN com 0
        adsets_full['leads'] = adsets_full['leads'].fillna(0)

    # DEBUG: Verificar adsets com convers√µes mas sem leads
    weird_adsets = adsets_full[
        (adsets_full['conversions'] > 0) &
        (adsets_full['leads'] == 0)
    ]

    if len(weird_adsets) > 0:
        logger.warning(f"\n   ‚ö†Ô∏è ATEN√á√ÉO: {len(weird_adsets)} adset(s) com convers√µes mas 0 leads:")
        for idx, row in weird_adsets.iterrows():
            logger.warning(f"      ‚Ä¢ {row['campaign_name'][:60]}")
            logger.warning(f"        Adset: {row['adset_name'][:50]}")
            logger.warning(f"        Convers√µes: {row['conversions']:.0f} | Leads (Excel): {row['leads']:.0f}")
            logger.warning(f"        Isso indica discrep√¢ncia entre dados CAPI/CSV e relat√≥rio Meta")
        logger.warning("")

    # AJUSTE ESPECIAL: Adsets da campanha edge case que n√£o dispara evento Lead
    # Aplicar mesma l√≥gica de "forjar" leads que foi feita no n√≠vel de campanha
    campaign_special_id_prefix = '120234062599950'

    # Verificar se h√° coluna LeadQualified
    if 'lead_qualified' in adsets_full.columns or 'LeadQualified' in adsets_full.columns:
        lq_col = 'lead_qualified' if 'lead_qualified' in adsets_full.columns else 'LeadQualified'

        # Calcular propor√ß√£o m√©dia LQ/Leads dos adsets normais (excluindo campanha especial)
        adsets_normal = adsets_full[
            ~adsets_full['campaign_id'].astype(str).str.startswith(campaign_special_id_prefix)
        ]

        total_leads_normal = adsets_normal['leads'].sum()
        total_lq_normal = adsets_normal[lq_col].sum()

        if total_leads_normal > 0 and total_lq_normal > 0:
            avg_ratio = total_lq_normal / total_leads_normal

            # Ajustar adsets da campanha especial
            for idx in adsets_full.index:
                camp_id = str(adsets_full.at[idx, 'campaign_id'])
                if camp_id.startswith(campaign_special_id_prefix):
                    lq = adsets_full.at[idx, lq_col]
                    current_leads = adsets_full.at[idx, 'leads']

                    # Se tem LQ mas n√£o tem leads, calcular leads artificiais
                    if pd.notna(lq) and lq > 0 and (pd.isna(current_leads) or current_leads == 0):
                        leads_artificial = int(lq / avg_ratio)
                        adsets_full.at[idx, 'leads'] = leads_artificial
                        logger.info(f"   üîß Adset especial ajustado (Matched): {adsets_full.at[idx, 'adset_name'][:50]}")
                        logger.info(f"      LeadQualified: {lq:.0f} ‚Üí Leads artificial: {leads_artificial} (propor√ß√£o {avg_ratio:.2%})")

    # Filtrar adsets com gasto 0 E leads 0 (sem atividade)
    # IMPORTANTE: Manter adsets com convers√µes mesmo se spend/leads = 0
    adsets_full = adsets_full[
        (adsets_full['spend'] > 0) |
        (adsets_full['leads'] > 0) |
        (adsets_full['conversions'] > 0)
    ].copy()

    logger.info(f"   üìä Adsets ap√≥s filtro (removidos com spend=0 e leads=0): {len(adsets_full)}")

    adsets_full['cpl'] = adsets_full['spend'] / adsets_full['leads'].replace(0, 1)
    adsets_full['cpa'] = adsets_full['spend'] / adsets_full['conversions'].replace(0, 1)
    adsets_full['conversion_rate'] = (adsets_full['conversions'] / adsets_full['leads'].replace(0, 1)) * 100
    # NOTA: 'revenue' j√° vem do matched_df com valores reais de venda, n√£o usar product_value fixo
    # adsets_full['revenue'] j√° foi preenchida no merge acima
    adsets_full['roas'] = adsets_full['revenue'] / adsets_full['spend'].replace(0, 1)
    adsets_full['margin'] = adsets_full['revenue'] - adsets_full['spend']
    adsets_full['margin_pct'] = (adsets_full['margin'] / adsets_full['revenue'].replace(0, 1)) * 100

    # Agrega√ß√£o ML vs Controle
    aggregated = adsets_full.groupby('ml_type').agg({
        'adset_name': 'nunique',
        'spend': 'sum',
        'leads': 'sum',
        'conversions': 'sum',
        'cpl': 'mean',
        'cpa': 'mean',
        'conversion_rate': 'mean',
        'roas': 'mean',
        'margin': 'sum',
        'margin_pct': 'mean'
    }).reset_index()

    # Detalhamento adset-a-adset (CADA CAMPANHA SEPARADA - N√ÉO AGREGAR)
    # MUDAN√áA IMPORTANTE: N√£o agrupar por adset_name
    # Cada linha representa um adset de uma campanha espec√≠fica
    # Exemplo: "ADV | Lookalike 1%" na campanha A √© diferente de "ADV | Lookalike 1%" na campanha B
    detailed = adsets_full[['campaign_name', 'campaign_id', 'adset_name', 'adset_id', 'ml_type',
                             'spend', 'leads', 'conversions', 'cpl', 'cpa',
                             'conversion_rate', 'roas', 'revenue', 'margin', 'margin_pct']].copy()

    # Adicionar account_id baseado no adset_id
    # O account_name vem do MetaReportsLoader (extra√≠do do nome do arquivo Excel)
    if '_account_name' in adsets_metrics_df.columns:
        account_map = adsets_metrics_df[['adset_id', '_account_name']].drop_duplicates().set_index('adset_id')['_account_name'].to_dict()
        detailed['account_id'] = detailed['adset_id'].map(account_map)
    elif 'account_id' in adsets_metrics_df.columns:
        account_map = adsets_metrics_df[['adset_id', 'account_id']].drop_duplicates().set_index('adset_id')['account_id'].to_dict()
        detailed['account_id'] = detailed['adset_id'].map(account_map)
    else:
        detailed['account_id'] = None

    # IMPORTANTE: Adsets herdam a classifica√ß√£o da CAMPANHA PAI
    # N√£o reclassificamos por optimization_goal do adset para manter consist√™ncia
    # A classifica√ß√£o j√° foi feita no n√≠vel de campanha considerando optimization_goal

    # Buscar optimization_goal apenas para refer√™ncia (n√£o para reclassificar)
    if 'optimization_goal' in adsets_metrics_df.columns:
        optimization_map = adsets_metrics_df[['adset_id', 'optimization_goal']].drop_duplicates().set_index('adset_id')['optimization_goal'].to_dict()
        detailed['optimization_goal'] = detailed['adset_id'].map(optimization_map)
    else:
        detailed['optimization_goal'] = None

    # Adicionar comparison_group HERDADO da campanha
    if comparison_group_map:
        # NOVO: Usar mapeamento refinado direto (j√° distingue Eventos ML vs Otimiza√ß√£o ML)
        # IMPORTANTE: Usar primeiros 15 d√≠gitos para matching (mesma l√≥gica do comparison_group_map)
        detailed['campaign_id_15'] = detailed['campaign_id'].astype(str).str[:15]

        # DEBUG: Verificar mapeamento antes de aplicar
        logger.info(f"\n   üîç DEBUG ADSETS - Verificando mapeamento comparison_group:")
        logger.info(f"      Total de IDs no mapa: {len(comparison_group_map)}")
        logger.info(f"      Total de adsets: {len(detailed)}")
        logger.info(f"      IDs √∫nicos nos adsets (15 dig): {detailed['campaign_id_15'].nunique()}")

        # DEBUG: Mostrar mapeamento das campanhas ML
        logger.info(f"\n      Mapeamento de campanhas ML:")
        for id_15, group in comparison_group_map.items():
            if 'ML' in group or group == 'Eventos ML':
                logger.info(f"         {id_15} ‚Üí {group}")

        # Verificar se h√° IDs que n√£o fazem match
        ids_in_detailed = set(detailed['campaign_id_15'].unique())
        ids_in_map = set(comparison_group_map.keys())
        ids_not_in_map = ids_in_detailed - ids_in_map
        if ids_not_in_map:
            logger.warning(f"      ‚ö†Ô∏è {len(ids_not_in_map)} IDs de adsets N√ÉO encontrados no mapa:")
            for id_val in list(ids_not_in_map)[:5]:
                # Mostrar o nome da campanha correspondente
                sample_adset = detailed[detailed['campaign_id_15'] == id_val].iloc[0]
                logger.warning(f"         ‚Ä¢ ID 15: {id_val} ‚Üí {sample_adset['campaign_name'][:50]}")

        detailed['comparison_group'] = detailed['campaign_id_15'].map(comparison_group_map)

        # DEBUG: Verificar se h√° NaN ap√≥s mapeamento
        unmapped_count = detailed['comparison_group'].isna().sum()
        if unmapped_count > 0:
            logger.warning(f"      ‚ö†Ô∏è {unmapped_count} adsets sem grupo ap√≥s mapeamento (NaN)")

        logger.info("   ‚úÖ Usando mapeamento refinado (Eventos ML / Otimiza√ß√£o ML / Controle)")
    else:
        # LEGACY: Converter ml_type para comparison_group (sem distin√ß√£o Eventos/Otimiza√ß√£o)
        def classify_comparison_group_from_ml_type(row):
            """Convers√£o legacy: ml_type ‚Üí comparison_group (sem refinamento)"""
            ml_type = row['ml_type']
            if ml_type == 'COM_ML':
                return 'Eventos ML'  # Assume todos ML s√£o Eventos (n√£o ideal)
            elif ml_type == 'SEM_ML':
                return 'Controle'
            else:
                return 'Outro'

        detailed['comparison_group'] = detailed.apply(classify_comparison_group_from_ml_type, axis=1)
        logger.warning("   ‚ö†Ô∏è Usando mapeamento legacy (sem distin√ß√£o Eventos ML vs Otimiza√ß√£o ML)")

    # Filtrar apenas "Eventos ML" vs "Controle" (excluir "Otimiza√ß√£o ML" e "Outro")
    before_filter = len(detailed)
    conversions_before_filter = detailed['conversions'].sum()

    # DEBUG: Verificar quais convers√µes ser√£o removidas pelo filtro
    removed_by_filter = detailed[~detailed['comparison_group'].isin(['Eventos ML', 'Controle'])].copy()
    if len(removed_by_filter) > 0:
        convs_removed = removed_by_filter['conversions'].sum()
        logger.warning(f"\n   üîç CONVERS√ïES REMOVIDAS PELO FILTRO (Otimiza√ß√£o ML / Outro):")
        logger.warning(f"      Adsets removidos: {len(removed_by_filter)}")
        logger.warning(f"      Convers√µes removidas: {convs_removed:.0f}")

        # Mostrar breakdown por comparison_group
        by_group = removed_by_filter.groupby('comparison_group').agg({
            'adset_name': 'count',
            'conversions': 'sum'
        }).reset_index()
        by_group.columns = ['Grupo', 'Adsets', 'Convers√µes']
        logger.warning(f"\n      Breakdown por grupo:")
        for _, row in by_group.iterrows():
            logger.warning(f"         {row['Grupo']}: {row['Adsets']} adsets, {row['Convers√µes']:.0f} convers√µes")

        # Mostrar detalhes de cada adset removido
        logger.warning(f"\n      Detalhes dos adsets removidos:")
        for idx, row in removed_by_filter.iterrows():
            logger.warning(f"      ‚Ä¢ [{row['comparison_group']}] {row['campaign_name'][:60]}")
            logger.warning(f"        Adset: {row['adset_name'][:60]}")
            logger.warning(f"        Convers√µes: {row['conversions']:.0f}")
            logger.warning(f"        Campaign ID (completo): {row['campaign_id']}")
            logger.warning(f"        Campaign ID (15 d√≠gitos): {str(row['campaign_id'])[:15]}")

            # Buscar emails espec√≠ficos deste adset em matched_df
            if 'campaign' in matched_df.columns and 'medium' in matched_df.columns:
                # Construir o nome completo da campanha como aparece no matched_df
                campaign_variations = [
                    row['campaign_name'],
                    f"{row['campaign_name']}|{row['campaign_id']}",
                    f"{row['campaign_name'].rstrip('|')}|{row['campaign_id']}"
                ]

                matching_rows = pd.DataFrame()
                for camp_var in campaign_variations:
                    matches = matched_df[
                        (matched_df['campaign'] == camp_var) &
                        (matched_df['medium'] == row['adset_name']) &
                        (matched_df['converted'] == True)
                    ]
                    if len(matches) > 0:
                        matching_rows = matches
                        break

                if len(matching_rows) > 0:
                    emails = matching_rows['email'].unique()
                    logger.warning(f"        Emails ({len(emails)}): {', '.join(emails[:5])}{' ...' if len(emails) > 5 else ''}")
                else:
                    logger.warning(f"        ‚ö†Ô∏è  N√£o encontrei os emails correspondentes em matched_df")
        logger.warning("")

    detailed = detailed[detailed['comparison_group'].isin(['Eventos ML', 'Controle'])].copy()
    after_filter = len(detailed)
    conversions_after_filter = detailed['conversions'].sum()

    if before_filter != after_filter:
        logger.info(f"   üîç Filtrados {before_filter - after_filter} adsets (Otimiza√ß√£o ML ou Outro)")
        logger.info(f"   üìä Convers√µes: {conversions_before_filter:.0f} ‚Üí {conversions_after_filter:.0f} ({conversions_before_filter - conversions_after_filter:.0f} removidas)")

    logger.info("   ‚úÖ Compara√ß√µes de adsets calculadas")
    logger.info(f"      Adsets ap√≥s filtro (Eventos ML + Controle): {len(detailed)}")

    return {
        'aggregated': aggregated,
        'detailed': detailed
    }


def compare_ad_performance(
    ad_metrics_df: pd.DataFrame,
    matched_df: pd.DataFrame,
    ml_type_map: Dict[str, str],
    product_value: float = 2000.0,
    comparison_group_map: Optional[Dict[str, str]] = None
) -> Dict[str, pd.DataFrame]:
    """
    Compara performance de an√∫ncios entre ML e Controle.

    IMPORTANTE: Usa matching preciso por (Campaign ID + ad_code).
    Mesma l√≥gica dos adsets, mas usando utm_content em vez de utm_medium.

    Args:
        ad_metrics_df: DataFrame com m√©tricas de an√∫ncios (da Meta API)
        matched_df: DataFrame com convers√µes matched (leads‚Üívendas)
        ml_type_map: Mapeamento campaign_id ‚Üí ml_type (DEPRECATED - usar comparison_group_map)
        product_value: Valor do produto em R$
        comparison_group_map: Mapeamento campaign_id ‚Üí comparison_group ('Eventos ML', 'Otimiza√ß√£o ML', 'Controle')

    Returns:
        Dict com DataFrames:
        - 'aggregated': Agrega√ß√£o ML vs Controle
        - 'detailed': Detalhamento an√∫ncio-a-an√∫ncio
    """
    logger.info("üìä Comparando performance de an√∫ncios...")

    # Adicionar ml_type aos an√∫ncios (para compatibilidade)
    ad_metrics_df['ml_type'] = ad_metrics_df['campaign_id'].map(ml_type_map)

    # Se temos comparison_group_map, usar ele diretamente (novo comportamento)
    if comparison_group_map:
        ad_metrics_df['comparison_group_from_campaign'] = ad_metrics_df['campaign_id'].map(comparison_group_map)

    # Criar coluna account_id se n√£o existir (pode vir como _account_name)
    if 'account_id' not in ad_metrics_df.columns and '_account_name' in ad_metrics_df.columns:
        ad_metrics_df['account_id'] = ad_metrics_df['_account_name']

    # =========================================================================
    # MATCHING PRECISO DE AN√öNCIOS (mesma l√≥gica dos adsets)
    # =========================================================================

    # Fun√ß√£o para extrair Campaign ID (reutilizar a mesma dos adsets)
    def extract_campaign_id(campaign_name):
        """Extrai o Campaign ID do final do nome da campanha"""
        if pd.isna(campaign_name):
            return None
        parts = str(campaign_name).split('|')
        if len(parts) > 1:
            last_part = parts[-1].strip()
            if last_part.isdigit() and len(last_part) >= 18:
                return last_part
        return None

    # Calcular convers√µes por AN√öNCIO (matching preciso!)
    if 'converted' in matched_df.columns:
        conversions_df = matched_df[matched_df['converted'] == True].copy()

        # 1. Extrair Campaign ID do utm_campaign
        conversions_df['campaign_id_from_utm'] = conversions_df['campaign'].apply(extract_campaign_id)

        # 2. Extrair ad_code do utm_content (padr√£o: AD0\d+)
        conversions_df['ad_code_from_utm'] = conversions_df['content'].str.extract(r'(AD0\d+)', expand=False)

        # DEBUG
        content_filled = conversions_df['content'].notna().sum()
        ad_code_extracted = conversions_df['ad_code_from_utm'].notna().sum()
        logger.info(f"\n   üîç Extra√ß√£o de ad_code das convers√µes:")
        logger.info(f"      Total convers√µes: {len(conversions_df)}")
        logger.info(f"      utm_content preenchido: {content_filled} ({content_filled/len(conversions_df)*100:.1f}%)")
        logger.info(f"      ad_code extra√≠do: {ad_code_extracted} ({ad_code_extracted/len(conversions_df)*100:.1f}%)")

        # 3. Preparar campaign_id_clean (primeiros 15 d√≠gitos)
        conversions_df['campaign_id_clean'] = conversions_df['campaign_id_from_utm'].astype(str).str[:15]

        # 4. Agrupar por (campaign_id_clean, ad_code) - MATCHING PRECISO E calcular RECEITA REAL
        # CR√çTICO: Contar emails √∫nicos para convers√µes, somar sale_value para receita
        conversions_by_campaign_ad = conversions_df.groupby(
            ['campaign_id_clean', 'ad_code_from_utm']
        ).agg({
            'email': 'nunique',  # Convers√µes √∫nicas
            'sale_value': 'sum'   # Receita real total
        }).reset_index()
        conversions_by_campaign_ad.columns = ['campaign_id_clean', 'ad_code_from_utm', 'conversions', 'revenue']

        logger.info(f"      Agrupadas por (Campaign ID + ad_code): {len(conversions_by_campaign_ad)}")

        # 5. Calcular LEADS por an√∫ncio (usar TODO o matched_df, n√£o s√≥ convers√µes)
        logger.info(f"\n   üìä Calculando leads por an√∫ncio:")

        # Extrair ad_code de TODOS os leads
        all_leads_df = matched_df.copy()
        all_leads_df['campaign_id_from_utm'] = all_leads_df['campaign'].apply(extract_campaign_id)
        all_leads_df['ad_code_from_utm'] = all_leads_df['content'].str.extract(r'(AD0\d+)', expand=False)
        all_leads_df['campaign_id_clean'] = all_leads_df['campaign_id_from_utm'].astype(str).str[:15]

        # Agrupar por (campaign_id_clean, ad_code) para contar leads
        leads_by_campaign_ad = all_leads_df[all_leads_df['ad_code_from_utm'].notna()].groupby(
            ['campaign_id_clean', 'ad_code_from_utm']
        ).size().reset_index(name='leads')

        logger.info(f"      Total de leads com ad_code: {leads_by_campaign_ad['leads'].sum()}")
        logger.info(f"      Combina√ß√µes √∫nicas (Campaign ID + ad_code): {len(leads_by_campaign_ad)}")

        # 6. Preparar ad_metrics_df para merge
        ad_metrics_df['campaign_id_clean'] = ad_metrics_df['campaign_id'].astype(str).str[:15]

        # 7. AGREGA√á√ÉO: Consolidar an√∫ncios com mesmo (campaign_id, ad_code)
        #    Mesmo ad_code pode ter m√∫ltiplos ad_ids no Excel ‚Üí somar spend
        logger.info(f"\n   üìä Agregando an√∫ncios com mesmo (Campaign ID + ad_code):")
        logger.info(f"      Total de linhas no Excel: {len(ad_metrics_df)}")

        ad_metrics_aggregated = ad_metrics_df.groupby(['campaign_id_clean', 'ad_code', 'ml_type'], dropna=False).agg({
            'spend': 'sum',
            'campaign_id': 'first',  # Manter ID original
            'campaign_name': 'first',  # Manter nome
            'ad_name': 'first',  # Manter nome do primeiro ad
            'adset_name': 'first',  # Nome do adset
            'account_id': 'first'  # Account ID
        }).reset_index()

        logger.info(f"      Total ap√≥s agrega√ß√£o: {len(ad_metrics_aggregated)}")
        logger.info(f"      An√∫ncios consolidados: {len(ad_metrics_df) - len(ad_metrics_aggregated)}")

        # 8. Merge LEADS por (campaign_id_clean, ad_code)
        ad_full = ad_metrics_aggregated.merge(
            leads_by_campaign_ad,
            left_on=['campaign_id_clean', 'ad_code'],
            right_on=['campaign_id_clean', 'ad_code_from_utm'],
            how='left',
            suffixes=('', '_leads')
        )

        ad_full['leads'] = ad_full['leads'].fillna(0)

        # 9. Merge CONVERS√ïES E RECEITA REAL por (campaign_id_clean, ad_code)
        ad_full = ad_full.merge(
            conversions_by_campaign_ad,
            left_on=['campaign_id_clean', 'ad_code'],
            right_on=['campaign_id_clean', 'ad_code_from_utm'],
            how='left',
            suffixes=('', '_conv')
        )

        ad_full['conversions'] = ad_full['conversions'].fillna(0)
        ad_full['revenue'] = ad_full['revenue'].fillna(0)  # Receita real do matched_df

        logger.info(f"   ‚úÖ An√∫ncios com leads: {(ad_full['leads'] > 0).sum()}")
        logger.info(f"   ‚úÖ An√∫ncios com convers√µes: {(ad_full['conversions'] > 0).sum()}")
        logger.info(f"   üìä Total leads: {ad_full['leads'].sum():.0f}")
        logger.info(f"   üìä Total convers√µes atribu√≠das: {ad_full['conversions'].sum():.0f}")

    else:
        ad_metrics_df['campaign_id_clean'] = ad_metrics_df['campaign_id'].astype(str).str[:15]
        ad_full = ad_metrics_df.copy()
        ad_full['conversions'] = 0
        ad_full['leads'] = 0
        ad_full['revenue'] = 0

    # =========================================================================
    # CALCULAR M√âTRICAS DE NEG√ìCIO
    # =========================================================================

    # Calcular m√©tricas
    ad_full['cpl'] = ad_full['spend'] / ad_full['leads'].replace(0, 1)
    ad_full['cpa'] = ad_full['spend'] / ad_full['conversions'].replace(0, 1)
    ad_full['conversion_rate'] = (ad_full['conversions'] / ad_full['leads'].replace(0, 1)) * 100
    # NOTA: 'revenue' j√° vem do matched_df com valores reais de venda, n√£o usar product_value fixo
    # ad_full['revenue'] j√° foi preenchida no merge acima
    ad_full['roas'] = ad_full['revenue'] / ad_full['spend'].replace(0, 1)
    ad_full['margin'] = ad_full['revenue'] - ad_full['spend']
    ad_full['margin_pct'] = (ad_full['margin'] / ad_full['revenue'].replace(0, 1)) * 100

    # CORRE√á√ÉO: Adicionar comparison_group ANTES de criar agrega√ß√µes
    # Preparar campaign_id_15 para matching
    ad_full['campaign_id_15'] = ad_full['campaign_id'].astype(str).str[:15]

    # Aplicar comparison_group_map
    if comparison_group_map:
        ad_full['comparison_group'] = ad_full['campaign_id_15'].map(comparison_group_map)
        logger.info("   ‚úÖ Usando mapeamento refinado (Eventos ML / Otimiza√ß√£o ML / Controle)")
    else:
        # Fallback para ml_type
        ad_full['comparison_group'] = ad_full['ml_type'].map({
            'COM_ML': 'Eventos ML',
            'SEM_ML': 'Controle'
        })
        logger.warning("   ‚ö†Ô∏è comparison_group_map n√£o dispon√≠vel, usando classifica√ß√£o simples")

    # FILTRAR antes de agregar: apenas Eventos ML e Controle
    before_filter_count = len(ad_full)
    ad_full_filtered = ad_full[ad_full['comparison_group'].isin(['Eventos ML', 'Controle'])].copy()
    after_filter_count = len(ad_full_filtered)

    if before_filter_count != after_filter_count:
        logger.info(f"   üîç Filtrados {before_filter_count - after_filter_count} ads (Otimiza√ß√£o ML ou Outro) ANTES da agrega√ß√£o")

    # Agrega√ß√£o por comparison_group (N√ÉO ml_type)
    aggregated = ad_full_filtered.groupby('comparison_group').agg({
        'ad_code': 'nunique',
        'spend': 'sum',
        'leads': 'sum',
        'conversions': 'sum',
        'cpl': 'mean',
        'cpa': 'mean',
        'conversion_rate': 'mean',
        'roas': 'mean',
        'margin': 'sum',
        'margin_pct': 'mean'
    }).reset_index()

    # Detalhamento an√∫ncio-a-an√∫ncio (incluir informa√ß√µes contextuais)
    # USAR ad_full_filtered para garantir que apenas Eventos ML e Controle sejam inclu√≠dos
    detailed = ad_full_filtered.groupby(['ad_code', 'comparison_group']).agg({
        'campaign_name': 'first',  # Nome da campanha
        'campaign_id': 'first',  # ID da campanha (para buscar optimization_goal)
        'account_id': 'first',  # Account ID
        'adset_name': 'first',  # Nome do adset
        'ad_name': 'first',  # Nome do an√∫ncio
        'ml_type': 'first',  # Manter ml_type para compatibilidade
        'spend': 'sum',
        'leads': 'sum',
        'conversions': 'sum',
        'cpl': 'mean',
        'cpa': 'mean',
        'conversion_rate': 'mean',
        'roas': 'mean',
        'revenue': 'sum',
        'margin': 'sum',
        'margin_pct': 'mean'
    }).reset_index()

    # IMPORTANTE: Ads herdam a classifica√ß√£o da CAMPANHA PAI
    # N√£o reclassificamos por optimization_goal do ad para manter consist√™ncia
    # A classifica√ß√£o j√° foi feita no n√≠vel de campanha considerando optimization_goal

    # Buscar optimization_goal apenas para refer√™ncia (n√£o para reclassificar)
    if 'optimization_goal' in ad_metrics_df.columns:
        optimization_map = ad_metrics_df[['campaign_id', 'optimization_goal']].drop_duplicates().set_index('campaign_id')['optimization_goal'].to_dict()
        detailed['optimization_goal'] = detailed['campaign_id'].map(optimization_map)
    else:
        detailed['optimization_goal'] = None

    # NOTA: comparison_group j√° foi adicionado ao ad_full nas linhas 1086-1095 e
    # o DataFrame foi filtrado (apenas Eventos ML e Controle) nas linhas 1097-1099.
    # O 'detailed' foi criado a partir do ad_full_filtered j√° filtrado (linhas 1118-1137),
    # ent√£o n√£o √© necess√°rio adicionar comparison_group ou filtrar novamente aqui.

    logger.info(f"   ‚úÖ Compara√ß√µes de an√∫ncios calculadas")
    logger.info(f"      An√∫ncios ap√≥s filtro (Eventos ML + Controle): {len(detailed)}")

    return {
        'aggregated': aggregated,
        'detailed': detailed
    }


def compare_ads_in_matched_adsets(
    ad_metrics_df: pd.DataFrame,
    matched_df: pd.DataFrame,
    ml_type_map: Dict[str, str],
    product_value: float = 2000.0,
    comparison_group_map: Optional[Dict[str, str]] = None,
    filtered_matched_adsets: Optional[List[str]] = None
) -> Dict[str, pd.DataFrame]:
    """
    Compara performance de an√∫ncios que pertencem APENAS aos adsets matched.

    DIFEREN√áA vs compare_ad_performance:
    - compare_ad_performance: todos os ads da lista MATCHED_ADS
    - compare_ads_in_matched_adsets: apenas ads cujo adset pai est√° em MATCHED_ADSETS

    Args:
        ad_metrics_df: DataFrame com m√©tricas de an√∫ncios (da Meta API)
        matched_df: DataFrame com convers√µes matched (leads‚Üívendas)
        ml_type_map: Mapeamento campaign_id ‚Üí ml_type
        product_value: Valor do produto em R$
        comparison_group_map: Mapeamento campaign_id ‚Üí comparison_group
        filtered_matched_adsets: Lista de adsets matched que passaram nos filtros (comparison_group).
                                 Se None, usa a lista hardcoded MATCHED_ADSETS.

    Returns:
        Dict com DataFrames:
        - 'aggregated': Agrega√ß√£o ML vs Controle
        - 'detailed': Detalhamento an√∫ncio-a-an√∫ncio
    """
    logger.info("üìä Comparando performance de an√∫ncios EM adsets matched...")

    # CORRE√á√ÉO: Usar lista filtrada de adsets em vez da hardcoded
    # Isso garante que apenas ads de adsets "Eventos ML" e "Controle" sejam inclu√≠dos
    # (excluindo "Otimiza√ß√£o ML" e outros)
    adsets_to_use = filtered_matched_adsets if filtered_matched_adsets is not None else MATCHED_ADSETS

    logger.info(f"   üìã Usando {len(adsets_to_use)} adsets matched (filtrados por comparison_group)")

    # Filtrar apenas ads cujo adset pai est√° na lista filtrada
    ads_in_matched_adsets = ad_metrics_df[
        ad_metrics_df['adset_name'].isin(adsets_to_use)
    ].copy()

    logger.info(f"   üìã Ads em adsets matched: {len(ads_in_matched_adsets)}")
    logger.info(f"   üìã Ad codes √∫nicos: {ads_in_matched_adsets['ad_name'].nunique()}")

    if len(ads_in_matched_adsets) == 0:
        logger.warning("   ‚ö†Ô∏è Nenhum ad encontrado nos adsets matched!")
        return {
            'aggregated': pd.DataFrame(),
            'detailed': pd.DataFrame()
        }

    # Usar a mesma l√≥gica de compare_ad_performance, mas com o DataFrame filtrado
    return compare_ad_performance(
        ads_in_matched_adsets,
        matched_df,
        ml_type_map,
        product_value,
        comparison_group_map
    )


def compare_matched_ads_in_matched_adsets(
    ad_metrics_df: pd.DataFrame,
    matched_df: pd.DataFrame,
    ml_type_map: Dict[str, str],
    product_value: float = 2000.0,
    comparison_group_map: Optional[Dict[str, str]] = None,
    filtered_matched_adsets: Optional[List[str]] = None
) -> Dict[str, pd.DataFrame]:
    """
    Compara performance de an√∫ncios MATCHED que pertencem APENAS aos adsets matched.

    Combina dois filtros:
    1. Apenas adsets matched (aparecem em ML e Controle)
    2. Dentro desses adsets, apenas ads matched (ad_code aparece em ML e Controle)

    Args:
        ad_metrics_df: DataFrame com m√©tricas de an√∫ncios
        matched_df: DataFrame com dados de matching leads-vendas
        ml_type_map: Dict mapeando campaign_id para ml_type (COM_ML/SEM_ML)
        product_value: Valor do produto para c√°lculo de receita
        comparison_group_map: Dict mapeando campaign_id (15 d√≠gitos) para grupo de compara√ß√£o
        filtered_matched_adsets: Lista de adsets matched que passaram nos filtros

    Returns:
        Dict com 'aggregated' e 'detailed' DataFrames
    """
    logger.info("üìä Comparando ads MATCHED em adsets MATCHED...")

    # PASSO 1: Filtrar apenas ads dos adsets matched
    adsets_to_use = filtered_matched_adsets if filtered_matched_adsets is not None else MATCHED_ADSETS

    logger.info(f"   üìã Usando {len(adsets_to_use)} adsets matched (filtrados por comparison_group)")

    ads_in_matched_adsets = ad_metrics_df[
        ad_metrics_df['adset_name'].isin(adsets_to_use)
    ].copy()

    logger.info(f"   üìã Ads em adsets matched: {len(ads_in_matched_adsets)}")

    if len(ads_in_matched_adsets) == 0:
        logger.warning("   ‚ö†Ô∏è Nenhum ad encontrado nos adsets matched!")
        return {
            'aggregated': pd.DataFrame(),
            'detailed': pd.DataFrame()
        }

    # PASSO 2: Identificar ad_codes matched (aparecem em ML E Controle)
    # Preparar campaign_id_15 e comparison_group
    ads_in_matched_adsets['campaign_id_15'] = ads_in_matched_adsets['campaign_id'].astype(str).str[:15]

    if comparison_group_map:
        ads_in_matched_adsets['comparison_group'] = ads_in_matched_adsets['campaign_id_15'].map(comparison_group_map)
    else:
        ads_in_matched_adsets['comparison_group'] = ads_in_matched_adsets['campaign_id'].map(ml_type_map).map({
            'COM_ML': 'Eventos ML',
            'SEM_ML': 'Controle'
        })

    # Filtrar apenas Eventos ML e Controle
    ads_filtered = ads_in_matched_adsets[
        ads_in_matched_adsets['comparison_group'].isin(['Eventos ML', 'Controle'])
    ].copy()

    logger.info(f"   üìã Ads ap√≥s filtro de comparison_group: {len(ads_filtered)}")

    # Identificar quais ad_codes aparecem em AMBOS os grupos
    ad_codes_by_group = ads_filtered.groupby('comparison_group')['ad_code'].unique()

    if 'Eventos ML' not in ad_codes_by_group or 'Controle' not in ad_codes_by_group:
        logger.warning("   ‚ö†Ô∏è N√£o h√° ad_codes em ambos os grupos!")
        return {
            'aggregated': pd.DataFrame(),
            'detailed': pd.DataFrame()
        }

    eventos_ml_codes = set(ad_codes_by_group['Eventos ML'])
    controle_codes = set(ad_codes_by_group['Controle'])
    matched_ad_codes = eventos_ml_codes & controle_codes

    logger.info(f"   üìã Ad codes matched (aparecem em ML E Controle): {len(matched_ad_codes)}")
    logger.info(f"      Eventos ML: {len(eventos_ml_codes)} c√≥digos")
    logger.info(f"      Controle: {len(controle_codes)} c√≥digos")
    logger.info(f"      Interse√ß√£o: {len(matched_ad_codes)} c√≥digos")

    if len(matched_ad_codes) == 0:
        logger.warning("   ‚ö†Ô∏è Nenhum ad_code matched encontrado!")
        return {
            'aggregated': pd.DataFrame(),
            'detailed': pd.DataFrame()
        }

    # PASSO 3: Filtrar apenas ads com ad_codes matched
    matched_ads_only = ads_filtered[
        ads_filtered['ad_code'].isin(matched_ad_codes)
    ].copy()

    logger.info(f"   üìã Ads finais (matched em adsets matched): {len(matched_ads_only)}")

    # PASSO 4: Calcular m√©tricas usando a mesma l√≥gica de compare_ad_performance
    return compare_ad_performance(
        matched_ads_only,
        matched_df,
        ml_type_map,
        product_value,
        comparison_group_map
    )


# ============================================================================
# FUN√á√ïES DE FORMATA√á√ÉO PARA EXCEL
# ============================================================================

def prepare_adset_comparison_for_excel(
    comparisons: Dict[str, pd.DataFrame]
) -> Dict[str, pd.DataFrame]:
    """
    Prepara DataFrames de compara√ß√£o por adset para Excel.
    Formato similar √† aba "Compara√ß√£o por Campanhas".

    Args:
        comparisons: Dict com 'aggregated' e 'detailed'

    Returns:
        Dict com DataFrames formatados para Excel
    """
    logger.info("üìù Preparando compara√ß√µes por adset para Excel...")

    excel_dfs = {}

    # Usar apenas 'detailed' com formato similar √† aba Campanhas
    if not comparisons['detailed'].empty:
        df = comparisons['detailed'].copy()

        # Renomear e reordenar colunas para formato similar √† aba Campanhas
        df = df.rename(columns={
            'account_id': 'Conta',
            'comparison_group': 'Grupo',
            'campaign_name': 'Campanha',
            'campaign_id': 'Campaign ID',
            'adset_name': 'Adset',
            'adset_id': 'Adset ID',
            'leads': 'Leads',
            'conversions': 'Vendas',
            'conversion_rate': 'Taxa de convers√£o',
            'spend': 'Valor gasto',
            'cpl': 'CPL',
            'roas': 'ROAS',
            'revenue': 'Receita Total',
            'margin': 'Margem de contribui√ß√£o'
        })

        # Mapear account_id para nomes amig√°veis
        if 'Conta' in df.columns:
            def clean_account_name(x):
                if pd.isna(x):
                    return 'N/A'
                x = str(x)
                # Se √© um ID de conta
                if x.startswith('act_'):
                    account_ids = {
                        'act_188005769808959': 'Rodolfo Mori',
                        'act_786790755803474': 'Gestor de IA'
                    }
                    return account_ids.get(x, x)
                # Se √© nome de arquivo, extrair nome da conta
                if 'Rodolfo Mori' in x:
                    return 'Rodolfo Mori'
                elif 'Gestor de IA' in x:
                    return 'Gestor de IA'
                return x

            df['Conta'] = df['Conta'].apply(clean_account_name)

        # Calcular receita total se n√£o existir
        if 'Receita Total' not in df.columns and 'Vendas' in df.columns:
            df['Receita Total'] = df['Vendas'] * 2000.0  # product_value

        # Selecionar e ordenar colunas (similar √† aba Campanhas, com Conta primeiro)
        columns_order = [
            'Conta', 'Campanha', 'Campaign ID', 'Adset', 'Adset ID', 'Grupo', 'Leads', 'Vendas',
            'Taxa de convers√£o', 'Valor gasto', 'CPL', 'ROAS',
            'Receita Total', 'Margem de contribui√ß√£o'
        ]

        # Incluir apenas colunas que existem
        available_columns = [col for col in columns_order if col in df.columns]
        df = df[available_columns]

        # Ordenar por ROAS descendente
        if 'ROAS' in df.columns:
            df = df.sort_values('ROAS', ascending=False)

        excel_dfs['comparacao_adsets'] = df

    logger.info(f"   ‚úÖ {len(excel_dfs)} abas preparadas para Excel")

    return excel_dfs


def prepare_ad_comparison_for_excel(
    comparisons: Dict[str, pd.DataFrame]
) -> Dict[str, pd.DataFrame]:
    """
    Prepara DataFrames de compara√ß√£o por an√∫ncio para Excel.
    Formato similar √† aba "Compara√ß√£o por Adsets".

    Args:
        comparisons: Dict com 'aggregated' e 'detailed'

    Returns:
        Dict com DataFrames formatados para Excel
    """
    logger.info("üìù Preparando compara√ß√µes por an√∫ncio para Excel...")

    excel_dfs = {}

    # Usar 'detailed' com formato similar √† aba Adsets
    if 'detailed' in comparisons and not comparisons['detailed'].empty:
        df = comparisons['detailed'].copy()

        # Renomear colunas (adicionar IDs de campanha e adset)
        df = df.rename(columns={
            'comparison_group': 'Grupo',
            'campaign_id': 'Campaign ID',
            'adset_id': 'Adset ID',
            'ad_code': 'Ad Code',
            'ad_name': 'Nome do An√∫ncio',
            'leads': 'Leads',
            'conversions': 'Vendas',
            'conversion_rate': 'Taxa de convers√£o',
            'spend': 'Valor gasto',
            'cpl': 'CPL',
            'roas': 'ROAS',
            'revenue': 'Receita Total',
            'margin': 'Margem de contribui√ß√£o'
        })

        # Calcular receita total se n√£o existir
        if 'Receita Total' not in df.columns and 'Vendas' in df.columns:
            df['Receita Total'] = df['Vendas'] * 2000.0  # product_value

        # Selecionar e ordenar colunas (incluir IDs)
        columns_order = [
            'Campaign ID', 'Adset ID', 'Ad Code', 'Nome do An√∫ncio', 'Grupo',
            'Leads', 'Vendas', 'Taxa de convers√£o', 'Valor gasto', 'CPL', 'ROAS',
            'Receita Total', 'Margem de contribui√ß√£o'
        ]

        # Incluir apenas colunas que existem
        available_columns = [col for col in columns_order if col in df.columns]
        df = df[available_columns]

        # Ordenar por ROAS descendente
        if 'ROAS' in df.columns:
            df = df.sort_values('ROAS', ascending=False)

        excel_dfs['comparacao_ads'] = df

    logger.info(f"   ‚úÖ {len(excel_dfs)} abas preparadas para Excel")

    return excel_dfs

# ============================================================================
# C√ìDIGO DE COMPATIBILIDADE COM VALIDATE_ML_PERFORMANCE.PY
# ============================================================================
# As se√ß√µes abaixo foram adicionadas para manter compatibilidade com o script
# principal (validate_ml_performance.py) que foi mantido na vers√£o do dia 16/12.
# TODO: Refatorar o script principal para usar as fun√ß√µes modernas acima.
# ============================================================================

# ============================================================================
# CONFIGURA√á√ÉO: N√çVEIS DE COMPARA√á√ÉO - EVENTO ML
# ============================================================================

# N√çVEL 1: Evento ML (adsets iguais)
# Compara√ß√£o rigorosa: mesma estrutura de adsets, budget similar
ADSETS_IGUAIS_CONFIG = {
    'name': 'Evento ML (adsets iguais)',
    'ml_campaigns': [
        '120236428684840390',  # ADV ML - CBO R$ 300/dia
        '120236428684850390',  # ADV ML - CBO R$ 300/dia
    ],
    'control_campaigns': [
        '120224064762630390',  # ADV Controle - CBO R$ 390/dia
        '120224064761980390',  # ADV Controle - CBO R$ 390/dia
    ],
    'matched_ads': [
        'AD0013', 'AD0014', 'AD0017', 'AD0018', 'AD0022', 'AD0033'
    ],
    'adset_names': [
        'ADV | Linguagem de programa√ß√£o',
        'ADV | Lookalike 1% Cadastrados - DEV 2.0 + Interesse Ci√™ncia da Computa√ß√£o',
        'ADV | Lookalike 2% Cadastrados - DEV 2.0 + Interesses',
        'ADV | Lookalike 2% Alunos + Interesse Linguagem de Programa√ß√£o',
    ],
    'filter_by_adset': True,
    'budget_tolerance': 0.30,  # 30%
}

# N√çVEL 2: Evento ML (todos)
# Compara√ß√£o geral: todas campanhas Evento ML, estruturas variadas
TODOS_CONFIG = {
    'name': 'Evento ML (todos)',
    'ml_campaigns': [
        '120236428684090390',  # ABERTO ML - CBO R$ 550/dia
        '120236428684840390',  # ADV ML - CBO R$ 300/dia
        '120236428684850390',  # ADV ML - CBO R$ 300/dia
    ],
    'control_campaigns': [
        '120220370119870390',  # ABERTO Controle - ABO
        '120224064762630390',  # ADV Controle - CBO R$ 390/dia
        '120224064761980390',  # ADV Controle - CBO R$ 390/dia
        '120224064762010390',  # ADV Controle
        '120224064762600390',  # ADV Controle
        '120228073033890390',  # ADV Controle
        '120230454190910390',  # ADV Controle
    ],
    'matched_ads': [
        'AD0004', 'AD0013', 'AD0014', 'AD0017', 'AD0018', 'AD0022', 'AD0027', 'AD0033'
    ],
    'filter_by_adset': False,
    'budget_tolerance': None,  # Sem restri√ß√£o
}


def get_comparison_config(comparison_level: str = 'adsets_iguais') -> Dict:
    """
    Retorna configura√ß√£o do n√≠vel de compara√ß√£o desejado.
    
    Args:
        comparison_level: 'adsets_iguais' ou 'todos'
    
    Returns:
        Dict com configura√ß√£o do n√≠vel
    """
    if comparison_level == 'adsets_iguais':
        return ADSETS_IGUAIS_CONFIG
    elif comparison_level == 'todos':
        return TODOS_CONFIG
    else:
        raise ValueError(f"N√≠vel desconhecido: {comparison_level}. Use 'adsets_iguais' ou 'todos'")
def filter_campaigns_by_level(
    campaigns_df: pd.DataFrame,
    ml_type: str,
    comparison_level: str = 'ultra_fair'
) -> pd.DataFrame:
    """
    Filtra campanhas de acordo com o n√≠vel de compara√ß√£o.

    Args:
        campaigns_df: DataFrame com todas as campanhas
        ml_type: 'eventos_ml' ou 'controle'
        comparison_level: 'ultra_fair' ou 'fair'

    Returns:
        DataFrame filtrado
    """
    config = get_comparison_config(comparison_level)

    if ml_type == 'eventos_ml':
        campaign_ids = config['ml_campaigns']
    elif ml_type == 'controle':
        campaign_ids = config['control_campaigns']
    else:
        raise ValueError(f"ml_type inv√°lido: {ml_type}. Use 'eventos_ml' ou 'controle'")

    # Filtrar campanhas
    filtered = campaigns_df[campaigns_df['campaign_id'].isin(campaign_ids)].copy()

    logger.info(
        f"Filtro {config['name']} ({ml_type}): "
        f"{len(filtered)} de {len(campaigns_df)} campanhas"
    )

    return filtered


def filter_ads_by_level(
    ads_df: pd.DataFrame,
    comparison_level: str = 'ultra_fair'
) -> pd.DataFrame:
    """
    Filtra an√∫ncios de acordo com o n√≠vel de compara√ß√£o.

    Para Ultra Fair: apenas matched ads do n√≠vel
    Para Fair: todos matched ads

    Args:
        ads_df: DataFrame com todos os an√∫ncios
        comparison_level: 'ultra_fair' ou 'fair'

    Returns:
        DataFrame filtrado
    """
    config = get_comparison_config(comparison_level)
    matched_ads = config['matched_ads']

    # Filtrar por ad_code
    if 'ad_code' in ads_df.columns:
        filtered = ads_df[ads_df['ad_code'].isin(matched_ads)].copy()
    else:
        logger.warning("Coluna 'ad_code' n√£o encontrada. Retornando DataFrame original.")
        return ads_df

    logger.info(
        f"Filtro {config['name']}: "
        f"{len(filtered)} de {len(ads_df)} an√∫ncios matched"
    )

    return filtered


def filter_ads_by_adset(
    ads_df: pd.DataFrame,
    comparison_level: str = 'ultra_fair'
) -> pd.DataFrame:
    """
    Filtra an√∫ncios que aparecem nos mesmos adsets (apenas para Ultra Fair).

    Args:
        ads_df: DataFrame com an√∫ncios (deve ter colunas 'adset_name' e 'ml_type')
        comparison_level: 'ultra_fair' ou 'fair'

    Returns:
        DataFrame filtrado
    """
    config = get_comparison_config(comparison_level)

    # Se n√£o filtrar por adset, retornar tudo
    if not config.get('filter_by_adset', False):
        return ads_df

    # Verificar colunas necess√°rias
    required_cols = ['adset_name', 'ml_type', 'ad_code']
    missing_cols = [col for col in required_cols if col not in ads_df.columns]
    if missing_cols:
        logger.warning(f"Colunas faltando para filtro de adset: {missing_cols}")
        return ads_df

    # Adsets v√°lidos
    valid_adsets = config.get('adset_names', [])
class FairCampaignMatcher:
    """
    Encontra campanhas de controle justo para compara√ß√£o com campanhas ML.

    Usa Meta Ads API para identificar campanhas n√£o-ML que sejam compar√°veis
    √†s campanhas ML em termos de spend, criativos e per√≠odo.
    """

    def __init__(self, account_id: str):
        """
        Inicializa o matcher com credenciais Meta API.

        Args:
            account_id: Meta Ads account ID (e.g., 'act_188005769808959')
        """
        self.account_id = account_id if account_id.startswith('act_') else f'act_{account_id}'
        self.access_token = META_CONFIG['access_token']

        # Cache para targeting (evitar chamadas repetidas √† API)
        self._targeting_cache = {}
        self._api_calls_count = 0
        self._cache_hits_count = 0

        try:
            FacebookAdsApi.init(access_token=self.access_token)
            self.account = AdAccount(self.account_id)
            self.api_available = True
            logger.info(f"‚úÖ Meta API inicializada: {self.account_id}")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar Meta API: {e}")
            self.api_available = False

    def get_ml_campaign_metadata(
        self,
        start_date: str,
        end_date: str
    ) -> Dict[str, Dict]:
        """
        Obt√©m metadata das campanhas ML (refer√™ncia para compara√ß√£o).

        Args:
            start_date: Data in√≠cio (YYYY-MM-DD)
            end_date: Data fim (YYYY-MM-DD)

        Returns:
            Dict com campaign_id ‚Üí {name, spend, creative_ids, impressions, ...}
        """
        if not self.api_available:
            logger.warning("‚ö†Ô∏è Meta API n√£o dispon√≠vel")
            return {}

        logger.info(f"üîç Buscando campanhas ML ({start_date} a {end_date})...")

        try:
            params = {
                'time_range': {'since': start_date, 'until': end_date},
                'level': 'campaign',
                'fields': [
                    'campaign_id',
                    'campaign_name',
                    'spend',
                    'impressions',
                    'clicks',
                    'actions',
                ],
                'filtering': [
                    {
                        'field': 'campaign.name',
                        'operator': 'CONTAIN',
                        'value': 'MACHINE LEARNING'
                    }
                ]
            }

            insights = self.account.get_insights(params=params)

            ml_campaigns = {}
            for insight in insights:
                campaign_id = insight.get('campaign_id')
                campaign_name = insight.get('campaign_name')

                # Verificar se √© realmente ML (MACHINE LEARNING ou | ML |)
                if not ('MACHINE LEARNING' in campaign_name.upper() or '| ML |' in campaign_name.upper()):
                    continue

                # Buscar budget e creative IDs desta campanha
                campaign_obj = Campaign(campaign_id)
                campaign_data = campaign_obj.api_get(fields=[
                    Campaign.Field.daily_budget,
                    Campaign.Field.lifetime_budget,
                    Campaign.Field.name
                ])

                # Pegar budget (priorizar daily, sen√£o lifetime)
                # Meta API retorna em centavos - converter para reais
                budget_cents = float(campaign_data.get('daily_budget', 0) or campaign_data.get('lifetime_budget', 0) or 0)
                budget = budget_cents / 100 if budget_cents > 0 else 0

                # Se budget √© 0, tentar buscar dos ad sets (CBO)
                if budget == 0:
                    try:
                        adsets = campaign_obj.get_ad_sets(fields=[
                            AdSet.Field.daily_budget,
                            AdSet.Field.lifetime_budget
                        ])
                        adset_budgets = []
                        for adset in adsets:
                            # Meta API retorna em centavos - converter para reais
                            adset_budget_cents = float(adset.get('daily_budget', 0) or adset.get('lifetime_budget', 0) or 0)
                            adset_budget = adset_budget_cents / 100 if adset_budget_cents > 0 else 0
                            if adset_budget > 0:
                                adset_budgets.append(adset_budget)

                        # Somar budgets dos ad sets
                        if adset_budgets:
                            budget = sum(adset_budgets)
                            logger.debug(f"Budget da campanha {campaign_id} obtido dos ad sets: R$ {budget:.2f}")
                    except Exception as e:
                        logger.debug(f"Erro ao buscar budget dos ad sets: {e}")

                # Buscar creative IDs desta campanha
                creative_ids = self._get_campaign_creative_ids(campaign_id, start_date, end_date)

                ml_campaigns[campaign_id] = {
                    'name': campaign_name,
                    'spend': float(insight.get('spend', 0)),
                    'budget': budget,
                    'impressions': int(insight.get('impressions', 0)),
                    'clicks': int(insight.get('clicks', 0)),
                    'creative_ids': creative_ids,
                }

            logger.info(f"   ‚úÖ {len(ml_campaigns)} campanhas ML encontradas")
            for cid, data in ml_campaigns.items():
                logger.info(f"      {data['name']}: Budget R$ {data['budget']:.2f}, Spend R$ {data['spend']:.2f}, {len(data['creative_ids'])} criativos")

            return ml_campaigns

        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar campanhas ML: {e}")
            return {}

    def find_fair_control_campaigns(
        self,
        ml_campaign_metadata: Dict[str, Dict],
        min_creative_overlap: float = 0.8,
        budget_tolerance: float = 0.30,
        start_date: str = None,
        end_date: str = None
    ) -> Tuple[Dict[str, List[str]], Dict[str, str]]:
        """
        Encontra campanhas de controle com caracter√≠sticas similares.

        CRIT√âRIOS REFINADOS (ap√≥s an√°lise manual):
        - Budget: ¬±30% toler√¢ncia (n√£o precisa ser exato)
        - Criativos: 80%+ overlap (m√≠nimo)
        - Targeting: N√ÉO verificado (evita rate limits, n√£o essencial)

        Args:
            ml_campaign_metadata: Metadata das campanhas ML (de get_ml_campaign_metadata)
            min_creative_overlap: Sobreposi√ß√£o m√≠nima de criativos (0.8 = 80%+)
            budget_tolerance: Toler√¢ncia de budget (0.30 = ¬±30%)
            start_date: Data in√≠cio (YYYY-MM-DD)
            end_date: Data fim (YYYY-MM-DD)

        Returns:
            Tuple de (fair_control_map, control_id_to_name):
            - fair_control_map: Dict com ml_campaign_id ‚Üí [fair_control_campaign_ids]
            - control_id_to_name: Dict com campaign_id ‚Üí campaign_name (para controles)
        """
        if not self.api_available or not ml_campaign_metadata:
            return {}, {}

        logger.info(f"üîç Buscando campanhas de controle justo (crit√©rios: Budget ¬±{budget_tolerance*100:.0f}%, Criativos {min_creative_overlap*100:.0f}%+ iguais)...")

        fair_matches = {}
        control_id_to_name = {}

        try:
            # Buscar TODAS as campanhas do per√≠odo (n√£o apenas ML)
            params = {
                'time_range': {'since': start_date, 'until': end_date},
                'level': 'campaign',
                'fields': ['campaign_id', 'campaign_name', 'spend'],
            }

            all_insights = self.account.get_insights(params=params)

            # Converter para dict - extrair campanhas n√£o-ML
            all_campaigns = {}
            for insight in all_insights:
                campaign_id = insight.get('campaign_id')
                campaign_name = insight.get('campaign_name')

                # Excluir campanhas ML
                if 'MACHINE LEARNING' in campaign_name.upper() or '| ML |' in campaign_name.upper():
                    continue

                # Buscar budget e criativos
                budget = self._get_campaign_budget(campaign_id)
                creative_ids = self._get_campaign_creative_ids(campaign_id, start_date, end_date)

                all_campaigns[campaign_id] = {
                    'name': campaign_name,
                    'spend': float(insight.get('spend', 0)),
                    'budget': budget,
                    'creative_ids': creative_ids,
                }

            logger.info(f"   ‚úÖ {len(all_campaigns)} campanhas n√£o-ML encontradas para compara√ß√£o")

            # Para cada campanha ML, encontrar matches usando crit√©rios refinados
            for ml_id, ml_data in ml_campaign_metadata.items():
                ml_budget = ml_data.get('budget', 0)
                ml_creatives = set(ml_data['creative_ids'])
                ml_name = ml_data['name']

                logger.info(f"\n   üîç Analisando ML: {ml_name[:80]}...")
                logger.info(f"      Budget: R$ {ml_budget:.2f}, {len(ml_creatives)} criativos")

                matches = []
                rejected_budget = 0
                rejected_creatives = 0

                for ctrl_id, ctrl_data in all_campaigns.items():
                    ctrl_budget = ctrl_data.get('budget', 0)
                    ctrl_creatives = set(ctrl_data['creative_ids'])
                    ctrl_name = ctrl_data['name']

                    # Crit√©rio 1: Budget dentro da toler√¢ncia (¬±30%)
                    if ml_budget > 0:
                        budget_diff = abs(ml_budget - ctrl_budget) / ml_budget
                        if budget_diff > budget_tolerance:
                            rejected_budget += 1
                            if rejected_budget <= 3:  # Mostrar primeiras 3
                                logger.info(f"      ‚ùå Budget: {ctrl_name[:60]} (R$ {ctrl_budget:.2f}, diff {budget_diff*100:.0f}% > {budget_tolerance*100:.0f}%)")
                            continue

                    # Crit√©rio 2: Sobreposi√ß√£o de criativos (80%+)
                    if len(ml_creatives) == 0 or len(ctrl_creatives) == 0:
                        rejected_creatives += 1
                        continue

                    overlap = len(ml_creatives & ctrl_creatives)
                    overlap_pct_ml = overlap / len(ml_creatives)
                    overlap_pct_ctrl = overlap / len(ctrl_creatives)
                    min_overlap_pct = min(overlap_pct_ml, overlap_pct_ctrl)

                    if min_overlap_pct < min_creative_overlap:
                        rejected_creatives += 1
                        if rejected_creatives <= 3:  # Mostrar primeiras 3
                            logger.info(f"      ‚ùå Criativos: {ctrl_name[:60]} ({min_overlap_pct*100:.0f}% < {min_creative_overlap*100:.0f}%)")
                        continue

                    # ‚úÖ MATCH ENCONTRADO! Budget ¬±30% e Criativos 80%+
                    logger.info(f"      ‚úÖ MATCH: {ctrl_name[:60]}")
                    logger.info(f"         Budget: R$ {ctrl_budget:.2f} (diff {budget_diff*100:.0f}%), Criativos: {overlap}/{len(ml_creatives)} ({min_overlap_pct*100:.0f}%)")

                    match_info = {
                        'id': ctrl_id,
                        'name': ctrl_data['name'],
                        'spend': ctrl_data['spend'],
                        'budget': ctrl_budget,
                        'creative_overlap': overlap,
                        'creative_overlap_pct': min_overlap_pct * 100,
                        'match_score': (1 - budget_diff) * min_overlap_pct  # Score combinado
                    }

                    matches.append(match_info)

                # Mostrar resumo de filtros
                total_checked = rejected_budget + rejected_creatives + len(matches)
                logger.info(f"\n      üìä Resumo de filtros para esta ML:")
                logger.info(f"         Total verificadas: {total_checked}")
                logger.info(f"         ‚ùå Rejeitadas por Budget: {rejected_budget}")
                logger.info(f"         ‚ùå Rejeitadas por Criativos: {rejected_creatives}")
                logger.info(f"         ‚úÖ Aprovadas (Fair Control): {len(matches)}")

                # Ordenar por match score (melhor combina√ß√£o de budget + criativos)
                matches.sort(key=lambda x: -x['match_score'])

                fair_matches[ml_id] = [m['id'] for m in matches]

                # Adicionar ao mapeamento id ‚Üí name
                for m in matches:
                    control_id_to_name[m['id']] = m['name']

                if matches:
                    logger.info(f"\n   ‚úÖ {ml_name}:")
                    logger.info(f"      üéØ Encontradas {len(matches)} campanhas Fair Control:")
                    for m in matches[:3]:  # Top 3
                        logger.info(f"         ‚Ä¢ {m['name'][:60]}")
                        logger.info(f"           Budget: R$ {m['budget']:.2f}, Criativos: {m['creative_overlap']} ({m['creative_overlap_pct']:.0f}%), Score: {m['match_score']:.2f}")
                else:
                    logger.warning(f"   ‚ö†Ô∏è Nenhuma campanha Fair Control encontrada")

            return fair_matches, control_id_to_name

        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar campanhas de controle: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return {}, {}

    def _get_campaign_budget(self, campaign_id: str) -> float:
        """
        Extrai budget de uma campanha (daily ou lifetime).

        Args:
            campaign_id: ID da campanha

        Returns:
            Budget em R$ (convertido de centavos)
        """
        try:
            campaign_obj = Campaign(campaign_id)
            campaign_data = campaign_obj.api_get(fields=[
                Campaign.Field.daily_budget,
                Campaign.Field.lifetime_budget
            ])
            # Meta API retorna em centavos - converter para reais
            budget_cents = float(campaign_data.get('daily_budget', 0) or campaign_data.get('lifetime_budget', 0) or 0)
            budget = budget_cents / 100 if budget_cents > 0 else 0

            # Se budget √© 0, tentar buscar dos ad sets (CBO)
            if budget == 0:
                try:
                    adsets = campaign_obj.get_ad_sets(fields=[
                        AdSet.Field.daily_budget,
                        AdSet.Field.lifetime_budget
                    ])
                    adset_budgets = []
                    for adset in adsets:
                        adset_budget_cents = float(adset.get('daily_budget', 0) or adset.get('lifetime_budget', 0) or 0)
                        adset_budget = adset_budget_cents / 100 if adset_budget_cents > 0 else 0
                        if adset_budget > 0:
                            adset_budgets.append(adset_budget)

                    if adset_budgets:
                        budget = sum(adset_budgets)
                        logger.debug(f"Budget da campanha {campaign_id} obtido dos ad sets: R$ {budget:.2f}")
                except Exception as e_adset:
                    logger.debug(f"Erro ao buscar budget dos ad sets: {e_adset}")

            return budget

        except Exception as e:
            logger.debug(f"Erro ao buscar budget da campanha {campaign_id}: {e}")
            return 0.0

    def _get_campaign_creative_ids(
        self,
        campaign_id: str,
        start_date: str,
        end_date: str
    ) -> List[str]:
        """
        Extrai creative IDs de uma campanha.

        Args:
            campaign_id: ID da campanha
            start_date: Data in√≠cio
            end_date: Data fim

        Returns:
            Lista de creative IDs √∫nicos
        """
        try:
            campaign = Campaign(campaign_id)

            # Buscar ads da campanha (sem filtro de time_range, buscar todos)
            ads = campaign.get_ads(
                fields=[Ad.Field.creative, Ad.Field.name, Ad.Field.status],
                params={
                    'effective_status': ['ACTIVE', 'PAUSED', 'ARCHIVED'],
                }
            )

            creative_ids = set()
            ad_count = 0
            for ad in ads:
                ad_count += 1
                creative = ad.get(Ad.Field.creative)

                if creative:
                    # Pode vir como dict ou como objeto AdCreative
                    if isinstance(creative, dict):
                        creative_id = creative.get('id')
                    else:
                        # √â um objeto AdCreative, pegar o ID dele
                        creative_id = getattr(creative, 'get_id', lambda: None)() or creative.get('id', None)

                    if creative_id:
                        creative_ids.add(str(creative_id))

            logger.debug(f"Campanha {campaign_id}: {ad_count} ads encontrados, {len(creative_ids)} criativos √∫nicos")
            return list(creative_ids)

        except Exception as e:
            logger.debug(f"Erro ao buscar criativos da campanha {campaign_id}: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []

    def create_comparison_groups(
        self,
        leads_df: pd.DataFrame,
        ml_campaign_metadata: Dict[str, Dict],
        fair_control_map: Dict[str, List[str]],
        control_id_to_name: Dict[str, str],
        campaign_hierarchy: Dict[str, Dict] = None,
        campaigns_with_custom_events: Set[str] = None
    ) -> pd.DataFrame:
        """
        Adiciona coluna 'comparison_group' aos leads baseado nos matches.

        Args:
            leads_df: DataFrame de leads com coluna 'campaign'
            ml_campaign_metadata: Metadata das campanhas ML (com nomes)
            fair_control_map: Mapeamento ML campaign_id ‚Üí [control campaign_ids]
            control_id_to_name: Mapeamento control campaign_id ‚Üí campaign_name
            campaign_hierarchy: Hierarquia de campanhas com optimization_goal (opcional)
            campaigns_with_custom_events: Set de campaign_ids que usam eventos customizados

        Returns:
            DataFrame com coluna 'comparison_group' adicionada:
            - 'Eventos ML': Campanha com eventos customizados
            - 'Otimiza√ß√£o ML': Campanha com ML mas eventos padr√£o
            - 'Controle': Campanha de controle justo
            - 'Outro': Outras campanhas
        """
        df = leads_df.copy()

        # Debug: verificar colunas dispon√≠veis
        has_lq = 'LeadQualified' in df.columns
        has_lqhq = 'LeadQualifiedHighQuality' in df.columns
        logger.info(f"   üîç Colunas de eventos customizados: LeadQualified={has_lq}, LeadQualifiedHighQuality={has_lqhq}")
        if has_lq:
            lq_sum = df['LeadQualified'].sum()
            lq_campaigns = df[df['LeadQualified'] > 0]['campaign'].unique()
            logger.info(f"   üìä Total LeadQualified: {lq_sum} em {len(lq_campaigns)} campanhas")
            if len(lq_campaigns) > 0:
                logger.info(f"   üìã Campanhas com LeadQualified: {lq_campaigns[:3]}")

        # Criar set de nomes COMPLETOS de campanhas de controle justo (incluindo ID)
        fair_control_names = set(control_id_to_name.values())

        # Enriquecer com optimization_goal se n√£o existir
        if 'optimization_goal' not in df.columns:
            # Criar mapeamento campaign_id ‚Üí optimization_goal da hierarquia
            if campaign_hierarchy:
                logger.info(f"   üîç Enriquecendo leads com optimization_goal ({len(campaign_hierarchy)} campanhas na hierarquia)")
                opt_goal_map = {}
                for campaign_id, campaign_data in campaign_hierarchy.items():
                    # Verificar TODOS os adsets para detectar eventos customizados
                    # Se qualquer adset usa evento customizado, a campanha √© "Eventos ML"
                    adsets = campaign_data.get('adsets', {})
                    optimization_goals = []
                    for adset_id, adset_data in adsets.items():
                        opt_goal = adset_data.get('optimization_goal', 'Lead')
                        optimization_goals.append(opt_goal)

                    # Se qualquer adset usa LeadQualified ou LeadQualifiedHighQuality, usar isso
                    if 'LeadQualified' in optimization_goals:
                        opt_goal_map[campaign_id] = 'LeadQualified'
                    elif 'LeadQualifiedHighQuality' in optimization_goals:
                        opt_goal_map[campaign_id] = 'LeadQualifiedHighQuality'
                    else:
                        # Usar o primeiro adset como antes
                        opt_goal_map[campaign_id] = optimization_goals[0] if optimization_goals else 'Lead'

                logger.info(f"   ‚úÖ Mapeamento criado para {len(opt_goal_map)} campanhas")

                # Extrair campaign_id da coluna campaign (formato: "nome|campaign_id")
                def get_campaign_id(campaign_str):
                    if pd.isna(campaign_str) or not isinstance(campaign_str, str):
                        return None
                    if '|' in campaign_str:
                        parts = campaign_str.rsplit('|', 1)
                        if len(parts) == 2 and parts[1].strip().isdigit():
                            return parts[1].strip()
                    return None

                df['_campaign_id'] = df['campaign'].apply(get_campaign_id)
                df['optimization_goal'] = df['_campaign_id'].map(opt_goal_map).fillna('Lead')
                df = df.drop(columns=['_campaign_id'])

                # Log de campanhas COM_ML e seus optimization_goals
                com_ml_campaigns = df[df['ml_type'] == 'COM_ML']['campaign'].unique()
                if len(com_ml_campaigns) > 0:
                    logger.info(f"   üìä Campanhas COM_ML e seus eventos:")
                    for camp in com_ml_campaigns[:5]:  # Primeiras 5
                        camp_rows = df[df['campaign'] == camp]
                        if len(camp_rows) > 0:
                            opt_goal = camp_rows.iloc[0]['optimization_goal']
                            logger.info(f"      ‚Ä¢ {camp[:60]}: {opt_goal}")
            else:
                logger.warning("   ‚ö†Ô∏è Hierarquia de campanhas n√£o fornecida - usando 'Lead' padr√£o")

        # Classificar
        def classify_group(row):
            campaign_name = row.get('campaign', '')
            optimization_goal = row.get('optimization_goal', '')

            # Normalizar: remover sufixo |campaign_id se presente
            campaign_name_base = campaign_name
            campaign_id = None
            if '|' in campaign_name:
                parts = campaign_name.rsplit('|', 1)
                if len(parts) == 2 and parts[1].strip().isdigit():
                    campaign_name_base = parts[0].strip()
                    campaign_id = parts[1].strip()

            # Crit√©rio 1: Eventos ML (COM_ML + usa eventos customizados)
            if row.get('ml_type') == 'COM_ML':
                # Verificar se usa eventos customizados atrav√©s de m√∫ltiplas fontes:
                # 1. Optimization goal da hierarquia
                # 2. Set expl√≠cito de campanhas com eventos customizados
                # 3. Heur√≠stica por data: campanhas criadas a partir de 25/11 usam eventos customizados
                uses_custom_events_by_goal = optimization_goal in ['LeadQualified', 'LeadQualifiedHighQuality']
                uses_custom_events_by_set = campaigns_with_custom_events and campaign_id in campaigns_with_custom_events

                # Heur√≠stica por data: extrair data do nome da campanha (formato: | YYYY-MM-DD)
                uses_custom_events_by_date = False
                import re
                date_match = re.search(r'\| (\d{4})-(\d{2})-(\d{2})', campaign_name)
                if date_match:
                    year, month, day = date_match.groups()
                    campaign_date = f"{year}-{month}-{day}"
                    # Campanhas Eventos ML foram criadas a partir de 2025-11-25 (conta 1880)
                    # ou 2025-11-11 (conta 7867 - teste com LeadQualified)
                    if campaign_date >= "2025-11-11":
                        uses_custom_events_by_date = True

                if uses_custom_events_by_goal or uses_custom_events_by_set or uses_custom_events_by_date:
                    return 'Eventos ML'
                else:
                    return 'Otimiza√ß√£o ML'

            # Crit√©rio 2: √â campanha de controle justo?
            # Check both full name and base name (without ID suffix)
            elif row.get('ml_type') == 'SEM_ML' and (
                campaign_name in fair_control_names or
                campaign_name_base in fair_control_names
            ):
                return 'Controle'

            # Outras campanhas
            else:
                return 'Outro'

        df['comparison_group'] = df.apply(classify_group, axis=1)

        # Log da distribui√ß√£o
        logger.info(f"\n   üìä Distribui√ß√£o de grupos de compara√ß√£o:")
        for group in ['Eventos ML', 'Otimiza√ß√£o ML', 'Controle', 'Outro']:
            count = len(df[df['comparison_group'] == group])
            pct = count / len(df) * 100 if len(df) > 0 else 0
            logger.info(f"      {group}: {count} leads ({pct:.1f}%)")

        return df


