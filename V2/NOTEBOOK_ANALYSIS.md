# An√°lise C√©lula por C√©lula - Notebook smart_ads_devclub_eda_v3

## Se√ß√£o 1: Importa√ß√£o e Upload de Arquivos

### C√âLULA #1: Imports e Upload
**Status:** ‚ùå Desnecess√°ria
**Tipo:** Importa√ß√£o/Upload
**Linhas:** 12-18

**C√≥digo Original:**
```python
from google.colab import files
import pandas as pd
import os
# Upload dos arquivos
print("üì§ FA√áA UPLOAD DOS ARQUIVOS .XLSX")
uploaded = files.upload()
```

**Justificativa:** Em produ√ß√£o, os arquivos ser√£o fornecidos via path direto, n√£o via upload do Colab.

**C√≥digo Produ√ß√£o:** Ser√° substitu√≠do por leitura direta de arquivo
```python
# src/data/loader.py
import pandas as pd
import os
from typing import Dict, Any

def load_lead_file(filepath: str) -> pd.DataFrame:
    """Carrega arquivo de leads no formato Excel"""
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"Arquivo n√£o encontrado: {filepath}")
    return pd.read_excel(filepath)
```

---

## Se√ß√£o 2: Filtragem de Abas e Remo√ß√£o de Duplicatas

### C√âLULA #2: Filtro de Abas + Remo√ß√£o de Duplicatas
**Status:** ‚ö†Ô∏è Adapta√ß√£o
**Tipo:** Transforma√ß√£o
**Linhas:** 26-131

**C√≥digo Original:**
```python
# FILTRAR ABAS + REMOVER DUPLICATAS
termos_manter = ["Pesquisa", "Vendas", "tmb", "Guru", "Sheet"]
termos_remover = ["Pontua√ß√£o", "Lead Score", "DEBUG_LOG", "Tabela Din√¢mica 1", "Detalhe1", "Alunos", "Guru", "TMB", "LEADS"]
min_linhas = 230

for filename in uploaded.keys():
    xl_file = pd.ExcelFile(filename)
    for sheet_name in xl_file.sheet_names:
        df = pd.read_excel(xl_file, sheet_name=sheet_name)
        # Aplicar crit√©rios de filtragem...
        df_sem_duplicatas = df.drop_duplicates(keep='first')
```

**Justificativa:** Em produ√ß√£o, trabalharemos com arquivo √∫nico (Lead Score LF24.xlsx) sem m√∫ltiplas abas. Apenas a remo√ß√£o de duplicatas √© necess√°ria.

**C√≥digo Produ√ß√£o:**
```python
# src/data/validator.py
def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:
    """Remove registros duplicados do DataFrame"""
    initial_count = len(df)
    df_clean = df.drop_duplicates(keep='first')
    removed_count = initial_count - len(df_clean)

    if removed_count > 0:
        print(f"Removidas {removed_count} linhas duplicadas")

    return df_clean
```
**Localiza√ß√£o:** src/data/validator.py:5-14

---

## Se√ß√£o 3: Limpeza de Colunas Desnecess√°rias

### C√âLULA #3: Remo√ß√£o de Colunas
**Status:** ‚ö†Ô∏è Adapta√ß√£o
**Tipo:** Transforma√ß√£o
**Linhas:** 135-234

**C√≥digo Original:**
```python
def obter_colunas_remover_exatas():
    return [
        'Faixa 3.0', 'Faixa A 3.0', 'Faixa B 3.0', 'Faixa C 3.0',
        # ... lista extensa de colunas
    ]

def aplicar_limpeza_colunas():
    colunas_remover = obter_colunas_remover_exatas()
    # Remove colunas desnecess√°rias e Unnamed
```

**Justificativa:** Em produ√ß√£o, precisamos remover apenas as colunas que n√£o fazem parte das 65 features do modelo.

**C√≥digo Produ√ß√£o:**
```python
# src/data/cleaner.py
from typing import List
import pandas as pd

COLUNAS_DESNECESSARIAS = [
    'Faixa 3.0', 'Faixa A 3.0', 'Faixa B 3.0', 'CEP', 'cep',
    'Bairro', 'Cidade', 'Estado', 'Logradouro', 'Complemento',
    'Cliente CPF', 'Data Cancelado', 'Data Efetivado',
    'data cancelamento', 'data garantia', 'Endere√ßo completo',
    # ... apenas colunas confirmadas como desnecess√°rias
]

def clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Remove colunas desnecess√°rias e Unnamed"""
    # Remove colunas Unnamed
    unnamed_cols = [col for col in df.columns if col.startswith('Unnamed:')]

    # Remove colunas da lista de desnecess√°rias
    cols_to_remove = []
    for col in df.columns:
        if col in COLUNAS_DESNECESSARIAS or col in unnamed_cols:
            cols_to_remove.append(col)

    df_clean = df.drop(columns=cols_to_remove, errors='ignore')

    print(f"Removidas {len(cols_to_remove)} colunas desnecess√°rias")
    return df_clean
```
**Localiza√ß√£o:** src/data/cleaner.py:1-28

---

## Se√ß√£o 4: Consolida√ß√£o de Datasets

### C√âLULA #4: Uni√£o de Datasets de Pesquisa e Vendas
**Status:** ‚ùå Desnecess√°ria
**Tipo:** Transforma√ß√£o/Merge
**Linhas:** 238-299

**C√≥digo Original:**
```python
def consolidar_datasets():
    # Identificar e consolidar datasets de pesquisa
    dados_pesquisa = []
    dados_vendas = []
    # ... c√≥digo de consolida√ß√£o
    df_pesquisa_consolidado = pd.concat(dados_pesquisa, ignore_index=True)
    df_vendas_consolidado = pd.concat(dados_vendas, ignore_index=True)
```

**Justificativa:** Em produ√ß√£o n√£o h√° necessidade de consolidar m√∫ltiplos arquivos. Receberemos apenas um arquivo de leads por vez.

---

## Resumo da An√°lise (C√©lulas 1-4)

### Transforma√ß√µes Necess√°rias para Produ√ß√£o:
1. ‚úÖ **Remo√ß√£o de duplicatas** - Manter integridade dos dados
2. ‚úÖ **Limpeza de colunas** - Remover colunas n√£o utilizadas pelo modelo
3. ‚ùå **Upload via Colab** - Substituir por leitura direta
4. ‚ùå **Consolida√ß√£o de m√∫ltiplos arquivos** - N√£o aplic√°vel em produ√ß√£o

### Pr√≥ximas C√©lulas a Analisar:
- Engenharia de features
- Codifica√ß√£o de vari√°veis categ√≥ricas
- Tratamento de valores ausentes
- Prepara√ß√£o final para o modelo

---

## Se√ß√£o 5: Unifica√ß√£o de Colunas Duplicadas (CORRIGIDA)

### C√âLULA #5: Unifica√ß√£o de Colunas - Pesquisa e Vendas
**Status:** ‚ö†Ô∏è Adapta√ß√£o
**Tipo:** Transforma√ß√£o
**Linhas:** 321-467

**An√°lise Detalhada do C√≥digo Original:**

1. **PESQUISA** - Unifica colunas duplicadas/truncadas:
   - `investiu_curso_online`: unifica varia√ß√µes com/sem espa√ßo no final
   - `interesse_programacao`: unifica varia√ß√µes com/sem espa√ßo no final
   - USA FILLNA para combinar valores (linhas 361-367, 377-383)

2. **VENDAS** - Unifica e depois REMOVE:
   - Unifica UTMs: `utm_last_*` com `utm_*` usando fillna (linhas 429-440)
   - **IMPORTANTE:** REMOVE todas as colunas UTM unificadas (linhas 444-450)
   - Unifica outras colunas: valor, produto, nome, email, telefone usando fillna

**Observa√ß√£o Cr√≠tica:** No notebook, as UTMs s√£o processadas apenas em VENDAS e depois REMOVIDAS. No Lead Score LF24 de produ√ß√£o, as UTMs j√° v√™m padronizadas como: SOURCE, MEDIUM, CAMPAIGN, TERM, CONTENT.

**Justificativa:** Em produ√ß√£o, as colunas j√° vir√£o padronizadas no formato Lead Score. Precisamos mapear poss√≠veis varia√ß√µes incluindo UTMs.

**C√≥digo Produ√ß√£o:**
```python
# src/features/column_mapper.py
from typing import Dict, List
import pandas as pd

COLUMN_MAPPINGS = {
    # Colunas de pesquisa
    'investiu_curso_online': [
        'J√° investiu em algum curso online para aprender uma nova forma de ganhar dinheiro?',
        'J√° investiu em algum curso online para aprender uma nova forma de ganhar dinheiro? ',
        'ja_investiu_curso_online'
    ],
    'interesse_programacao': [
        'O que mais te chama aten√ß√£o na profiss√£o de Programador?',
        'O que mais te chama aten√ß√£o na profiss√£o de Programador? ',
        'interesse_programador'
    ],
    # Colunas b√°sicas
    'nome': ['NOME', 'Cliente Nome', 'nome_completo', 'nome contato'],
    'email': ['E-MAIL', 'Cliente Email', 'email_contato'],
    'telefone': ['TELEFONE', 'Telefone', 'telefone_contato'],
    # UTMs - padronizadas no Lead Score
    'Source': ['SOURCE', 'utm_source', 'utm_last_source'],
    'Medium': ['MEDIUM', 'utm_medium', 'utm_last_medium'],
    'Term': ['TERM', 'utm_term', 'utm_last_term']
}

def standardize_column_names(df: pd.DataFrame) -> pd.DataFrame:
    """Padroniza colunas usando fillna como no notebook"""
    df_copy = df.copy()

    for standard_name, variations in COLUMN_MAPPINGS.items():
        existing_cols = [col for col in variations if col in df_copy.columns]

        if len(existing_cols) > 1:
            # Replica estrat√©gia do notebook: fillna iterativo
            df_copy[standard_name] = df_copy[existing_cols[0]]
            for col in existing_cols[1:]:
                df_copy[standard_name] = df_copy[standard_name].fillna(df_copy[col])
            df_copy = df_copy.drop(columns=existing_cols)
        elif len(existing_cols) == 1:
            df_copy = df_copy.rename(columns={existing_cols[0]: standard_name})

    return df_copy
```
**Localiza√ß√£o:** src/features/column_mapper.py:1-43

---

## Se√ß√£o 6: Investiga√ß√£o de Colunas de Programa√ß√£o

### C√âLULA #6: An√°lise Temporal
**Status:** ‚ùå Desnecess√°ria
**Tipo:** Investiga√ß√£o
**Linhas:** 474-499

**Justificativa:** An√°lise explorat√≥ria. Conclus√£o: colunas N√ÉO devem ser unificadas (refutada).

---

## Se√ß√£o 8: Remo√ß√£o de Features Desnecess√°rias

### C√âLULA #8: Remo√ß√£o de Campaign e Content
**Status:** ‚úÖ Necess√°ria
**Tipo:** Transforma√ß√£o
**Linhas:** 1462-1588

**An√°lise:** O modelo foi treinado SEM as colunas Campaign e Content, portanto elas DEVEM ser removidas em produ√ß√£o tamb√©m.

**Colunas removidas:**
1. `Campaign`: Espec√≠fica de cada lan√ßamento
2. `Content`: An√∫ncios individuais de cada lan√ßamento
3. Colunas vazias ou com nomes problem√°ticos

**C√≥digo Produ√ß√£o:**
```python
# src/features/feature_remover.py
import pandas as pd

def remove_unnecessary_features(df: pd.DataFrame) -> pd.DataFrame:
    """Remove features que n√£o foram usadas no treinamento do modelo"""
    df_copy = df.copy()

    # Features que devem ser removidas (modelo foi treinado sem elas)
    features_to_remove = ['Campaign', 'Content', 'CAMPAIGN', 'CONTENT']

    # Remover tamb√©m colunas vazias ou problem√°ticas
    for col in df_copy.columns:
        if col == '' or pd.isna(col) or col is None or str(col).strip() == '':
            features_to_remove.append(col)

    # Remover apenas as que existem
    existing_to_remove = [col for col in features_to_remove if col in df_copy.columns]

    if existing_to_remove:
        df_copy = df_copy.drop(columns=existing_to_remove)
        print(f"Removidas {len(existing_to_remove)} colunas: {existing_to_remove}")

    return df_copy
```
**Localiza√ß√£o:** src/features/feature_remover.py:1-23

---

## Se√ß√£o 10: Unifica√ß√£o de UTM Source e Term

### C√âLULA #10: Categoriza√ß√£o de Source e Term
**Status:** ‚úÖ Necess√°ria
**Tipo:** Transforma√ß√£o
**Linhas:** 1912-2060

**Transforma√ß√µes:**

1. **Source** - Agrupa categorias menores em "outros":
   - Mant√©m: `facebook-ads` (89.6%), `google-ads` (8.3%)
   - Agrupa em "outros": `fb`, `teste`, `[field id="utm_source"]`, etc.

2. **Term** - Padroniza plataformas:
   - `ig` ‚Üí `instagram`
   - `fb` ‚Üí `facebook`
   - IDs num√©ricos (com `--`) ‚Üí `outros`
   - Par√¢metros din√¢micos (com `{`) ‚Üí `outros`

**C√≥digo Produ√ß√£o:**
```python
# src/features/utm_normalizer.py
import pandas as pd
import re

def normalize_utm_fields(df: pd.DataFrame) -> pd.DataFrame:
    """Normaliza campos UTM conforme padr√£o do modelo"""
    df_copy = df.copy()

    # Normalizar Source
    if 'Source' in df_copy.columns or 'SOURCE' in df_copy.columns:
        col_name = 'Source' if 'Source' in df_copy.columns else 'SOURCE'

        # Manter principais, agrupar resto em "outros"
        main_sources = ['facebook-ads', 'google-ads', 'facebook_ads', 'google_ads']
        df_copy[col_name] = df_copy[col_name].apply(
            lambda x: x if pd.isna(x) or x in main_sources else 'outros'
        )

    # Normalizar Term
    if 'Term' in df_copy.columns or 'TERM' in df_copy.columns:
        col_name = 'Term' if 'Term' in df_copy.columns else 'TERM'

        # Mapear valores conhecidos
        term_mapping = {'ig': 'instagram', 'fb': 'facebook'}

        def normalize_term(value):
            if pd.isna(value):
                return value
            value_str = str(value).lower()

            # Aplicar mapeamento direto
            if value_str in term_mapping:
                return term_mapping[value_str]

            # IDs num√©ricos ou par√¢metros din√¢micos
            if '--' in value_str or '{' in value_str:
                return 'outros'

            # Manter instagram/facebook, outros vira "outros"
            if value_str in ['instagram', 'facebook']:
                return value_str

            return 'outros'

        df_copy[col_name] = df_copy[col_name].apply(normalize_term)

    return df_copy
```
**Localiza√ß√£o:** src/features/utm_normalizer.py:1-45

---

## Se√ß√£o 11: Unifica√ß√£o de UTM Medium

### C√âLULA #11: Extra√ß√£o de P√∫blicos do Medium
**Status:** ‚úÖ Necess√°ria
**Tipo:** Transforma√ß√£o
**Linhas:** 2061-2200

**An√°lise:** Extrai o tipo de p√∫blico dos valores complexos de Medium (ex: "ADV | Interesse Python" ‚Üí "Interesse Python")

Continuar com an√°lise das pr√≥ximas c√©lulas? (S/N)