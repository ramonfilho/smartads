#!/usr/bin/env python
"""
Script de diagn√≥stico expandido para detectar mudan√ßas de nomes de colunas.
Inclui an√°lise do arquivo de produ√ß√£o e busca mais detalhada por varia√ß√µes.
"""

import os
import sys
import pandas as pd
from difflib import SequenceMatcher
from collections import defaultdict, Counter
import warnings

# Adicionar o diret√≥rio raiz do projeto ao sys.path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, project_root)

warnings.filterwarnings('ignore')

# Importar m√≥dulos do projeto
from src.utils.local_storage import (
    connect_to_gcs, list_files_by_extension, categorize_files,
    load_csv_or_excel, extract_launch_id
)

def similarity_score(str1, str2):
    """Calcula score de similaridade entre duas strings."""
    if not str1 or not str2:
        return 0
    return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()

def clean_column_name(col_name):
    """Limpa nome da coluna para compara√ß√£o mais efetiva."""
    if pd.isna(col_name):
        return ""
    
    # Converter para string e limpar
    clean_name = str(col_name).lower().strip()
    
    # Remover caracteres especiais comuns
    replacements = {
        '¬ø': '', '?': '', '¬°': '', '!': '', 
        '√°': 'a', '√©': 'e', '√≠': 'i', '√≥': 'o', '√∫': 'u', '√±': 'n',
        '√º': 'u', '\n': ' ', '\t': ' '
    }
    
    for old, new in replacements.items():
        clean_name = clean_name.replace(old, new)
    
    # Normalizar espa√ßos
    clean_name = ' '.join(clean_name.split())
    
    return clean_name

def load_production_reference():
    """Carrega arquivo de produ√ß√£o como refer√™ncia."""
    production_file = "/Users/ramonmoreira/Desktop/smart_ads/data/l24_data.csv"
    
    try:
        if os.path.exists(production_file):
            print(f"üìã Carregando arquivo de produ√ß√£o: {production_file}")
            df = pd.read_csv(production_file)
            
            # Filtrar colunas de predi√ß√£o
            prediction_cols = ['prediction', 'decil', 'Prediction', 'Decil']
            original_cols = [col for col in df.columns if col not in prediction_cols]
            
            print(f"   Shape: {df.shape}")
            print(f"   Colunas (excluindo predi√ß√µes): {len(original_cols)}")
            print(f"   Primeiras 5 colunas: {original_cols[:5]}")
            
            return {
                'dataframe': df,
                'columns': original_cols,
                'all_columns': list(df.columns)
            }
        else:
            print(f"‚ö†Ô∏è Arquivo de produ√ß√£o n√£o encontrado: {production_file}")
            return None
    except Exception as e:
        print(f"‚ùå Erro ao carregar arquivo de produ√ß√£o: {e}")
        return None

def load_survey_data_by_launch():
    """Carrega dados de pesquisa separados por lan√ßamento."""
    print("\nüìä Carregando dados de pesquisa por lan√ßamento...")
    
    # Conectar ao armazenamento
    bucket = connect_to_gcs("local_bucket")
    file_paths = list_files_by_extension(bucket, prefix="")
    
    # Categorizar arquivos
    survey_files, _, _, _ = categorize_files(file_paths)
    
    # Carregar dados por lan√ßamento
    launch_data = {}
    
    for file_path in survey_files:
        launch_id = extract_launch_id(file_path)
        if not launch_id:
            continue
            
        print(f"  üìÅ Carregando {file_path}...")
        df = load_csv_or_excel(bucket, file_path)
        
        if df is not None:
            launch_data[launch_id] = {
                'dataframe': df,
                'file_path': file_path,
                'columns': list(df.columns),
                'shape': df.shape
            }
            print(f"     {launch_id}: {df.shape[0]} linhas, {df.shape[1]} colunas")
        else:
            print(f"     ‚ùå ERRO ao carregar {file_path}")
    
    return launch_data

def analyze_quality_columns(launch_data):
    """Analisa especificamente as colunas de qualidade."""
    print("\n=== üîç AN√ÅLISE DETALHADA DAS COLUNAS DE QUALIDADE ===")
    
    quality_patterns = ['qualidade', 'qualidad', 'quality']
    
    for launch_id, data in launch_data.items():
        quality_cols = []
        for col in data['columns']:
            if any(pattern in col.lower() for pattern in quality_patterns):
                quality_cols.append(col)
        
        print(f"\nüìã {launch_id}:")
        if quality_cols:
            for col in quality_cols:
                # Analisar conte√∫do da coluna
                df = data['dataframe']
                sample_values = df[col].dropna().head(10).tolist()
                unique_count = df[col].nunique()
                
                print(f"   üî∏ {col}")
                print(f"      Valores √∫nicos: {unique_count}")
                print(f"      Amostra: {sample_values[:3]}")
        else:
            print("   ‚ùå Nenhuma coluna de qualidade encontrada")

def search_inmersion_variations(launch_data, target_question):
    """Busca varia√ß√µes da pergunta sobre Inmersi√≥n com threshold mais baixo."""
    print(f"\n=== üîé BUSCANDO VARIA√á√ïES DA PERGUNTA INMERSI√ìN ===")
    print(f"Pergunta alvo: {target_question}")
    
    target_clean = clean_column_name(target_question)
    keywords = ['inmersion', 'aprender', 'ingles', 'horas', '72']
    
    print(f"Palavras-chave: {keywords}")
    print("-" * 80)
    
    variations_found = []
    
    for launch_id, data in launch_data.items():
        print(f"\nüìã {launch_id}:")
        best_matches = []
        
        for col in data['columns']:
            col_clean = clean_column_name(col)
            
            # Verificar se cont√©m palavras-chave relevantes
            keyword_matches = sum(1 for keyword in keywords if keyword in col_clean)
            
            # Calcular similaridade
            similarity = similarity_score(target_clean, col_clean)
            
            # Considerar match se tem palavras-chave OU alta similaridade
            if keyword_matches >= 2 or similarity >= 0.3:
                best_matches.append({
                    'column': col,
                    'similarity': similarity,
                    'keyword_matches': keyword_matches,
                    'clean_name': col_clean
                })
        
        # Ordenar por relev√¢ncia (palavras-chave + similaridade)
        best_matches.sort(key=lambda x: (x['keyword_matches'], x['similarity']), reverse=True)
        
        if best_matches:
            for i, match in enumerate(best_matches[:3]):  # Top 3
                print(f"   {i+1}. {match['column']}")
                print(f"      Similaridade: {match['similarity']:.3f}")
                print(f"      Palavras-chave: {match['keyword_matches']}/{len(keywords)}")
                
                variations_found.append({
                    'launch': launch_id,
                    'column': match['column'],
                    'similarity': match['similarity'],
                    'keyword_matches': match['keyword_matches']
                })
        else:
            print("   ‚ùå Nenhuma varia√ß√£o encontrada")
    
    return variations_found

def compare_with_production(launch_data, production_data):
    """Compara colunas dos lan√ßamentos com arquivo de produ√ß√£o."""
    if not production_data:
        return
        
    print(f"\n=== üìä COMPARA√á√ÉO COM DADOS DE PRODU√á√ÉO ===")
    
    prod_cols_clean = {clean_column_name(col): col for col in production_data['columns']}
    
    print(f"Colunas no arquivo de produ√ß√£o (sem predi√ß√µes): {len(prod_cols_clean)}")
    
    # Para cada lan√ßamento, ver quais colunas est√£o faltando vs produ√ß√£o
    for launch_id, data in launch_data.items():
        launch_cols_clean = {clean_column_name(col): col for col in data['columns']}
        
        missing_in_launch = set(prod_cols_clean.keys()) - set(launch_cols_clean.keys())
        extra_in_launch = set(launch_cols_clean.keys()) - set(prod_cols_clean.keys())
        
        print(f"\nüìã {launch_id}:")
        print(f"   ‚úÖ Colunas em comum: {len(set(prod_cols_clean.keys()) & set(launch_cols_clean.keys()))}")
        
        if missing_in_launch:
            print(f"   ‚ùå Faltando no {launch_id}: {len(missing_in_launch)}")
            for col_clean in list(missing_in_launch)[:5]:  # Mostrar apenas 5
                original_name = prod_cols_clean[col_clean]
                print(f"      - {original_name}")
            if len(missing_in_launch) > 5:
                print(f"      ... e mais {len(missing_in_launch) - 5}")
        
        if extra_in_launch:
            print(f"   ‚ûï Extras no {launch_id}: {len(extra_in_launch)}")
            for col_clean in list(extra_in_launch)[:5]:  # Mostrar apenas 5
                original_name = launch_cols_clean[col_clean]
                print(f"      - {original_name}")
            if len(extra_in_launch) > 5:
                print(f"      ... e mais {len(extra_in_launch) - 5}")

def generate_enhanced_mapping(launch_data, production_data, inmersion_variations):
    """Gera mapeamento mais abrangente baseado em todas as an√°lises."""
    print(f"\n=== üìù MAPEAMENTO RECOMENDADO ===")
    
    print("# Dicion√°rio de mapeamento de colunas")
    print("COLUMN_MAPPINGS = {")
    
    # 1. Colunas de qualidade
    print("    # === COLUNAS DE QUALIDADE ===")
    quality_mappings = [
        ("'Qualidade (Nome) '", "'Qualidade (Nome)'"),  # Remover espa√ßo
        ("'Qualidade (nome)'", "'Qualidade (Nome)'"),   # Padronizar
        ("'Qualidade (N√∫mero) '", "'Qualidade (N√∫mero)'"),  # Remover espa√ßo
        ("'Qualidade (n√∫mero)'", "'Qualidade (N√∫mero)'"),   # Padronizar
        ("'Qualidade (Numero)'", "'Qualidade (N√∫mero)'"),   # Acentua√ß√£o
    ]
    
    for old, new in quality_mappings:
        print(f"    {old}: {new},")
    
    # 2. Varia√ß√µes da pergunta Inmersi√≥n
    if inmersion_variations:
        print("\n    # === PERGUNTA INMERSI√ìN ===")
        target_question = "¬øQu√© esperas aprender en la Inmersi√≥n Desbloquea Tu Ingl√©s En 72 horas?"
        
        for var in inmersion_variations:
            if var['similarity'] > 0.5 or var['keyword_matches'] >= 3:
                print(f"    '{var['column']}': '{target_question}',")
    
    print("}")
    
    # 3. Colunas para remover
    print("\n# Colunas para remover")
    print("COLUMNS_TO_REMOVE = [")
    print("    'teste',")
    print("    'prediction',") 
    print("    'class',")
    print("    'Prediction',")
    print("    'Decil',")
    print("]")
    
    # 4. Tratamento especial para Qualidade simples
    print("\n# TRATAMENTO ESPECIAL NECESS√ÅRIO:")
    print("# Para L16 e L17 que t√™m apenas 'Qualidade':")
    print("# - Verificar se essa coluna cont√©m nomes ou n√∫meros")
    print("# - Criar l√≥gica para dividir em 'Qualidade (Nome)' e 'Qualidade (N√∫mero)'")
    print("# - Ou mapear para uma das duas baseado no conte√∫do")

def main():
    """Fun√ß√£o principal do diagn√≥stico expandido."""
    print("=== üîç DIAGN√ìSTICO EXPANDIDO DE COLUNAS ===")
    
    try:
        # 1. Carregar arquivo de produ√ß√£o como refer√™ncia
        production_data = load_production_reference()
        
        # 2. Carregar dados por lan√ßamento
        launch_data = load_survey_data_by_launch()
        
        if not launch_data:
            print("‚ùå ERRO: Nenhum dado de pesquisa encontrado!")
            return
        
        # 3. An√°lise detalhada das colunas de qualidade
        analyze_quality_columns(launch_data)
        
        # 4. Buscar varia√ß√µes da pergunta Inmersi√≥n
        target_inmersion = "¬øQu√© esperas aprender en la Inmersi√≥n Desbloquea Tu Ingl√©s En 72 horas?"
        inmersion_variations = search_inmersion_variations(launch_data, target_inmersion)
        
        # 5. Comparar com produ√ß√£o (se dispon√≠vel)
        if production_data:
            compare_with_production(launch_data, production_data)
        
        # 6. Gerar mapeamento abrangente
        generate_enhanced_mapping(launch_data, production_data, inmersion_variations)
        
        print(f"\n=== ‚úÖ DIAGN√ìSTICO EXPANDIDO CONCLU√çDO ===")
        
    except Exception as e:
        print(f"‚ùå ERRO durante o diagn√≥stico: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()