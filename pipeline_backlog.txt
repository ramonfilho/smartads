### Sobre Topic Modeling (LDA):
- Textos válidos: 85041 de 116816 total. O número de textos válidos ser aprox 75%, significa que 1 em cada 4 leads não terá os textos analisados? Isso é porque o texto que eles escreveu é nulo ou pequeno, ou é algum parâmetro do código que está sendo excessivamente exigente? 

### Sobre a diferença do número de features de 1007 para 1050: é devido à ausência de textos ou outro motivo? 

### Script 01: 
- Coluna de e-mail removida na função `prepare_final_dataset`. Alguma outra feature pode estar deixando de ser criada posteriormente em virtude disso? Ou seja, alguma parte do código depende dessa coluna específicamente para criar features?
- Certificar por que a coluna "Data" está sendo removida junto com as `COLUMNS_REMOVED_FOR_PRODUCTION_COMPATIBILITY`.
- Tirar excesso de prints

### Script 02:
- Como a coluna de profissões está sendo tratada?  

### Perguntar sobre a estrutura geral da pipeline. Comparar com outras pipelines já vistas. Prós e contras e oportunidades de melhoria que não vão "quebrar" o pipeline. Considere o tipo de problema que estamos tratando e a natureza dos dados.
 - Perguntar sobre feature selection se não mencionar, e sobre o tratamento dos dados no script 2

### Tornar o script reutilizável:
- Atualize a função `apply_preprocessing_pipeline`, passo 6 do script 2, para detectar as colunas de texto usando uma lógica de verificação que identifique pelo conteúdo as features se ela é textual ou não.  Alguma variação no conteúdo da resposta somado a uma verificação de tipo na resposta pode ajudar a identificar as colunas de texto.
- Detecte se algum outro lugar possui alguma lógica isolada para identificar colunas de texto e unifique com essa mesma lógica.

### Futuras implementações:
- Chamar LLM (langchain?) para determinar o vocabulário de palavras a serem usadas para criar as features de texto.
- Tornar a pipeline robusta à linguagem
- Criar função que reconhece os dados de produção em vez de "hardcodar" as colunas de produção no código.
- Criar função que chama LLM para decidir se o arquivo é UTM, pesquisa ou compradores.
 
### Sobre o software: 
- Toda vez que um cliente criar uma conta, gera um bucket na Cloud Storage ou pasta no google drive para ele. 
- Toda vez que ele adiciona um arquivo, perguntar se ainda existem mais arquivos, ou se ele já deseja começar o treinamento do modelo.