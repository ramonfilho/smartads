{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c927f5d6-20a3-499f-823a-2dcd61fc2e82",
   "metadata": {},
   "source": [
    "# Ajuste nos dados para consulta Big Query\n",
    "Estou mesclando as colunas repetidas para poder fazer a consulta de data e definir corretamente os compradores de cada lançamento, para então poder seguir com as análises por lançamento.\n",
    "Além disso houve um problema na formatação:\n",
    "*\"campos de texto com aspas, vírgulas ou quebras de linha não estão sendo corretamente escapados no CSV. A presença de aspas (\"), vírgulas (,) ou quebras de linha dentro de campos de texto causa problemas na interpretação do CSV se não forem adequadamente tratados.\"*\n",
    "O código abaixo trata ambos os problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbe610-020d-4980-adfb-b9765da0022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# PARTE 1: Consolidação de colunas duplicadas\n",
    "print(\"Iniciando consolidação de colunas duplicadas...\")\n",
    "\n",
    "# Usar o dataframe existente\n",
    "df = merged_data.copy()\n",
    "\n",
    "print(f\"DataFrame original: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
    "\n",
    "# 1. Consolidar colunas de Qualidade Nome\n",
    "print(\"\\n--- Consolidando colunas de Qualidade Nome ---\")\n",
    "\n",
    "# Identificar todas as variantes de Qualidade Nome\n",
    "nome_columns = [\n",
    "    col for col in df.columns \n",
    "    if col.lower() in ['qualidade_nome', 'qualidade (nome)', 'qualidade (nome)', 'qualidade_nome']\n",
    "    or col.upper() in ['QUALIDADE_NOME', 'QUALIDADE (NOME)', 'QUALIDADE (NOME)', 'QUALIDADE_NOME']\n",
    "]\n",
    "\n",
    "# Mostrar colunas encontradas\n",
    "print(f\"Variantes de Qualidade Nome encontradas: {nome_columns}\")\n",
    "\n",
    "# Criar uma única coluna consolidada\n",
    "if nome_columns:\n",
    "    # Criar nova coluna\n",
    "    df['qualidade_nome_consolidada'] = np.nan\n",
    "    \n",
    "    # Preencher com valores não nulos de cada variante\n",
    "    for col in nome_columns:\n",
    "        mask = df['qualidade_nome_consolidada'].isna() & df[col].notna()\n",
    "        df.loc[mask, 'qualidade_nome_consolidada'] = df.loc[mask, col]\n",
    "        \n",
    "        # Contar valores adicionados desta coluna\n",
    "        added = mask.sum()\n",
    "        print(f\"- Adicionados {added} valores de '{col}'\")\n",
    "    \n",
    "    # Estatísticas da consolidação\n",
    "    total_filled = df['qualidade_nome_consolidada'].notna().sum()\n",
    "    original_max = max([df[col].notna().sum() for col in nome_columns]) if nome_columns else 0\n",
    "    \n",
    "    print(f\"- Total na coluna consolidada: {total_filled} valores\")\n",
    "    print(f\"- Melhor coluna original tinha: {original_max} valores\")\n",
    "    print(f\"- Ganho de {total_filled - original_max} valores ({((total_filled - original_max) / len(df) * 100):.2f}%)\")\n",
    "    \n",
    "    # Remover colunas originais\n",
    "    df = df.drop(columns=nome_columns)\n",
    "    print(f\"- Removidas {len(nome_columns)} colunas originais\")\n",
    "else:\n",
    "    print(\"Nenhuma coluna de Qualidade Nome encontrada\")\n",
    "\n",
    "# 2. Consolidar colunas de Qualidade Número\n",
    "print(\"\\n--- Consolidando colunas de Qualidade Número ---\")\n",
    "\n",
    "# Identificar todas as variantes de Qualidade Número\n",
    "numero_columns = [\n",
    "    col for col in df.columns \n",
    "    if col.lower() in ['qualidade_numero', 'qualidade (número)', 'qualidade (numero)', 'qualidade_numero']\n",
    "    or col.upper() in ['QUALIDADE_NUMERO', 'QUALIDADE (NÚMERO)', 'QUALIDADE (NUMERO)', 'QUALIDADE_NUMERO']\n",
    "]\n",
    "\n",
    "# Mostrar colunas encontradas\n",
    "print(f\"Variantes de Qualidade Número encontradas: {numero_columns}\")\n",
    "\n",
    "# Criar uma única coluna consolidada\n",
    "if numero_columns:\n",
    "    # Criar nova coluna\n",
    "    df['qualidade_numero_consolidada'] = np.nan\n",
    "    \n",
    "    # Preencher com valores não nulos de cada variante\n",
    "    for col in numero_columns:\n",
    "        mask = df['qualidade_numero_consolidada'].isna() & df[col].notna()\n",
    "        df.loc[mask, 'qualidade_numero_consolidada'] = df.loc[mask, col]\n",
    "        \n",
    "        # Contar valores adicionados desta coluna\n",
    "        added = mask.sum()\n",
    "        print(f\"- Adicionados {added} valores de '{col}'\")\n",
    "    \n",
    "    # Estatísticas da consolidação\n",
    "    total_filled = df['qualidade_numero_consolidada'].notna().sum()\n",
    "    original_max = max([df[col].notna().sum() for col in numero_columns]) if numero_columns else 0\n",
    "    \n",
    "    print(f\"- Total na coluna consolidada: {total_filled} valores\")\n",
    "    print(f\"- Melhor coluna original tinha: {original_max} valores\")\n",
    "    print(f\"- Ganho de {total_filled - original_max} valores ({((total_filled - original_max) / len(df) * 100):.2f}%)\")\n",
    "    \n",
    "    # Remover colunas originais\n",
    "    df = df.drop(columns=numero_columns)\n",
    "    print(f\"- Removidas {len(numero_columns)} colunas originais\")\n",
    "else:\n",
    "    print(\"Nenhuma coluna de Qualidade Número encontrada\")\n",
    "\n",
    "# 3. Consolidar colunas UTM Campaign\n",
    "print(\"\\n--- Consolidando colunas UTM Campaign ---\")\n",
    "\n",
    "# Identificar todas as variantes de UTM Campaign\n",
    "utm_campaign_columns = [\n",
    "    col for col in df.columns \n",
    "    if 'utm' in col.lower() and ('campaign' in col.lower() or 'campaing' in col.lower())\n",
    "]\n",
    "\n",
    "# Mostrar colunas encontradas\n",
    "print(f\"Variantes de UTM Campaign encontradas: {utm_campaign_columns}\")\n",
    "\n",
    "# Criar uma única coluna consolidada (utm_campaign)\n",
    "if utm_campaign_columns and len(utm_campaign_columns) > 1:\n",
    "    # Criar nova coluna\n",
    "    df['utm_campaign_consolidada'] = np.nan\n",
    "    \n",
    "    # Preencher com valores não nulos de cada variante\n",
    "    for col in utm_campaign_columns:\n",
    "        mask = df['utm_campaign_consolidada'].isna() & df[col].notna()\n",
    "        df.loc[mask, 'utm_campaign_consolidada'] = df.loc[mask, col]\n",
    "        \n",
    "        # Contar valores adicionados desta coluna\n",
    "        added = mask.sum()\n",
    "        print(f\"- Adicionados {added} valores de '{col}'\")\n",
    "    \n",
    "    # Estatísticas da consolidação\n",
    "    total_filled = df['utm_campaign_consolidada'].notna().sum()\n",
    "    original_max = max([df[col].notna().sum() for col in utm_campaign_columns]) if utm_campaign_columns else 0\n",
    "    \n",
    "    print(f\"- Total na coluna consolidada: {total_filled} valores\")\n",
    "    print(f\"- Melhor coluna original tinha: {original_max} valores\")\n",
    "    print(f\"- Ganho de {total_filled - original_max} valores ({((total_filled - original_max) / len(df) * 100):.2f}%)\")\n",
    "    \n",
    "    # Remover colunas originais\n",
    "    df = df.drop(columns=utm_campaign_columns)\n",
    "    print(f\"- Removidas {len(utm_campaign_columns)} colunas originais\")\n",
    "else:\n",
    "    print(\"Nenhuma coluna duplicada de UTM Campaign encontrada\")\n",
    "\n",
    "# PARTE 2: Correção do formato CSV para BigQuery\n",
    "print(\"\\n=== CORRIGINDO FORMATO CSV PARA BIGQUERY ===\")\n",
    "\n",
    "# 1. Corrigir problemas com aspas e caracteres especiais nos campos de texto\n",
    "print(\"Corrigindo problemas de formatação em campos de texto...\")\n",
    "\n",
    "# Identificar colunas de texto\n",
    "texto_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Verificando {len(texto_columns)} colunas de texto\")\n",
    "\n",
    "# Processar cada coluna de texto para remover ou escapar caracteres problemáticos\n",
    "for col in texto_columns:\n",
    "    if col in df.columns:  # Verificar se a coluna existe (pode ter sido removida)\n",
    "        # Substituir aspas duplas por aspas simples\n",
    "        df[col] = df[col].apply(lambda x: str(x).replace('\"', \"'\") if isinstance(x, str) else x)\n",
    "        \n",
    "        # Remover quebras de linha e caracteres de controle que podem afetar o CSV\n",
    "        df[col] = df[col].apply(lambda x: str(x).replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ') \n",
    "                               if isinstance(x, str) else x)\n",
    "\n",
    "print(\"Correções aplicadas aos campos de texto\")\n",
    "\n",
    "# 2. Tratar valores nulos (opcional - conforme necessidade)\n",
    "# df = df.fillna('')  # Substituir NaN por strings vazias\n",
    "\n",
    "# 3. Criar pasta para saída\n",
    "output_dir = 'bq_export'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 4. Exportar para CSV com formatação otimizada para BigQuery\n",
    "print(\"\\nExportando para CSV com formatação otimizada para BigQuery...\")\n",
    "\n",
    "# Gerar nome do arquivo com timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_file = f\"{output_dir}/data_consolidada_corrigida_{timestamp}.csv\"\n",
    "\n",
    "# Exportar para CSV com configurações adequadas para BigQuery\n",
    "df.to_csv(output_file, \n",
    "          quoting=csv.QUOTE_NONNUMERIC,  # Coloca aspas em todos os campos não numéricos\n",
    "          escapechar='\\\\',               # Usa \\ para escapar caracteres especiais\n",
    "          doublequote=True,              # Duplica aspas internas em vez de escapá-las\n",
    "          index=False)                   # Não inclui índice\n",
    "\n",
    "# 5. Exportar também uma versão intermediária para validar\n",
    "temp_file = f\"{output_dir}/data_consolidada_sem_correcao_{timestamp}.csv\"\n",
    "df.to_csv(temp_file, index=False)  # Versão sem as configurações especiais\n",
    "\n",
    "print(f\"Arquivo CSV corrigido exportado para: {output_file}\")\n",
    "print(f\"Arquivo CSV padrão (para comparação) exportado para: {temp_file}\")\n",
    "\n",
    "# Resumo final\n",
    "print(\"\\n=== RESUMO DO PROCESSAMENTO ===\")\n",
    "print(f\"DataFrame original: {merged_data.shape[1]} colunas\")\n",
    "print(f\"DataFrame consolidado e corrigido: {df.shape[1]} colunas\")\n",
    "print(f\"Redução: {merged_data.shape[1] - df.shape[1]} colunas ({((merged_data.shape[1] - df.shape[1])/merged_data.shape[1]*100):.2f}%)\")\n",
    "\n",
    "# Verificar se houve alguma perda de dados\n",
    "original_non_null = merged_data.count().sum()\n",
    "new_non_null = df.count().sum()\n",
    "print(f\"Valores não nulos antes: {original_non_null}\")\n",
    "print(f\"Valores não nulos depois: {new_non_null}\")\n",
    "print(f\"Diferença: {new_non_null - original_non_null}\")\n",
    "\n",
    "print(\"\\nProcessamento concluído com sucesso! Tente importar o arquivo corrigido para o BigQuery.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f104a-0829-4a8c-add7-1a40c2ee5fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
